{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guE34D3Fj2R9"
   },
   "source": [
    "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V57zhcTp1Xxb"
   },
   "source": [
    "Objectives:\n",
    "* Solve a regression problem with deep neural networks (DNN).\n",
    "* Understand basic DNN training tips.\n",
    "* Familiarize yourself with PyTorch.\n",
    "\n",
    "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2022-spring@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tm2aXcb-j9Fc"
   },
   "source": [
    "# Download data\n",
    "If the Google Drive links below do not work, you can download data from [Kaggle](https://www.kaggle.com/c/ml2022spring-hw1/data), and upload data manually to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPmfl-awlKZA",
    "outputId": "1d647bcf-046b-46ab-8afe-a3d8ae795569"
   },
   "outputs": [],
   "source": [
    "# !gdown --id '1kLSW_-cW2Huj7bh84YTdimGBOJaODiOS' --output covid.train.csv\n",
    "# !gdown --id '1iiI5qROrAhZn-o4FPqsE97bMzDEFvIdg' --output covid.test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igqIMEgu64-F"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xybQNYCXYu13"
   },
   "outputs": [],
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Reading/Writing Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# For Progress Bar\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# Pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# For plotting learning curve\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTAVqRfc2KK3"
   },
   "source": [
    "# Some Utility Functions\n",
    "\n",
    "You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RbrcpfYN2I-H"
   },
   "outputs": [],
   "source": [
    "def same_seed(seed): \n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)\n",
    "\n",
    "def predict(test_loader, model, device):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    preds = []\n",
    "    for x in test_loader:\n",
    "        x = x.to(device)                        \n",
    "        with torch.no_grad():                   \n",
    "            pred = model(x)                     \n",
    "            preds.append(pred.detach().cpu())   \n",
    "    preds = torch.cat(preds, dim=0).numpy()  \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqO3lTm78nNO"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-mjaJM0wprMs"
   },
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m73ooU75CL_j"
   },
   "source": [
    "# Neural Network Model\n",
    "Try out different model architectures by modifying the class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qn97_WvvrEkG"
   },
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions. \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5-LKF6R8xeq"
   },
   "source": [
    "# Feature Selection\n",
    "Choose features you deem useful by modifying the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0FEnKRaIIeKp"
   },
   "outputs": [],
   "source": [
    "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
    "    '''Selects useful features to perform regression'''\n",
    "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
    "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
    "\n",
    "    if select_all:\n",
    "        feat_idx = list(range(raw_x_train.shape[1]))\n",
    "    else:\n",
    "        feat_idx = [38, 39, 40, 41, 53, 54, 55, 56, 57, 69, 70, 71, 72, 73, 85, 86, 87, 88, 89, 101, 102, 103, 104, 105]\n",
    "#         feat_idx = [38, 39, 40, 41, 50, 53, 54, 55, 56, 57, 66, 69, 70, 71, 72, 73, 82, 85, 86, 87, 88, 89, 98, 101, 102, 103, 104, 105, 114] # TODO: Select suitable feature columns.\n",
    "        \n",
    "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kADIPNQ2Ih5X"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "k4Rq8_TztAhq"
   },
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "\n",
    "    # Define your optimization algorithm. \n",
    "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
    "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'],weight_decay=0.02) \n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.1)\n",
    "    # writer = SummaryWriter() # Writer of tensoboard.\n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode.\n",
    "        loss_record = []\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        # train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
    "            pred = model(x)             \n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "            \n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            # train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            # train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "        #scheduler.step()\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "#         print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}')\n",
    "        # writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "#         if mean_train_loss >1.05:\n",
    "#             continue\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            print(best_loss)\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pgkOh2e9UjE"
   },
   "source": [
    "# Configurations\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QoWPUahCtoT6"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = {\n",
    "    'seed':6264,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': False,   # Whether to use all features.\n",
    "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 3000,     # Number of epochs.            \n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 5e-3,              \n",
    "    'early_stop': 400,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model5.ckpt'  # Your model will be saved here.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrS-aJJh9XkW"
   },
   "source": [
    "# Dataloader\n",
    "Read data from files and set up training, validation, and testing sets. You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jc7ZfDot2t9",
    "outputId": "60c58ccb-f26d-463c-faf2-5436cf6bf83d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size: (2160, 118) \n",
      "valid_data size: (539, 118) \n",
      "test_data size: (1078, 117)\n",
      "number of features: 24\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "same_seed(config['seed'])\n",
    "\n",
    "\n",
    "# train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days) \n",
    "# test_data size: 1078 x 117 (without last day's positive rate)\n",
    "train_data, test_data = pd.read_csv('./covid.train.csv').values, pd.read_csv('./covid.test.csv').values\n",
    "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
    "\n",
    "# Print out the data size.\n",
    "print(f\"\"\"train_data size: {train_data.shape} \n",
    "valid_data size: {valid_data.shape} \n",
    "test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "# Select features\n",
    "x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
    "\n",
    "# Print out the number of features.\n",
    "print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n",
    "                                            COVID19Dataset(x_valid, y_valid), \\\n",
    "                                            COVID19Dataset(x_test)\n",
    "# m = train_dataset.x.mean(0, keepdim=True)\n",
    "# s = train_dataset.x.std(0, keepdim=True)\n",
    "# train_dataset.x = (train_dataset.x-m) / s\n",
    "# valid_dataset.x = (valid_dataset.x-m) / s\n",
    "# test_dataset.x = (test_dataset.x-m) / s\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OBYgjCA-YwD"
   },
   "source": [
    "# Start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdttVRkAfu2t",
    "outputId": "56fead4b-0964-459a-d029-b070323de416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3000]: Train loss: 119.5395, Valid loss: 25.5677\n",
      "Saving model with loss 25.568...\n",
      "Epoch [2/3000]: Train loss: 12.3156, Valid loss: 5.9678\n",
      "Saving model with loss 5.968...\n",
      "Epoch [3/3000]: Train loss: 10.9523, Valid loss: 12.2027\n",
      "Epoch [4/3000]: Train loss: 9.8916, Valid loss: 5.9436\n",
      "Saving model with loss 5.944...\n",
      "Epoch [5/3000]: Train loss: 5.1843, Valid loss: 3.8064\n",
      "Saving model with loss 3.806...\n",
      "Epoch [6/3000]: Train loss: 5.2468, Valid loss: 4.1419\n",
      "Epoch [7/3000]: Train loss: 4.7075, Valid loss: 3.9567\n",
      "Epoch [8/3000]: Train loss: 4.5340, Valid loss: 4.1196\n",
      "Epoch [9/3000]: Train loss: 4.4088, Valid loss: 3.7098\n",
      "Saving model with loss 3.710...\n",
      "Epoch [10/3000]: Train loss: 4.2775, Valid loss: 3.6976\n",
      "Saving model with loss 3.698...\n",
      "Epoch [11/3000]: Train loss: 4.1793, Valid loss: 3.7964\n",
      "Epoch [12/3000]: Train loss: 4.0470, Valid loss: 4.2531\n",
      "Epoch [13/3000]: Train loss: 3.9582, Valid loss: 3.5768\n",
      "Saving model with loss 3.577...\n",
      "Epoch [14/3000]: Train loss: 3.8812, Valid loss: 3.6836\n",
      "Epoch [15/3000]: Train loss: 3.7818, Valid loss: 3.0043\n",
      "Saving model with loss 3.004...\n",
      "Epoch [16/3000]: Train loss: 3.7045, Valid loss: 3.4581\n",
      "Epoch [17/3000]: Train loss: 3.5582, Valid loss: 3.0232\n",
      "Epoch [18/3000]: Train loss: 3.4735, Valid loss: 3.3721\n",
      "Epoch [19/3000]: Train loss: 3.4096, Valid loss: 2.7914\n",
      "Saving model with loss 2.791...\n",
      "Epoch [20/3000]: Train loss: 3.2623, Valid loss: 3.5000\n",
      "Epoch [21/3000]: Train loss: 3.1702, Valid loss: 3.4093\n",
      "Epoch [22/3000]: Train loss: 3.1465, Valid loss: 3.0994\n",
      "Epoch [23/3000]: Train loss: 3.0754, Valid loss: 2.9169\n",
      "Epoch [24/3000]: Train loss: 2.9917, Valid loss: 2.7744\n",
      "Saving model with loss 2.774...\n",
      "Epoch [25/3000]: Train loss: 2.9308, Valid loss: 3.2592\n",
      "Epoch [26/3000]: Train loss: 2.8659, Valid loss: 2.4996\n",
      "Saving model with loss 2.500...\n",
      "Epoch [27/3000]: Train loss: 2.7724, Valid loss: 2.9711\n",
      "Epoch [28/3000]: Train loss: 2.7075, Valid loss: 3.2388\n",
      "Epoch [29/3000]: Train loss: 2.6831, Valid loss: 3.3670\n",
      "Epoch [30/3000]: Train loss: 2.6108, Valid loss: 2.1814\n",
      "Saving model with loss 2.181...\n",
      "Epoch [31/3000]: Train loss: 2.5688, Valid loss: 2.4924\n",
      "Epoch [32/3000]: Train loss: 2.5252, Valid loss: 2.4594\n",
      "Epoch [33/3000]: Train loss: 2.4597, Valid loss: 2.2755\n",
      "Epoch [34/3000]: Train loss: 2.4771, Valid loss: 2.6850\n",
      "Epoch [35/3000]: Train loss: 2.3807, Valid loss: 2.3304\n",
      "Epoch [36/3000]: Train loss: 2.4037, Valid loss: 2.0712\n",
      "Saving model with loss 2.071...\n",
      "Epoch [37/3000]: Train loss: 2.3156, Valid loss: 2.0326\n",
      "Saving model with loss 2.033...\n",
      "Epoch [38/3000]: Train loss: 2.3080, Valid loss: 2.2699\n",
      "Epoch [39/3000]: Train loss: 2.2530, Valid loss: 2.2174\n",
      "Epoch [40/3000]: Train loss: 2.2832, Valid loss: 2.3571\n",
      "Epoch [41/3000]: Train loss: 2.2660, Valid loss: 2.2117\n",
      "Epoch [42/3000]: Train loss: 2.2193, Valid loss: 2.1353\n",
      "Epoch [43/3000]: Train loss: 2.2038, Valid loss: 1.9056\n",
      "Saving model with loss 1.906...\n",
      "Epoch [44/3000]: Train loss: 2.1565, Valid loss: 1.9943\n",
      "Epoch [45/3000]: Train loss: 2.1410, Valid loss: 2.1369\n",
      "Epoch [46/3000]: Train loss: 2.1214, Valid loss: 2.3810\n",
      "Epoch [47/3000]: Train loss: 2.1427, Valid loss: 2.2374\n",
      "Epoch [48/3000]: Train loss: 2.0803, Valid loss: 1.8474\n",
      "Saving model with loss 1.847...\n",
      "Epoch [49/3000]: Train loss: 2.1293, Valid loss: 2.0881\n",
      "Epoch [50/3000]: Train loss: 2.0798, Valid loss: 2.3196\n",
      "Epoch [51/3000]: Train loss: 2.0027, Valid loss: 2.5716\n",
      "Epoch [52/3000]: Train loss: 2.0143, Valid loss: 1.7986\n",
      "Saving model with loss 1.799...\n",
      "Epoch [53/3000]: Train loss: 2.0216, Valid loss: 1.7620\n",
      "Saving model with loss 1.762...\n",
      "Epoch [54/3000]: Train loss: 1.9913, Valid loss: 2.0700\n",
      "Epoch [55/3000]: Train loss: 1.9722, Valid loss: 2.0052\n",
      "Epoch [56/3000]: Train loss: 1.9731, Valid loss: 1.9812\n",
      "Epoch [57/3000]: Train loss: 1.9977, Valid loss: 2.3432\n",
      "Epoch [58/3000]: Train loss: 1.9786, Valid loss: 1.8354\n",
      "Epoch [59/3000]: Train loss: 1.9784, Valid loss: 2.5541\n",
      "Epoch [60/3000]: Train loss: 1.9504, Valid loss: 2.0811\n",
      "Epoch [61/3000]: Train loss: 1.9586, Valid loss: 1.9429\n",
      "Epoch [62/3000]: Train loss: 1.9323, Valid loss: 2.1397\n",
      "Epoch [63/3000]: Train loss: 1.8708, Valid loss: 1.9138\n",
      "Epoch [64/3000]: Train loss: 1.8781, Valid loss: 2.1150\n",
      "Epoch [65/3000]: Train loss: 1.8930, Valid loss: 1.5620\n",
      "Saving model with loss 1.562...\n",
      "Epoch [66/3000]: Train loss: 1.9050, Valid loss: 1.6566\n",
      "Epoch [67/3000]: Train loss: 1.8740, Valid loss: 2.0095\n",
      "Epoch [68/3000]: Train loss: 1.8259, Valid loss: 1.8644\n",
      "Epoch [69/3000]: Train loss: 1.8152, Valid loss: 2.3697\n",
      "Epoch [70/3000]: Train loss: 1.8371, Valid loss: 1.6923\n",
      "Epoch [71/3000]: Train loss: 1.8203, Valid loss: 1.9784\n",
      "Epoch [72/3000]: Train loss: 1.8208, Valid loss: 2.0653\n",
      "Epoch [73/3000]: Train loss: 1.8044, Valid loss: 1.6589\n",
      "Epoch [74/3000]: Train loss: 1.8060, Valid loss: 2.1856\n",
      "Epoch [75/3000]: Train loss: 1.7998, Valid loss: 2.0892\n",
      "Epoch [76/3000]: Train loss: 1.7682, Valid loss: 2.0534\n",
      "Epoch [77/3000]: Train loss: 1.7817, Valid loss: 1.7288\n",
      "Epoch [78/3000]: Train loss: 1.7773, Valid loss: 1.9745\n",
      "Epoch [79/3000]: Train loss: 1.7430, Valid loss: 1.5400\n",
      "Saving model with loss 1.540...\n",
      "Epoch [80/3000]: Train loss: 1.7364, Valid loss: 1.5106\n",
      "Saving model with loss 1.511...\n",
      "Epoch [81/3000]: Train loss: 1.7638, Valid loss: 1.4902\n",
      "Saving model with loss 1.490...\n",
      "Epoch [82/3000]: Train loss: 1.7544, Valid loss: 1.7540\n",
      "Epoch [83/3000]: Train loss: 1.7448, Valid loss: 1.8672\n",
      "Epoch [84/3000]: Train loss: 1.6975, Valid loss: 1.7178\n",
      "Epoch [85/3000]: Train loss: 1.7219, Valid loss: 1.7050\n",
      "Epoch [86/3000]: Train loss: 1.7314, Valid loss: 1.6859\n",
      "Epoch [87/3000]: Train loss: 1.7138, Valid loss: 1.7859\n",
      "Epoch [88/3000]: Train loss: 1.6670, Valid loss: 1.5463\n",
      "Epoch [89/3000]: Train loss: 1.6913, Valid loss: 1.6983\n",
      "Epoch [90/3000]: Train loss: 1.6882, Valid loss: 1.6838\n",
      "Epoch [91/3000]: Train loss: 1.6726, Valid loss: 1.7789\n",
      "Epoch [92/3000]: Train loss: 1.6319, Valid loss: 1.7608\n",
      "Epoch [93/3000]: Train loss: 1.6534, Valid loss: 1.6431\n",
      "Epoch [94/3000]: Train loss: 1.6911, Valid loss: 1.5822\n",
      "Epoch [95/3000]: Train loss: 1.6373, Valid loss: 1.5191\n",
      "Epoch [96/3000]: Train loss: 1.6306, Valid loss: 1.2775\n",
      "Saving model with loss 1.277...\n",
      "Epoch [97/3000]: Train loss: 1.6075, Valid loss: 1.8564\n",
      "Epoch [98/3000]: Train loss: 1.6239, Valid loss: 1.5989\n",
      "Epoch [99/3000]: Train loss: 1.6110, Valid loss: 1.5572\n",
      "Epoch [100/3000]: Train loss: 1.6065, Valid loss: 1.6911\n",
      "Epoch [101/3000]: Train loss: 1.6165, Valid loss: 1.8412\n",
      "Epoch [102/3000]: Train loss: 1.6252, Valid loss: 1.6257\n",
      "Epoch [103/3000]: Train loss: 1.5765, Valid loss: 1.4222\n",
      "Epoch [104/3000]: Train loss: 1.5832, Valid loss: 1.4797\n",
      "Epoch [105/3000]: Train loss: 1.5541, Valid loss: 1.2259\n",
      "Saving model with loss 1.226...\n",
      "Epoch [106/3000]: Train loss: 1.5876, Valid loss: 1.5139\n",
      "Epoch [107/3000]: Train loss: 1.5585, Valid loss: 1.6455\n",
      "Epoch [108/3000]: Train loss: 1.5847, Valid loss: 1.9089\n",
      "Epoch [109/3000]: Train loss: 1.5400, Valid loss: 1.4053\n",
      "Epoch [110/3000]: Train loss: 1.5484, Valid loss: 1.4452\n",
      "Epoch [111/3000]: Train loss: 1.5276, Valid loss: 1.3300\n",
      "Epoch [112/3000]: Train loss: 1.5219, Valid loss: 1.5242\n",
      "Epoch [113/3000]: Train loss: 1.5186, Valid loss: 1.3532\n",
      "Epoch [114/3000]: Train loss: 1.5018, Valid loss: 1.5565\n",
      "Epoch [115/3000]: Train loss: 1.5126, Valid loss: 1.5433\n",
      "Epoch [116/3000]: Train loss: 1.5136, Valid loss: 1.3703\n",
      "Epoch [117/3000]: Train loss: 1.5121, Valid loss: 1.5283\n",
      "Epoch [118/3000]: Train loss: 1.5243, Valid loss: 1.6860\n",
      "Epoch [119/3000]: Train loss: 1.4826, Valid loss: 1.5944\n",
      "Epoch [120/3000]: Train loss: 1.5413, Valid loss: 1.7390\n",
      "Epoch [121/3000]: Train loss: 1.4892, Valid loss: 1.2941\n",
      "Epoch [122/3000]: Train loss: 1.4647, Valid loss: 1.4918\n",
      "Epoch [123/3000]: Train loss: 1.5122, Valid loss: 1.3444\n",
      "Epoch [124/3000]: Train loss: 1.4820, Valid loss: 1.6130\n",
      "Epoch [125/3000]: Train loss: 1.4521, Valid loss: 1.5701\n",
      "Epoch [126/3000]: Train loss: 1.4478, Valid loss: 1.1164\n",
      "Saving model with loss 1.116...\n",
      "Epoch [127/3000]: Train loss: 1.4914, Valid loss: 1.7582\n",
      "Epoch [128/3000]: Train loss: 1.4545, Valid loss: 1.2395\n",
      "Epoch [129/3000]: Train loss: 1.4473, Valid loss: 1.3369\n",
      "Epoch [130/3000]: Train loss: 1.4320, Valid loss: 1.4201\n",
      "Epoch [131/3000]: Train loss: 1.4186, Valid loss: 1.3085\n",
      "Epoch [132/3000]: Train loss: 1.4289, Valid loss: 1.2193\n",
      "Epoch [133/3000]: Train loss: 1.4412, Valid loss: 1.2377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/3000]: Train loss: 1.4117, Valid loss: 1.4533\n",
      "Epoch [135/3000]: Train loss: 1.4118, Valid loss: 1.2596\n",
      "Epoch [136/3000]: Train loss: 1.3928, Valid loss: 1.5458\n",
      "Epoch [137/3000]: Train loss: 1.4448, Valid loss: 1.4328\n",
      "Epoch [138/3000]: Train loss: 1.4106, Valid loss: 1.3463\n",
      "Epoch [139/3000]: Train loss: 1.3999, Valid loss: 1.3703\n",
      "Epoch [140/3000]: Train loss: 1.4073, Valid loss: 1.1214\n",
      "Epoch [141/3000]: Train loss: 1.3991, Valid loss: 1.2866\n",
      "Epoch [142/3000]: Train loss: 1.3888, Valid loss: 1.2038\n",
      "Epoch [143/3000]: Train loss: 1.3836, Valid loss: 1.4542\n",
      "Epoch [144/3000]: Train loss: 1.4033, Valid loss: 1.0391\n",
      "Saving model with loss 1.039...\n",
      "Epoch [145/3000]: Train loss: 1.3789, Valid loss: 1.1501\n",
      "Epoch [146/3000]: Train loss: 1.3583, Valid loss: 1.1686\n",
      "Epoch [147/3000]: Train loss: 1.3777, Valid loss: 1.4162\n",
      "Epoch [148/3000]: Train loss: 1.3773, Valid loss: 1.5228\n",
      "Epoch [149/3000]: Train loss: 1.3827, Valid loss: 1.5285\n",
      "Epoch [150/3000]: Train loss: 1.3704, Valid loss: 1.2028\n",
      "Epoch [151/3000]: Train loss: 1.3434, Valid loss: 1.3439\n",
      "Epoch [152/3000]: Train loss: 1.3652, Valid loss: 1.0728\n",
      "Epoch [153/3000]: Train loss: 1.3513, Valid loss: 1.1440\n",
      "Epoch [154/3000]: Train loss: 1.3462, Valid loss: 1.2232\n",
      "Epoch [155/3000]: Train loss: 1.3294, Valid loss: 1.2261\n",
      "Epoch [156/3000]: Train loss: 1.3320, Valid loss: 1.2996\n",
      "Epoch [157/3000]: Train loss: 1.3561, Valid loss: 1.0739\n",
      "Epoch [158/3000]: Train loss: 1.3299, Valid loss: 1.1488\n",
      "Epoch [159/3000]: Train loss: 1.3325, Valid loss: 1.4504\n",
      "Epoch [160/3000]: Train loss: 1.3258, Valid loss: 1.1554\n",
      "Epoch [161/3000]: Train loss: 1.3174, Valid loss: 1.2975\n",
      "Epoch [162/3000]: Train loss: 1.3230, Valid loss: 1.0071\n",
      "Saving model with loss 1.007...\n",
      "Epoch [163/3000]: Train loss: 1.3383, Valid loss: 1.3974\n",
      "Epoch [164/3000]: Train loss: 1.3295, Valid loss: 1.1466\n",
      "Epoch [165/3000]: Train loss: 1.3507, Valid loss: 1.2277\n",
      "Epoch [166/3000]: Train loss: 1.3311, Valid loss: 1.1425\n",
      "Epoch [167/3000]: Train loss: 1.3081, Valid loss: 1.0598\n",
      "Epoch [168/3000]: Train loss: 1.3185, Valid loss: 1.0467\n",
      "Epoch [169/3000]: Train loss: 1.3110, Valid loss: 1.1273\n",
      "Epoch [170/3000]: Train loss: 1.3089, Valid loss: 1.2029\n",
      "Epoch [171/3000]: Train loss: 1.3072, Valid loss: 1.4260\n",
      "Epoch [172/3000]: Train loss: 1.2994, Valid loss: 1.1461\n",
      "Epoch [173/3000]: Train loss: 1.2744, Valid loss: 1.1922\n",
      "Epoch [174/3000]: Train loss: 1.2833, Valid loss: 1.0698\n",
      "Epoch [175/3000]: Train loss: 1.3257, Valid loss: 1.2573\n",
      "Epoch [176/3000]: Train loss: 1.2854, Valid loss: 1.0830\n",
      "Epoch [177/3000]: Train loss: 1.2977, Valid loss: 1.0867\n",
      "Epoch [178/3000]: Train loss: 1.2631, Valid loss: 1.1646\n",
      "Epoch [179/3000]: Train loss: 1.2997, Valid loss: 1.3003\n",
      "Epoch [180/3000]: Train loss: 1.3159, Valid loss: 1.2210\n",
      "Epoch [181/3000]: Train loss: 1.2546, Valid loss: 1.1702\n",
      "Epoch [182/3000]: Train loss: 1.2733, Valid loss: 1.1344\n",
      "Epoch [183/3000]: Train loss: 1.3045, Valid loss: 0.9465\n",
      "Saving model with loss 0.947...\n",
      "Epoch [184/3000]: Train loss: 1.2913, Valid loss: 1.0082\n",
      "Epoch [185/3000]: Train loss: 1.2643, Valid loss: 1.1501\n",
      "Epoch [186/3000]: Train loss: 1.2486, Valid loss: 1.0072\n",
      "Epoch [187/3000]: Train loss: 1.3037, Valid loss: 1.0735\n",
      "Epoch [188/3000]: Train loss: 1.2554, Valid loss: 1.2497\n",
      "Epoch [189/3000]: Train loss: 1.2463, Valid loss: 1.4261\n",
      "Epoch [190/3000]: Train loss: 1.2852, Valid loss: 1.2287\n",
      "Epoch [191/3000]: Train loss: 1.2605, Valid loss: 1.2149\n",
      "Epoch [192/3000]: Train loss: 1.2571, Valid loss: 1.3163\n",
      "Epoch [193/3000]: Train loss: 1.2491, Valid loss: 1.1059\n",
      "Epoch [194/3000]: Train loss: 1.2522, Valid loss: 0.9280\n",
      "Saving model with loss 0.928...\n",
      "Epoch [195/3000]: Train loss: 1.2441, Valid loss: 1.1908\n",
      "Epoch [196/3000]: Train loss: 1.2545, Valid loss: 1.2985\n",
      "Epoch [197/3000]: Train loss: 1.2740, Valid loss: 1.1033\n",
      "Epoch [198/3000]: Train loss: 1.2216, Valid loss: 1.5038\n",
      "Epoch [199/3000]: Train loss: 1.2510, Valid loss: 1.1740\n",
      "Epoch [200/3000]: Train loss: 1.2556, Valid loss: 1.4828\n",
      "Epoch [201/3000]: Train loss: 1.2604, Valid loss: 0.9871\n",
      "Epoch [202/3000]: Train loss: 1.2669, Valid loss: 0.9631\n",
      "Epoch [203/3000]: Train loss: 1.2475, Valid loss: 1.1875\n",
      "Epoch [204/3000]: Train loss: 1.2317, Valid loss: 1.0075\n",
      "Epoch [205/3000]: Train loss: 1.2177, Valid loss: 1.0179\n",
      "Epoch [206/3000]: Train loss: 1.2141, Valid loss: 1.1021\n",
      "Epoch [207/3000]: Train loss: 1.2272, Valid loss: 0.9975\n",
      "Epoch [208/3000]: Train loss: 1.2487, Valid loss: 1.1727\n",
      "Epoch [209/3000]: Train loss: 1.2463, Valid loss: 0.9632\n",
      "Epoch [210/3000]: Train loss: 1.2457, Valid loss: 0.8642\n",
      "Saving model with loss 0.864...\n",
      "Epoch [211/3000]: Train loss: 1.2243, Valid loss: 1.2553\n",
      "Epoch [212/3000]: Train loss: 1.2283, Valid loss: 1.2963\n",
      "Epoch [213/3000]: Train loss: 1.2407, Valid loss: 1.2344\n",
      "Epoch [214/3000]: Train loss: 1.2448, Valid loss: 0.9828\n",
      "Epoch [215/3000]: Train loss: 1.2586, Valid loss: 0.9492\n",
      "Epoch [216/3000]: Train loss: 1.2665, Valid loss: 0.9767\n",
      "Epoch [217/3000]: Train loss: 1.2354, Valid loss: 0.8983\n",
      "Epoch [218/3000]: Train loss: 1.2279, Valid loss: 0.9628\n",
      "Epoch [219/3000]: Train loss: 1.2200, Valid loss: 1.0766\n",
      "Epoch [220/3000]: Train loss: 1.2184, Valid loss: 1.1527\n",
      "Epoch [221/3000]: Train loss: 1.2298, Valid loss: 0.9110\n",
      "Epoch [222/3000]: Train loss: 1.2446, Valid loss: 0.9688\n",
      "Epoch [223/3000]: Train loss: 1.2017, Valid loss: 1.1555\n",
      "Epoch [224/3000]: Train loss: 1.2477, Valid loss: 1.1595\n",
      "Epoch [225/3000]: Train loss: 1.2301, Valid loss: 0.9604\n",
      "Epoch [226/3000]: Train loss: 1.2048, Valid loss: 0.9420\n",
      "Epoch [227/3000]: Train loss: 1.2251, Valid loss: 0.8839\n",
      "Epoch [228/3000]: Train loss: 1.2521, Valid loss: 0.9777\n",
      "Epoch [229/3000]: Train loss: 1.2099, Valid loss: 0.8929\n",
      "Epoch [230/3000]: Train loss: 1.2320, Valid loss: 0.9087\n",
      "Epoch [231/3000]: Train loss: 1.2154, Valid loss: 0.9133\n",
      "Epoch [232/3000]: Train loss: 1.2165, Valid loss: 1.1188\n",
      "Epoch [233/3000]: Train loss: 1.2429, Valid loss: 1.0592\n",
      "Epoch [234/3000]: Train loss: 1.2471, Valid loss: 1.2029\n",
      "Epoch [235/3000]: Train loss: 1.2373, Valid loss: 1.1218\n",
      "Epoch [236/3000]: Train loss: 1.2081, Valid loss: 0.9190\n",
      "Epoch [237/3000]: Train loss: 1.1886, Valid loss: 0.8569\n",
      "Saving model with loss 0.857...\n",
      "Epoch [238/3000]: Train loss: 1.1892, Valid loss: 1.0779\n",
      "Epoch [239/3000]: Train loss: 1.1991, Valid loss: 1.1146\n",
      "Epoch [240/3000]: Train loss: 1.2110, Valid loss: 1.2241\n",
      "Epoch [241/3000]: Train loss: 1.2230, Valid loss: 1.0637\n",
      "Epoch [242/3000]: Train loss: 1.2050, Valid loss: 1.1357\n",
      "Epoch [243/3000]: Train loss: 1.2103, Valid loss: 1.1695\n",
      "Epoch [244/3000]: Train loss: 1.1991, Valid loss: 0.9164\n",
      "Epoch [245/3000]: Train loss: 1.2064, Valid loss: 0.8539\n",
      "Saving model with loss 0.854...\n",
      "Epoch [246/3000]: Train loss: 1.1724, Valid loss: 1.2183\n",
      "Epoch [247/3000]: Train loss: 1.2099, Valid loss: 1.0100\n",
      "Epoch [248/3000]: Train loss: 1.2309, Valid loss: 1.2690\n",
      "Epoch [249/3000]: Train loss: 1.2057, Valid loss: 1.0232\n",
      "Epoch [250/3000]: Train loss: 1.2251, Valid loss: 0.8805\n",
      "Epoch [251/3000]: Train loss: 1.2209, Valid loss: 1.0185\n",
      "Epoch [252/3000]: Train loss: 1.2196, Valid loss: 1.0598\n",
      "Epoch [253/3000]: Train loss: 1.1975, Valid loss: 1.5001\n",
      "Epoch [254/3000]: Train loss: 1.2129, Valid loss: 0.8573\n",
      "Epoch [255/3000]: Train loss: 1.2025, Valid loss: 0.9970\n",
      "Epoch [256/3000]: Train loss: 1.1913, Valid loss: 1.0066\n",
      "Epoch [257/3000]: Train loss: 1.1738, Valid loss: 1.2263\n",
      "Epoch [258/3000]: Train loss: 1.1928, Valid loss: 0.9689\n",
      "Epoch [259/3000]: Train loss: 1.1790, Valid loss: 0.9433\n",
      "Epoch [260/3000]: Train loss: 1.1868, Valid loss: 0.9446\n",
      "Epoch [261/3000]: Train loss: 1.2150, Valid loss: 0.9844\n",
      "Epoch [262/3000]: Train loss: 1.2168, Valid loss: 0.9752\n",
      "Epoch [263/3000]: Train loss: 1.2110, Valid loss: 0.9362\n",
      "Epoch [264/3000]: Train loss: 1.2518, Valid loss: 1.1202\n",
      "Epoch [265/3000]: Train loss: 1.1742, Valid loss: 0.9121\n",
      "Epoch [266/3000]: Train loss: 1.1870, Valid loss: 1.0100\n",
      "Epoch [267/3000]: Train loss: 1.2303, Valid loss: 1.0217\n",
      "Epoch [268/3000]: Train loss: 1.2078, Valid loss: 1.1861\n",
      "Epoch [269/3000]: Train loss: 1.1711, Valid loss: 1.0858\n",
      "Epoch [270/3000]: Train loss: 1.1807, Valid loss: 1.1568\n",
      "Epoch [271/3000]: Train loss: 1.1876, Valid loss: 0.9931\n",
      "Epoch [272/3000]: Train loss: 1.2069, Valid loss: 0.8521\n",
      "Saving model with loss 0.852...\n",
      "Epoch [273/3000]: Train loss: 1.2109, Valid loss: 1.0795\n",
      "Epoch [274/3000]: Train loss: 1.2065, Valid loss: 0.8854\n",
      "Epoch [275/3000]: Train loss: 1.2007, Valid loss: 1.0476\n",
      "Epoch [276/3000]: Train loss: 1.1798, Valid loss: 1.1070\n",
      "Epoch [277/3000]: Train loss: 1.2129, Valid loss: 0.8082\n",
      "Saving model with loss 0.808...\n",
      "Epoch [278/3000]: Train loss: 1.1772, Valid loss: 0.9481\n",
      "Epoch [279/3000]: Train loss: 1.1854, Valid loss: 1.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/3000]: Train loss: 1.1956, Valid loss: 0.9335\n",
      "Epoch [281/3000]: Train loss: 1.1927, Valid loss: 1.0639\n",
      "Epoch [282/3000]: Train loss: 1.1920, Valid loss: 0.8762\n",
      "Epoch [283/3000]: Train loss: 1.2200, Valid loss: 1.0591\n",
      "Epoch [284/3000]: Train loss: 1.2135, Valid loss: 1.0399\n",
      "Epoch [285/3000]: Train loss: 1.2068, Valid loss: 0.9297\n",
      "Epoch [286/3000]: Train loss: 1.2380, Valid loss: 0.9757\n",
      "Epoch [287/3000]: Train loss: 1.1975, Valid loss: 1.1237\n",
      "Epoch [288/3000]: Train loss: 1.1810, Valid loss: 0.8998\n",
      "Epoch [289/3000]: Train loss: 1.1785, Valid loss: 1.1110\n",
      "Epoch [290/3000]: Train loss: 1.1965, Valid loss: 0.9685\n",
      "Epoch [291/3000]: Train loss: 1.1713, Valid loss: 0.8917\n",
      "Epoch [292/3000]: Train loss: 1.1720, Valid loss: 0.9155\n",
      "Epoch [293/3000]: Train loss: 1.1616, Valid loss: 0.8545\n",
      "Epoch [294/3000]: Train loss: 1.1730, Valid loss: 1.1040\n",
      "Epoch [295/3000]: Train loss: 1.1730, Valid loss: 1.0026\n",
      "Epoch [296/3000]: Train loss: 1.1719, Valid loss: 0.9357\n",
      "Epoch [297/3000]: Train loss: 1.1639, Valid loss: 1.0013\n",
      "Epoch [298/3000]: Train loss: 1.1914, Valid loss: 0.8778\n",
      "Epoch [299/3000]: Train loss: 1.1982, Valid loss: 0.9496\n",
      "Epoch [300/3000]: Train loss: 1.1735, Valid loss: 1.2224\n",
      "Epoch [301/3000]: Train loss: 1.1924, Valid loss: 1.0359\n",
      "Epoch [302/3000]: Train loss: 1.2138, Valid loss: 0.9474\n",
      "Epoch [303/3000]: Train loss: 1.1777, Valid loss: 1.0344\n",
      "Epoch [304/3000]: Train loss: 1.1837, Valid loss: 1.1137\n",
      "Epoch [305/3000]: Train loss: 1.2064, Valid loss: 1.0736\n",
      "Epoch [306/3000]: Train loss: 1.2128, Valid loss: 1.1023\n",
      "Epoch [307/3000]: Train loss: 1.2075, Valid loss: 0.9211\n",
      "Epoch [308/3000]: Train loss: 1.1810, Valid loss: 0.9335\n",
      "Epoch [309/3000]: Train loss: 1.2009, Valid loss: 0.9604\n",
      "Epoch [310/3000]: Train loss: 1.2154, Valid loss: 0.9301\n",
      "Epoch [311/3000]: Train loss: 1.2317, Valid loss: 1.1167\n",
      "Epoch [312/3000]: Train loss: 1.2125, Valid loss: 0.9705\n",
      "Epoch [313/3000]: Train loss: 1.2151, Valid loss: 0.9373\n",
      "Epoch [314/3000]: Train loss: 1.2209, Valid loss: 1.1193\n",
      "Epoch [315/3000]: Train loss: 1.1579, Valid loss: 1.1062\n",
      "Epoch [316/3000]: Train loss: 1.1632, Valid loss: 1.0113\n",
      "Epoch [317/3000]: Train loss: 1.1761, Valid loss: 1.1184\n",
      "Epoch [318/3000]: Train loss: 1.1831, Valid loss: 1.0047\n",
      "Epoch [319/3000]: Train loss: 1.1766, Valid loss: 1.1820\n",
      "Epoch [320/3000]: Train loss: 1.1762, Valid loss: 0.9529\n",
      "Epoch [321/3000]: Train loss: 1.1500, Valid loss: 0.9854\n",
      "Epoch [322/3000]: Train loss: 1.2128, Valid loss: 0.8678\n",
      "Epoch [323/3000]: Train loss: 1.1869, Valid loss: 0.9120\n",
      "Epoch [324/3000]: Train loss: 1.2045, Valid loss: 1.0112\n",
      "Epoch [325/3000]: Train loss: 1.1979, Valid loss: 1.2303\n",
      "Epoch [326/3000]: Train loss: 1.2140, Valid loss: 0.8856\n",
      "Epoch [327/3000]: Train loss: 1.1809, Valid loss: 0.8204\n",
      "Epoch [328/3000]: Train loss: 1.1541, Valid loss: 0.9134\n",
      "Epoch [329/3000]: Train loss: 1.1867, Valid loss: 1.0362\n",
      "Epoch [330/3000]: Train loss: 1.1694, Valid loss: 0.8670\n",
      "Epoch [331/3000]: Train loss: 1.1600, Valid loss: 0.9860\n",
      "Epoch [332/3000]: Train loss: 1.1520, Valid loss: 0.9929\n",
      "Epoch [333/3000]: Train loss: 1.1887, Valid loss: 1.1480\n",
      "Epoch [334/3000]: Train loss: 1.1841, Valid loss: 0.8093\n",
      "Epoch [335/3000]: Train loss: 1.1617, Valid loss: 0.8825\n",
      "Epoch [336/3000]: Train loss: 1.1777, Valid loss: 0.8569\n",
      "Epoch [337/3000]: Train loss: 1.1958, Valid loss: 1.0212\n",
      "Epoch [338/3000]: Train loss: 1.2330, Valid loss: 0.8516\n",
      "Epoch [339/3000]: Train loss: 1.1563, Valid loss: 0.9572\n",
      "Epoch [340/3000]: Train loss: 1.1703, Valid loss: 0.9342\n",
      "Epoch [341/3000]: Train loss: 1.1644, Valid loss: 1.0679\n",
      "Epoch [342/3000]: Train loss: 1.1682, Valid loss: 0.8622\n",
      "Epoch [343/3000]: Train loss: 1.1633, Valid loss: 1.1936\n",
      "Epoch [344/3000]: Train loss: 1.1826, Valid loss: 0.9455\n",
      "Epoch [345/3000]: Train loss: 1.2266, Valid loss: 0.9804\n",
      "Epoch [346/3000]: Train loss: 1.1933, Valid loss: 1.1187\n",
      "Epoch [347/3000]: Train loss: 1.1949, Valid loss: 0.8604\n",
      "Epoch [348/3000]: Train loss: 1.1761, Valid loss: 0.9818\n",
      "Epoch [349/3000]: Train loss: 1.1582, Valid loss: 1.1048\n",
      "Epoch [350/3000]: Train loss: 1.1960, Valid loss: 0.8360\n",
      "Epoch [351/3000]: Train loss: 1.1500, Valid loss: 0.9996\n",
      "Epoch [352/3000]: Train loss: 1.1823, Valid loss: 1.0902\n",
      "Epoch [353/3000]: Train loss: 1.1793, Valid loss: 0.9821\n",
      "Epoch [354/3000]: Train loss: 1.1913, Valid loss: 1.0453\n",
      "Epoch [355/3000]: Train loss: 1.1588, Valid loss: 0.8440\n",
      "Epoch [356/3000]: Train loss: 1.1655, Valid loss: 1.1163\n",
      "Epoch [357/3000]: Train loss: 1.1720, Valid loss: 0.8056\n",
      "Saving model with loss 0.806...\n",
      "Epoch [358/3000]: Train loss: 1.1636, Valid loss: 0.9273\n",
      "Epoch [359/3000]: Train loss: 1.1531, Valid loss: 0.9374\n",
      "Epoch [360/3000]: Train loss: 1.2007, Valid loss: 0.9048\n",
      "Epoch [361/3000]: Train loss: 1.1944, Valid loss: 1.1758\n",
      "Epoch [362/3000]: Train loss: 1.1575, Valid loss: 0.8983\n",
      "Epoch [363/3000]: Train loss: 1.1746, Valid loss: 0.8237\n",
      "Epoch [364/3000]: Train loss: 1.1631, Valid loss: 0.9880\n",
      "Epoch [365/3000]: Train loss: 1.1814, Valid loss: 0.9223\n",
      "Epoch [366/3000]: Train loss: 1.1711, Valid loss: 0.8878\n",
      "Epoch [367/3000]: Train loss: 1.1740, Valid loss: 1.0130\n",
      "Epoch [368/3000]: Train loss: 1.1910, Valid loss: 0.9796\n",
      "Epoch [369/3000]: Train loss: 1.1998, Valid loss: 0.8276\n",
      "Epoch [370/3000]: Train loss: 1.1998, Valid loss: 0.8264\n",
      "Epoch [371/3000]: Train loss: 1.1557, Valid loss: 0.9364\n",
      "Epoch [372/3000]: Train loss: 1.1800, Valid loss: 0.8739\n",
      "Epoch [373/3000]: Train loss: 1.1637, Valid loss: 1.0879\n",
      "Epoch [374/3000]: Train loss: 1.1553, Valid loss: 0.9476\n",
      "Epoch [375/3000]: Train loss: 1.1618, Valid loss: 0.8433\n",
      "Epoch [376/3000]: Train loss: 1.1532, Valid loss: 1.1077\n",
      "Epoch [377/3000]: Train loss: 1.1827, Valid loss: 1.1468\n",
      "Epoch [378/3000]: Train loss: 1.1624, Valid loss: 0.8975\n",
      "Epoch [379/3000]: Train loss: 1.1586, Valid loss: 0.8510\n",
      "Epoch [380/3000]: Train loss: 1.1491, Valid loss: 0.9494\n",
      "Epoch [381/3000]: Train loss: 1.2012, Valid loss: 0.8761\n",
      "Epoch [382/3000]: Train loss: 1.1521, Valid loss: 0.9944\n",
      "Epoch [383/3000]: Train loss: 1.1722, Valid loss: 0.9107\n",
      "Epoch [384/3000]: Train loss: 1.2062, Valid loss: 1.1045\n",
      "Epoch [385/3000]: Train loss: 1.2950, Valid loss: 0.8699\n",
      "Epoch [386/3000]: Train loss: 1.2168, Valid loss: 0.9591\n",
      "Epoch [387/3000]: Train loss: 1.1913, Valid loss: 0.9421\n",
      "Epoch [388/3000]: Train loss: 1.1958, Valid loss: 1.0812\n",
      "Epoch [389/3000]: Train loss: 1.1693, Valid loss: 0.9201\n",
      "Epoch [390/3000]: Train loss: 1.1510, Valid loss: 0.8235\n",
      "Epoch [391/3000]: Train loss: 1.1614, Valid loss: 1.0447\n",
      "Epoch [392/3000]: Train loss: 1.1816, Valid loss: 1.0824\n",
      "Epoch [393/3000]: Train loss: 1.1958, Valid loss: 0.8712\n",
      "Epoch [394/3000]: Train loss: 1.1699, Valid loss: 0.8232\n",
      "Epoch [395/3000]: Train loss: 1.1945, Valid loss: 1.0189\n",
      "Epoch [396/3000]: Train loss: 1.2012, Valid loss: 1.0694\n",
      "Epoch [397/3000]: Train loss: 1.1522, Valid loss: 1.1090\n",
      "Epoch [398/3000]: Train loss: 1.1610, Valid loss: 0.9288\n",
      "Epoch [399/3000]: Train loss: 1.1515, Valid loss: 0.9344\n",
      "Epoch [400/3000]: Train loss: 1.1678, Valid loss: 0.9924\n",
      "Epoch [401/3000]: Train loss: 1.1684, Valid loss: 0.9480\n",
      "Epoch [402/3000]: Train loss: 1.1473, Valid loss: 1.0098\n",
      "Epoch [403/3000]: Train loss: 1.1621, Valid loss: 0.8894\n",
      "Epoch [404/3000]: Train loss: 1.2205, Valid loss: 1.0438\n",
      "Epoch [405/3000]: Train loss: 1.1578, Valid loss: 0.8640\n",
      "Epoch [406/3000]: Train loss: 1.1578, Valid loss: 1.0530\n",
      "Epoch [407/3000]: Train loss: 1.1585, Valid loss: 0.9129\n",
      "Epoch [408/3000]: Train loss: 1.1569, Valid loss: 0.8656\n",
      "Epoch [409/3000]: Train loss: 1.1886, Valid loss: 1.0001\n",
      "Epoch [410/3000]: Train loss: 1.1471, Valid loss: 0.8801\n",
      "Epoch [411/3000]: Train loss: 1.1551, Valid loss: 1.1439\n",
      "Epoch [412/3000]: Train loss: 1.1482, Valid loss: 0.8078\n",
      "Epoch [413/3000]: Train loss: 1.1803, Valid loss: 0.8955\n",
      "Epoch [414/3000]: Train loss: 1.1659, Valid loss: 1.1279\n",
      "Epoch [415/3000]: Train loss: 1.1837, Valid loss: 0.8722\n",
      "Epoch [416/3000]: Train loss: 1.1548, Valid loss: 1.1430\n",
      "Epoch [417/3000]: Train loss: 1.1671, Valid loss: 0.9541\n",
      "Epoch [418/3000]: Train loss: 1.1540, Valid loss: 0.9779\n",
      "Epoch [419/3000]: Train loss: 1.1347, Valid loss: 0.8281\n",
      "Epoch [420/3000]: Train loss: 1.1651, Valid loss: 0.9577\n",
      "Epoch [421/3000]: Train loss: 1.1412, Valid loss: 0.8961\n",
      "Epoch [422/3000]: Train loss: 1.1422, Valid loss: 0.8575\n",
      "Epoch [423/3000]: Train loss: 1.1428, Valid loss: 0.8578\n",
      "Epoch [424/3000]: Train loss: 1.1952, Valid loss: 0.8985\n",
      "Epoch [425/3000]: Train loss: 1.1642, Valid loss: 0.9408\n",
      "Epoch [426/3000]: Train loss: 1.1557, Valid loss: 0.8710\n",
      "Epoch [427/3000]: Train loss: 1.1458, Valid loss: 0.9730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [428/3000]: Train loss: 1.1639, Valid loss: 0.8716\n",
      "Epoch [429/3000]: Train loss: 1.1570, Valid loss: 1.1343\n",
      "Epoch [430/3000]: Train loss: 1.1425, Valid loss: 1.1223\n",
      "Epoch [431/3000]: Train loss: 1.1936, Valid loss: 0.8479\n",
      "Epoch [432/3000]: Train loss: 1.1355, Valid loss: 0.9587\n",
      "Epoch [433/3000]: Train loss: 1.1730, Valid loss: 0.7816\n",
      "Saving model with loss 0.782...\n",
      "Epoch [434/3000]: Train loss: 1.1447, Valid loss: 0.9482\n",
      "Epoch [435/3000]: Train loss: 1.1397, Valid loss: 0.8683\n",
      "Epoch [436/3000]: Train loss: 1.1424, Valid loss: 0.8746\n",
      "Epoch [437/3000]: Train loss: 1.1539, Valid loss: 1.0466\n",
      "Epoch [438/3000]: Train loss: 1.1605, Valid loss: 1.0052\n",
      "Epoch [439/3000]: Train loss: 1.2058, Valid loss: 0.8418\n",
      "Epoch [440/3000]: Train loss: 1.1666, Valid loss: 0.8824\n",
      "Epoch [441/3000]: Train loss: 1.1726, Valid loss: 0.8475\n",
      "Epoch [442/3000]: Train loss: 1.1476, Valid loss: 0.8234\n",
      "Epoch [443/3000]: Train loss: 1.1859, Valid loss: 0.9570\n",
      "Epoch [444/3000]: Train loss: 1.1999, Valid loss: 0.8759\n",
      "Epoch [445/3000]: Train loss: 1.1991, Valid loss: 0.8750\n",
      "Epoch [446/3000]: Train loss: 1.1916, Valid loss: 1.1007\n",
      "Epoch [447/3000]: Train loss: 1.2000, Valid loss: 0.9345\n",
      "Epoch [448/3000]: Train loss: 1.1921, Valid loss: 0.9977\n",
      "Epoch [449/3000]: Train loss: 1.1628, Valid loss: 0.8120\n",
      "Epoch [450/3000]: Train loss: 1.1252, Valid loss: 0.9607\n",
      "Epoch [451/3000]: Train loss: 1.1298, Valid loss: 0.8742\n",
      "Epoch [452/3000]: Train loss: 1.1968, Valid loss: 0.9666\n",
      "Epoch [453/3000]: Train loss: 1.1470, Valid loss: 0.9796\n",
      "Epoch [454/3000]: Train loss: 1.1498, Valid loss: 0.7663\n",
      "Saving model with loss 0.766...\n",
      "Epoch [455/3000]: Train loss: 1.1657, Valid loss: 0.9932\n",
      "Epoch [456/3000]: Train loss: 1.1472, Valid loss: 1.1026\n",
      "Epoch [457/3000]: Train loss: 1.1567, Valid loss: 1.0208\n",
      "Epoch [458/3000]: Train loss: 1.1511, Valid loss: 0.8226\n",
      "Epoch [459/3000]: Train loss: 1.1444, Valid loss: 1.1376\n",
      "Epoch [460/3000]: Train loss: 1.1530, Valid loss: 0.9970\n",
      "Epoch [461/3000]: Train loss: 1.1840, Valid loss: 0.9506\n",
      "Epoch [462/3000]: Train loss: 1.1427, Valid loss: 0.8934\n",
      "Epoch [463/3000]: Train loss: 1.1387, Valid loss: 1.0507\n",
      "Epoch [464/3000]: Train loss: 1.1499, Valid loss: 1.0153\n",
      "Epoch [465/3000]: Train loss: 1.1841, Valid loss: 0.9343\n",
      "Epoch [466/3000]: Train loss: 1.1737, Valid loss: 0.7937\n",
      "Epoch [467/3000]: Train loss: 1.1522, Valid loss: 0.9340\n",
      "Epoch [468/3000]: Train loss: 1.1418, Valid loss: 0.8296\n",
      "Epoch [469/3000]: Train loss: 1.1510, Valid loss: 1.0497\n",
      "Epoch [470/3000]: Train loss: 1.1798, Valid loss: 0.8249\n",
      "Epoch [471/3000]: Train loss: 1.1378, Valid loss: 0.7909\n",
      "Epoch [472/3000]: Train loss: 1.1705, Valid loss: 0.8649\n",
      "Epoch [473/3000]: Train loss: 1.1610, Valid loss: 1.0098\n",
      "Epoch [474/3000]: Train loss: 1.1214, Valid loss: 0.8150\n",
      "Epoch [475/3000]: Train loss: 1.1734, Valid loss: 0.8867\n",
      "Epoch [476/3000]: Train loss: 1.1499, Valid loss: 0.8288\n",
      "Epoch [477/3000]: Train loss: 1.1456, Valid loss: 1.1020\n",
      "Epoch [478/3000]: Train loss: 1.1500, Valid loss: 1.0016\n",
      "Epoch [479/3000]: Train loss: 1.1590, Valid loss: 0.8891\n",
      "Epoch [480/3000]: Train loss: 1.1726, Valid loss: 0.9245\n",
      "Epoch [481/3000]: Train loss: 1.1660, Valid loss: 1.0488\n",
      "Epoch [482/3000]: Train loss: 1.1584, Valid loss: 1.0140\n",
      "Epoch [483/3000]: Train loss: 1.1534, Valid loss: 0.7608\n",
      "Saving model with loss 0.761...\n",
      "Epoch [484/3000]: Train loss: 1.1628, Valid loss: 0.9236\n",
      "Epoch [485/3000]: Train loss: 1.1402, Valid loss: 0.8580\n",
      "Epoch [486/3000]: Train loss: 1.1582, Valid loss: 0.9551\n",
      "Epoch [487/3000]: Train loss: 1.1478, Valid loss: 1.1268\n",
      "Epoch [488/3000]: Train loss: 1.1814, Valid loss: 0.8862\n",
      "Epoch [489/3000]: Train loss: 1.1354, Valid loss: 0.8306\n",
      "Epoch [490/3000]: Train loss: 1.1759, Valid loss: 0.8918\n",
      "Epoch [491/3000]: Train loss: 1.1697, Valid loss: 0.9336\n",
      "Epoch [492/3000]: Train loss: 1.1720, Valid loss: 0.8779\n",
      "Epoch [493/3000]: Train loss: 1.1728, Valid loss: 0.9252\n",
      "Epoch [494/3000]: Train loss: 1.1310, Valid loss: 0.9349\n",
      "Epoch [495/3000]: Train loss: 1.1371, Valid loss: 0.9599\n",
      "Epoch [496/3000]: Train loss: 1.1624, Valid loss: 0.8524\n",
      "Epoch [497/3000]: Train loss: 1.1439, Valid loss: 0.8257\n",
      "Epoch [498/3000]: Train loss: 1.1272, Valid loss: 0.9872\n",
      "Epoch [499/3000]: Train loss: 1.1555, Valid loss: 0.9014\n",
      "Epoch [500/3000]: Train loss: 1.1675, Valid loss: 0.8760\n",
      "Epoch [501/3000]: Train loss: 1.1882, Valid loss: 1.1291\n",
      "Epoch [502/3000]: Train loss: 1.1437, Valid loss: 1.1376\n",
      "Epoch [503/3000]: Train loss: 1.1289, Valid loss: 0.9546\n",
      "Epoch [504/3000]: Train loss: 1.1608, Valid loss: 1.0095\n",
      "Epoch [505/3000]: Train loss: 1.1486, Valid loss: 1.0956\n",
      "Epoch [506/3000]: Train loss: 1.1528, Valid loss: 0.7774\n",
      "Epoch [507/3000]: Train loss: 1.1415, Valid loss: 0.9773\n",
      "Epoch [508/3000]: Train loss: 1.1405, Valid loss: 0.7164\n",
      "Saving model with loss 0.716...\n",
      "Epoch [509/3000]: Train loss: 1.1501, Valid loss: 0.8896\n",
      "Epoch [510/3000]: Train loss: 1.1888, Valid loss: 1.2379\n",
      "Epoch [511/3000]: Train loss: 1.1368, Valid loss: 0.9661\n",
      "Epoch [512/3000]: Train loss: 1.1315, Valid loss: 1.1234\n",
      "Epoch [513/3000]: Train loss: 1.1653, Valid loss: 0.9766\n",
      "Epoch [514/3000]: Train loss: 1.1373, Valid loss: 0.9673\n",
      "Epoch [515/3000]: Train loss: 1.1222, Valid loss: 0.8982\n",
      "Epoch [516/3000]: Train loss: 1.1559, Valid loss: 0.9994\n",
      "Epoch [517/3000]: Train loss: 1.1677, Valid loss: 0.9111\n",
      "Epoch [518/3000]: Train loss: 1.2026, Valid loss: 0.8543\n",
      "Epoch [519/3000]: Train loss: 1.2102, Valid loss: 1.0024\n",
      "Epoch [520/3000]: Train loss: 1.1742, Valid loss: 0.9142\n",
      "Epoch [521/3000]: Train loss: 1.1446, Valid loss: 0.8896\n",
      "Epoch [522/3000]: Train loss: 1.1586, Valid loss: 0.7820\n",
      "Epoch [523/3000]: Train loss: 1.1314, Valid loss: 0.9052\n",
      "Epoch [524/3000]: Train loss: 1.1450, Valid loss: 0.9776\n",
      "Epoch [525/3000]: Train loss: 1.1257, Valid loss: 1.0083\n",
      "Epoch [526/3000]: Train loss: 1.1436, Valid loss: 0.9771\n",
      "Epoch [527/3000]: Train loss: 1.1393, Valid loss: 1.0333\n",
      "Epoch [528/3000]: Train loss: 1.1677, Valid loss: 0.7949\n",
      "Epoch [529/3000]: Train loss: 1.2063, Valid loss: 1.0167\n",
      "Epoch [530/3000]: Train loss: 1.1615, Valid loss: 0.9105\n",
      "Epoch [531/3000]: Train loss: 1.1457, Valid loss: 1.1377\n",
      "Epoch [532/3000]: Train loss: 1.1532, Valid loss: 0.9227\n",
      "Epoch [533/3000]: Train loss: 1.1257, Valid loss: 1.0275\n",
      "Epoch [534/3000]: Train loss: 1.1414, Valid loss: 0.9185\n",
      "Epoch [535/3000]: Train loss: 1.1730, Valid loss: 1.0651\n",
      "Epoch [536/3000]: Train loss: 1.1524, Valid loss: 0.9803\n",
      "Epoch [537/3000]: Train loss: 1.1761, Valid loss: 1.0056\n",
      "Epoch [538/3000]: Train loss: 1.1694, Valid loss: 0.9511\n",
      "Epoch [539/3000]: Train loss: 1.1528, Valid loss: 0.8339\n",
      "Epoch [540/3000]: Train loss: 1.1566, Valid loss: 0.9468\n",
      "Epoch [541/3000]: Train loss: 1.1952, Valid loss: 1.1107\n",
      "Epoch [542/3000]: Train loss: 1.1544, Valid loss: 0.7917\n",
      "Epoch [543/3000]: Train loss: 1.1719, Valid loss: 0.8687\n",
      "Epoch [544/3000]: Train loss: 1.1450, Valid loss: 1.4553\n",
      "Epoch [545/3000]: Train loss: 1.1713, Valid loss: 0.8741\n",
      "Epoch [546/3000]: Train loss: 1.1631, Valid loss: 0.8164\n",
      "Epoch [547/3000]: Train loss: 1.1905, Valid loss: 0.8370\n",
      "Epoch [548/3000]: Train loss: 1.1584, Valid loss: 1.0427\n",
      "Epoch [549/3000]: Train loss: 1.1597, Valid loss: 1.1355\n",
      "Epoch [550/3000]: Train loss: 1.1644, Valid loss: 0.9031\n",
      "Epoch [551/3000]: Train loss: 1.1930, Valid loss: 0.8511\n",
      "Epoch [552/3000]: Train loss: 1.1837, Valid loss: 0.9652\n",
      "Epoch [553/3000]: Train loss: 1.2841, Valid loss: 1.4210\n",
      "Epoch [554/3000]: Train loss: 1.3266, Valid loss: 0.8550\n",
      "Epoch [555/3000]: Train loss: 1.1966, Valid loss: 0.9558\n",
      "Epoch [556/3000]: Train loss: 1.1693, Valid loss: 1.0588\n",
      "Epoch [557/3000]: Train loss: 1.1927, Valid loss: 1.0326\n",
      "Epoch [558/3000]: Train loss: 1.1848, Valid loss: 0.9157\n",
      "Epoch [559/3000]: Train loss: 1.2090, Valid loss: 0.9120\n",
      "Epoch [560/3000]: Train loss: 1.1336, Valid loss: 1.1566\n",
      "Epoch [561/3000]: Train loss: 1.1812, Valid loss: 0.7933\n",
      "Epoch [562/3000]: Train loss: 1.1497, Valid loss: 1.1031\n",
      "Epoch [563/3000]: Train loss: 1.2129, Valid loss: 0.9439\n",
      "Epoch [564/3000]: Train loss: 1.1596, Valid loss: 1.0083\n",
      "Epoch [565/3000]: Train loss: 1.1950, Valid loss: 0.9115\n",
      "Epoch [566/3000]: Train loss: 1.2422, Valid loss: 1.0896\n",
      "Epoch [567/3000]: Train loss: 1.1990, Valid loss: 0.8532\n",
      "Epoch [568/3000]: Train loss: 1.1803, Valid loss: 0.8192\n",
      "Epoch [569/3000]: Train loss: 1.1536, Valid loss: 0.8898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [570/3000]: Train loss: 1.1739, Valid loss: 0.9579\n",
      "Epoch [571/3000]: Train loss: 1.1474, Valid loss: 0.7899\n",
      "Epoch [572/3000]: Train loss: 1.1573, Valid loss: 0.8586\n",
      "Epoch [573/3000]: Train loss: 1.1379, Valid loss: 0.8011\n",
      "Epoch [574/3000]: Train loss: 1.1588, Valid loss: 0.8610\n",
      "Epoch [575/3000]: Train loss: 1.2160, Valid loss: 1.1477\n",
      "Epoch [576/3000]: Train loss: 1.1451, Valid loss: 1.2080\n",
      "Epoch [577/3000]: Train loss: 1.1316, Valid loss: 0.9133\n",
      "Epoch [578/3000]: Train loss: 1.1765, Valid loss: 0.8113\n",
      "Epoch [579/3000]: Train loss: 1.1435, Valid loss: 0.8451\n",
      "Epoch [580/3000]: Train loss: 1.1493, Valid loss: 0.9350\n",
      "Epoch [581/3000]: Train loss: 1.1360, Valid loss: 0.9970\n",
      "Epoch [582/3000]: Train loss: 1.1375, Valid loss: 1.1525\n",
      "Epoch [583/3000]: Train loss: 1.1513, Valid loss: 1.1626\n",
      "Epoch [584/3000]: Train loss: 1.1742, Valid loss: 0.9645\n",
      "Epoch [585/3000]: Train loss: 1.1287, Valid loss: 0.8672\n",
      "Epoch [586/3000]: Train loss: 1.1355, Valid loss: 0.8308\n",
      "Epoch [587/3000]: Train loss: 1.1517, Valid loss: 0.7857\n",
      "Epoch [588/3000]: Train loss: 1.1351, Valid loss: 0.9355\n",
      "Epoch [589/3000]: Train loss: 1.1779, Valid loss: 0.9719\n",
      "Epoch [590/3000]: Train loss: 1.1433, Valid loss: 0.8878\n",
      "Epoch [591/3000]: Train loss: 1.1660, Valid loss: 1.1351\n",
      "Epoch [592/3000]: Train loss: 1.2007, Valid loss: 0.8376\n",
      "Epoch [593/3000]: Train loss: 1.1656, Valid loss: 1.0201\n",
      "Epoch [594/3000]: Train loss: 1.1790, Valid loss: 0.8729\n",
      "Epoch [595/3000]: Train loss: 1.1513, Valid loss: 0.9148\n",
      "Epoch [596/3000]: Train loss: 1.1595, Valid loss: 0.9548\n",
      "Epoch [597/3000]: Train loss: 1.1719, Valid loss: 0.9150\n",
      "Epoch [598/3000]: Train loss: 1.1488, Valid loss: 0.9056\n",
      "Epoch [599/3000]: Train loss: 1.1689, Valid loss: 0.9472\n",
      "Epoch [600/3000]: Train loss: 1.1692, Valid loss: 1.0143\n",
      "Epoch [601/3000]: Train loss: 1.1605, Valid loss: 0.9288\n",
      "Epoch [602/3000]: Train loss: 1.1581, Valid loss: 1.0620\n",
      "Epoch [603/3000]: Train loss: 1.1596, Valid loss: 0.8914\n",
      "Epoch [604/3000]: Train loss: 1.1583, Valid loss: 0.8533\n",
      "Epoch [605/3000]: Train loss: 1.1403, Valid loss: 0.8016\n",
      "Epoch [606/3000]: Train loss: 1.1857, Valid loss: 1.0006\n",
      "Epoch [607/3000]: Train loss: 1.1874, Valid loss: 1.0841\n",
      "Epoch [608/3000]: Train loss: 1.2297, Valid loss: 0.8362\n",
      "Epoch [609/3000]: Train loss: 1.1601, Valid loss: 1.0667\n",
      "Epoch [610/3000]: Train loss: 1.1881, Valid loss: 0.9080\n",
      "Epoch [611/3000]: Train loss: 1.1207, Valid loss: 0.8799\n",
      "Epoch [612/3000]: Train loss: 1.1273, Valid loss: 0.9171\n",
      "Epoch [613/3000]: Train loss: 1.1570, Valid loss: 0.9699\n",
      "Epoch [614/3000]: Train loss: 1.1402, Valid loss: 0.9281\n",
      "Epoch [615/3000]: Train loss: 1.1560, Valid loss: 0.9437\n",
      "Epoch [616/3000]: Train loss: 1.1786, Valid loss: 1.1427\n",
      "Epoch [617/3000]: Train loss: 1.2019, Valid loss: 0.9721\n",
      "Epoch [618/3000]: Train loss: 1.1371, Valid loss: 0.9339\n",
      "Epoch [619/3000]: Train loss: 1.1773, Valid loss: 1.0097\n",
      "Epoch [620/3000]: Train loss: 1.1759, Valid loss: 1.0680\n",
      "Epoch [621/3000]: Train loss: 1.1880, Valid loss: 0.8635\n",
      "Epoch [622/3000]: Train loss: 1.1541, Valid loss: 0.9543\n",
      "Epoch [623/3000]: Train loss: 1.1353, Valid loss: 0.9974\n",
      "Epoch [624/3000]: Train loss: 1.1433, Valid loss: 0.9358\n",
      "Epoch [625/3000]: Train loss: 1.1544, Valid loss: 1.1608\n",
      "Epoch [626/3000]: Train loss: 1.1531, Valid loss: 0.9474\n",
      "Epoch [627/3000]: Train loss: 1.1954, Valid loss: 0.9561\n",
      "Epoch [628/3000]: Train loss: 1.1846, Valid loss: 0.8655\n",
      "Epoch [629/3000]: Train loss: 1.1777, Valid loss: 1.0239\n",
      "Epoch [630/3000]: Train loss: 1.1736, Valid loss: 0.9787\n",
      "Epoch [631/3000]: Train loss: 1.1551, Valid loss: 1.0828\n",
      "Epoch [632/3000]: Train loss: 1.1572, Valid loss: 1.2528\n",
      "Epoch [633/3000]: Train loss: 1.2467, Valid loss: 0.8766\n",
      "Epoch [634/3000]: Train loss: 1.1527, Valid loss: 0.8875\n",
      "Epoch [635/3000]: Train loss: 1.1829, Valid loss: 0.9047\n",
      "Epoch [636/3000]: Train loss: 1.1855, Valid loss: 0.9124\n",
      "Epoch [637/3000]: Train loss: 1.1476, Valid loss: 0.8716\n",
      "Epoch [638/3000]: Train loss: 1.1422, Valid loss: 0.8432\n",
      "Epoch [639/3000]: Train loss: 1.1352, Valid loss: 0.9486\n",
      "Epoch [640/3000]: Train loss: 1.1580, Valid loss: 1.0256\n",
      "Epoch [641/3000]: Train loss: 1.1874, Valid loss: 1.0961\n",
      "Epoch [642/3000]: Train loss: 1.2083, Valid loss: 0.8406\n",
      "Epoch [643/3000]: Train loss: 1.1858, Valid loss: 0.9696\n",
      "Epoch [644/3000]: Train loss: 1.1493, Valid loss: 0.9469\n",
      "Epoch [645/3000]: Train loss: 1.1710, Valid loss: 0.9190\n",
      "Epoch [646/3000]: Train loss: 1.1425, Valid loss: 0.9558\n",
      "Epoch [647/3000]: Train loss: 1.1618, Valid loss: 0.9226\n",
      "Epoch [648/3000]: Train loss: 1.1710, Valid loss: 0.9979\n",
      "Epoch [649/3000]: Train loss: 1.1815, Valid loss: 1.0764\n",
      "Epoch [650/3000]: Train loss: 1.1531, Valid loss: 1.0639\n",
      "Epoch [651/3000]: Train loss: 1.1639, Valid loss: 1.0828\n",
      "Epoch [652/3000]: Train loss: 1.2306, Valid loss: 0.9553\n",
      "Epoch [653/3000]: Train loss: 1.1738, Valid loss: 1.0082\n",
      "Epoch [654/3000]: Train loss: 1.2024, Valid loss: 0.8493\n",
      "Epoch [655/3000]: Train loss: 1.1724, Valid loss: 0.9430\n",
      "Epoch [656/3000]: Train loss: 1.1443, Valid loss: 0.8369\n",
      "Epoch [657/3000]: Train loss: 1.1550, Valid loss: 0.8786\n",
      "Epoch [658/3000]: Train loss: 1.1495, Valid loss: 0.8222\n",
      "Epoch [659/3000]: Train loss: 1.1410, Valid loss: 1.0992\n",
      "Epoch [660/3000]: Train loss: 1.1446, Valid loss: 0.9309\n",
      "Epoch [661/3000]: Train loss: 1.1446, Valid loss: 0.8181\n",
      "Epoch [662/3000]: Train loss: 1.1537, Valid loss: 0.8775\n",
      "Epoch [663/3000]: Train loss: 1.1342, Valid loss: 0.9811\n",
      "Epoch [664/3000]: Train loss: 1.1617, Valid loss: 0.8932\n",
      "Epoch [665/3000]: Train loss: 1.1201, Valid loss: 0.7999\n",
      "Epoch [666/3000]: Train loss: 1.1215, Valid loss: 0.8220\n",
      "Epoch [667/3000]: Train loss: 1.1300, Valid loss: 0.8526\n",
      "Epoch [668/3000]: Train loss: 1.1708, Valid loss: 0.8795\n",
      "Epoch [669/3000]: Train loss: 1.1605, Valid loss: 0.8550\n",
      "Epoch [670/3000]: Train loss: 1.1636, Valid loss: 0.8925\n",
      "Epoch [671/3000]: Train loss: 1.1401, Valid loss: 0.9310\n",
      "Epoch [672/3000]: Train loss: 1.1446, Valid loss: 1.1336\n",
      "Epoch [673/3000]: Train loss: 1.1534, Valid loss: 0.8168\n",
      "Epoch [674/3000]: Train loss: 1.1359, Valid loss: 1.1182\n",
      "Epoch [675/3000]: Train loss: 1.1592, Valid loss: 0.9736\n",
      "Epoch [676/3000]: Train loss: 1.1466, Valid loss: 0.9669\n",
      "Epoch [677/3000]: Train loss: 1.1449, Valid loss: 1.1348\n",
      "Epoch [678/3000]: Train loss: 1.1606, Valid loss: 0.7892\n",
      "Epoch [679/3000]: Train loss: 1.1332, Valid loss: 0.9270\n",
      "Epoch [680/3000]: Train loss: 1.1257, Valid loss: 1.0711\n",
      "Epoch [681/3000]: Train loss: 1.1441, Valid loss: 0.9730\n",
      "Epoch [682/3000]: Train loss: 1.1493, Valid loss: 1.1454\n",
      "Epoch [683/3000]: Train loss: 1.1733, Valid loss: 0.9294\n",
      "Epoch [684/3000]: Train loss: 1.1481, Valid loss: 1.1290\n",
      "Epoch [685/3000]: Train loss: 1.1453, Valid loss: 1.2698\n",
      "Epoch [686/3000]: Train loss: 1.1594, Valid loss: 0.9295\n",
      "Epoch [687/3000]: Train loss: 1.1445, Valid loss: 0.9987\n",
      "Epoch [688/3000]: Train loss: 1.1386, Valid loss: 0.8384\n",
      "Epoch [689/3000]: Train loss: 1.1589, Valid loss: 0.8590\n",
      "Epoch [690/3000]: Train loss: 1.1767, Valid loss: 1.0277\n",
      "Epoch [691/3000]: Train loss: 1.1617, Valid loss: 1.0045\n",
      "Epoch [692/3000]: Train loss: 1.1456, Valid loss: 1.1839\n",
      "Epoch [693/3000]: Train loss: 1.1373, Valid loss: 0.9517\n",
      "Epoch [694/3000]: Train loss: 1.1589, Valid loss: 0.8026\n",
      "Epoch [695/3000]: Train loss: 1.1310, Valid loss: 0.8639\n",
      "Epoch [696/3000]: Train loss: 1.1915, Valid loss: 1.1207\n",
      "Epoch [697/3000]: Train loss: 1.1230, Valid loss: 0.9565\n",
      "Epoch [698/3000]: Train loss: 1.1398, Valid loss: 0.8616\n",
      "Epoch [699/3000]: Train loss: 1.1691, Valid loss: 0.9092\n",
      "Epoch [700/3000]: Train loss: 1.1737, Valid loss: 0.9212\n",
      "Epoch [701/3000]: Train loss: 1.1634, Valid loss: 0.8359\n",
      "Epoch [702/3000]: Train loss: 1.1517, Valid loss: 1.0735\n",
      "Epoch [703/3000]: Train loss: 1.1873, Valid loss: 0.9275\n",
      "Epoch [704/3000]: Train loss: 1.1575, Valid loss: 0.9291\n",
      "Epoch [705/3000]: Train loss: 1.1722, Valid loss: 1.0297\n",
      "Epoch [706/3000]: Train loss: 1.1390, Valid loss: 1.0323\n",
      "Epoch [707/3000]: Train loss: 1.1387, Valid loss: 0.9568\n",
      "Epoch [708/3000]: Train loss: 1.1865, Valid loss: 1.0210\n",
      "Epoch [709/3000]: Train loss: 1.2677, Valid loss: 0.7876\n",
      "Epoch [710/3000]: Train loss: 1.1985, Valid loss: 0.8527\n",
      "Epoch [711/3000]: Train loss: 1.1433, Valid loss: 0.9072\n",
      "Epoch [712/3000]: Train loss: 1.1396, Valid loss: 0.9418\n",
      "Epoch [713/3000]: Train loss: 1.1311, Valid loss: 0.8838\n",
      "Epoch [714/3000]: Train loss: 1.1507, Valid loss: 0.8869\n",
      "Epoch [715/3000]: Train loss: 1.1726, Valid loss: 0.8793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [716/3000]: Train loss: 1.1225, Valid loss: 1.1460\n",
      "Epoch [717/3000]: Train loss: 1.1621, Valid loss: 0.9682\n",
      "Epoch [718/3000]: Train loss: 1.1542, Valid loss: 0.9846\n",
      "Epoch [719/3000]: Train loss: 1.1451, Valid loss: 0.8285\n",
      "Epoch [720/3000]: Train loss: 1.1774, Valid loss: 0.9648\n",
      "Epoch [721/3000]: Train loss: 1.1334, Valid loss: 0.9975\n",
      "Epoch [722/3000]: Train loss: 1.1264, Valid loss: 0.8577\n",
      "Epoch [723/3000]: Train loss: 1.1527, Valid loss: 0.8252\n",
      "Epoch [724/3000]: Train loss: 1.1334, Valid loss: 0.9237\n",
      "Epoch [725/3000]: Train loss: 1.1529, Valid loss: 0.8799\n",
      "Epoch [726/3000]: Train loss: 1.1949, Valid loss: 0.9106\n",
      "Epoch [727/3000]: Train loss: 1.1473, Valid loss: 1.0626\n",
      "Epoch [728/3000]: Train loss: 1.1618, Valid loss: 0.9096\n",
      "Epoch [729/3000]: Train loss: 1.1758, Valid loss: 0.9746\n",
      "Epoch [730/3000]: Train loss: 1.1992, Valid loss: 0.9720\n",
      "Epoch [731/3000]: Train loss: 1.1768, Valid loss: 0.8592\n",
      "Epoch [732/3000]: Train loss: 1.1674, Valid loss: 1.0682\n",
      "Epoch [733/3000]: Train loss: 1.1427, Valid loss: 0.8672\n",
      "Epoch [734/3000]: Train loss: 1.1539, Valid loss: 0.9729\n",
      "Epoch [735/3000]: Train loss: 1.1531, Valid loss: 0.8295\n",
      "Epoch [736/3000]: Train loss: 1.1198, Valid loss: 0.9830\n",
      "Epoch [737/3000]: Train loss: 1.1384, Valid loss: 0.9621\n",
      "Epoch [738/3000]: Train loss: 1.1355, Valid loss: 0.8702\n",
      "Epoch [739/3000]: Train loss: 1.1541, Valid loss: 1.1866\n",
      "Epoch [740/3000]: Train loss: 1.1456, Valid loss: 0.8661\n",
      "Epoch [741/3000]: Train loss: 1.1493, Valid loss: 0.8258\n",
      "Epoch [742/3000]: Train loss: 1.1475, Valid loss: 0.9251\n",
      "Epoch [743/3000]: Train loss: 1.2051, Valid loss: 0.8752\n",
      "Epoch [744/3000]: Train loss: 1.1742, Valid loss: 0.9765\n",
      "Epoch [745/3000]: Train loss: 1.1632, Valid loss: 1.0989\n",
      "Epoch [746/3000]: Train loss: 1.1536, Valid loss: 1.0009\n",
      "Epoch [747/3000]: Train loss: 1.1913, Valid loss: 0.9267\n",
      "Epoch [748/3000]: Train loss: 1.1666, Valid loss: 0.9044\n",
      "Epoch [749/3000]: Train loss: 1.1232, Valid loss: 0.8784\n",
      "Epoch [750/3000]: Train loss: 1.1403, Valid loss: 0.8403\n",
      "Epoch [751/3000]: Train loss: 1.1373, Valid loss: 0.8334\n",
      "Epoch [752/3000]: Train loss: 1.1337, Valid loss: 0.9086\n",
      "Epoch [753/3000]: Train loss: 1.1463, Valid loss: 0.9520\n",
      "Epoch [754/3000]: Train loss: 1.1327, Valid loss: 0.8364\n",
      "Epoch [755/3000]: Train loss: 1.1518, Valid loss: 0.9862\n",
      "Epoch [756/3000]: Train loss: 1.2176, Valid loss: 0.9685\n",
      "Epoch [757/3000]: Train loss: 1.2016, Valid loss: 0.9688\n",
      "Epoch [758/3000]: Train loss: 1.2041, Valid loss: 0.8868\n",
      "Epoch [759/3000]: Train loss: 1.2249, Valid loss: 1.1906\n",
      "Epoch [760/3000]: Train loss: 1.2329, Valid loss: 0.9370\n",
      "Epoch [761/3000]: Train loss: 1.1951, Valid loss: 0.9926\n",
      "Epoch [762/3000]: Train loss: 1.1498, Valid loss: 0.8854\n",
      "Epoch [763/3000]: Train loss: 1.1638, Valid loss: 0.9851\n",
      "Epoch [764/3000]: Train loss: 1.1788, Valid loss: 1.0385\n",
      "Epoch [765/3000]: Train loss: 1.1639, Valid loss: 1.0421\n",
      "Epoch [766/3000]: Train loss: 1.2056, Valid loss: 0.9586\n",
      "Epoch [767/3000]: Train loss: 1.2165, Valid loss: 1.1970\n",
      "Epoch [768/3000]: Train loss: 1.2490, Valid loss: 0.9984\n",
      "Epoch [769/3000]: Train loss: 1.1669, Valid loss: 1.0984\n",
      "Epoch [770/3000]: Train loss: 1.1680, Valid loss: 0.9309\n",
      "Epoch [771/3000]: Train loss: 1.1341, Valid loss: 1.0146\n",
      "Epoch [772/3000]: Train loss: 1.1702, Valid loss: 0.9836\n",
      "Epoch [773/3000]: Train loss: 1.1531, Valid loss: 0.8806\n",
      "Epoch [774/3000]: Train loss: 1.1549, Valid loss: 0.9288\n",
      "Epoch [775/3000]: Train loss: 1.1770, Valid loss: 1.0534\n",
      "Epoch [776/3000]: Train loss: 1.1650, Valid loss: 1.0578\n",
      "Epoch [777/3000]: Train loss: 1.1367, Valid loss: 0.8644\n",
      "Epoch [778/3000]: Train loss: 1.1329, Valid loss: 0.7837\n",
      "Epoch [779/3000]: Train loss: 1.1399, Valid loss: 1.0684\n",
      "Epoch [780/3000]: Train loss: 1.1607, Valid loss: 1.1800\n",
      "Epoch [781/3000]: Train loss: 1.1311, Valid loss: 1.0540\n",
      "Epoch [782/3000]: Train loss: 1.1377, Valid loss: 1.1297\n",
      "Epoch [783/3000]: Train loss: 1.1529, Valid loss: 0.9846\n",
      "Epoch [784/3000]: Train loss: 1.1967, Valid loss: 0.8546\n",
      "Epoch [785/3000]: Train loss: 1.1543, Valid loss: 1.0887\n",
      "Epoch [786/3000]: Train loss: 1.1927, Valid loss: 0.9240\n",
      "Epoch [787/3000]: Train loss: 1.1723, Valid loss: 0.9840\n",
      "Epoch [788/3000]: Train loss: 1.1542, Valid loss: 0.8523\n",
      "Epoch [789/3000]: Train loss: 1.1557, Valid loss: 0.9417\n",
      "Epoch [790/3000]: Train loss: 1.1334, Valid loss: 0.8694\n",
      "Epoch [791/3000]: Train loss: 1.1658, Valid loss: 1.0009\n",
      "Epoch [792/3000]: Train loss: 1.1480, Valid loss: 0.8888\n",
      "Epoch [793/3000]: Train loss: 1.1273, Valid loss: 1.0837\n",
      "Epoch [794/3000]: Train loss: 1.1404, Valid loss: 0.9434\n",
      "Epoch [795/3000]: Train loss: 1.1640, Valid loss: 0.7442\n",
      "Epoch [796/3000]: Train loss: 1.1779, Valid loss: 0.9783\n",
      "Epoch [797/3000]: Train loss: 1.1497, Valid loss: 0.8836\n",
      "Epoch [798/3000]: Train loss: 1.1644, Valid loss: 0.9874\n",
      "Epoch [799/3000]: Train loss: 1.1314, Valid loss: 1.0066\n",
      "Epoch [800/3000]: Train loss: 1.1475, Valid loss: 0.8368\n",
      "Epoch [801/3000]: Train loss: 1.1427, Valid loss: 0.9107\n",
      "Epoch [802/3000]: Train loss: 1.1421, Valid loss: 0.9461\n",
      "Epoch [803/3000]: Train loss: 1.1377, Valid loss: 0.8258\n",
      "Epoch [804/3000]: Train loss: 1.1290, Valid loss: 0.8570\n",
      "Epoch [805/3000]: Train loss: 1.1817, Valid loss: 1.1160\n",
      "Epoch [806/3000]: Train loss: 1.2041, Valid loss: 1.0574\n",
      "Epoch [807/3000]: Train loss: 1.1715, Valid loss: 0.9882\n",
      "Epoch [808/3000]: Train loss: 1.1126, Valid loss: 0.9680\n",
      "Epoch [809/3000]: Train loss: 1.1333, Valid loss: 0.9352\n",
      "Epoch [810/3000]: Train loss: 1.1431, Valid loss: 0.9571\n",
      "Epoch [811/3000]: Train loss: 1.1706, Valid loss: 0.9990\n",
      "Epoch [812/3000]: Train loss: 1.1422, Valid loss: 0.9572\n",
      "Epoch [813/3000]: Train loss: 1.1664, Valid loss: 1.0680\n",
      "Epoch [814/3000]: Train loss: 1.1599, Valid loss: 0.7872\n",
      "Epoch [815/3000]: Train loss: 1.1750, Valid loss: 1.0850\n",
      "Epoch [816/3000]: Train loss: 1.2970, Valid loss: 1.1440\n",
      "Epoch [817/3000]: Train loss: 1.2253, Valid loss: 1.1880\n",
      "Epoch [818/3000]: Train loss: 1.2150, Valid loss: 0.8251\n",
      "Epoch [819/3000]: Train loss: 1.1238, Valid loss: 0.8432\n",
      "Epoch [820/3000]: Train loss: 1.1391, Valid loss: 0.8736\n",
      "Epoch [821/3000]: Train loss: 1.1634, Valid loss: 0.8360\n",
      "Epoch [822/3000]: Train loss: 1.2050, Valid loss: 1.1770\n",
      "Epoch [823/3000]: Train loss: 1.1868, Valid loss: 1.0175\n",
      "Epoch [824/3000]: Train loss: 1.1401, Valid loss: 0.9667\n",
      "Epoch [825/3000]: Train loss: 1.1711, Valid loss: 0.9022\n",
      "Epoch [826/3000]: Train loss: 1.1620, Valid loss: 0.9995\n",
      "Epoch [827/3000]: Train loss: 1.1937, Valid loss: 0.8607\n",
      "Epoch [828/3000]: Train loss: 1.1648, Valid loss: 1.0266\n",
      "Epoch [829/3000]: Train loss: 1.1388, Valid loss: 0.8616\n",
      "Epoch [830/3000]: Train loss: 1.1737, Valid loss: 0.9297\n",
      "Epoch [831/3000]: Train loss: 1.1778, Valid loss: 1.1129\n",
      "Epoch [832/3000]: Train loss: 1.1890, Valid loss: 0.9193\n",
      "Epoch [833/3000]: Train loss: 1.1626, Valid loss: 0.9825\n",
      "Epoch [834/3000]: Train loss: 1.1371, Valid loss: 1.0299\n",
      "Epoch [835/3000]: Train loss: 1.1362, Valid loss: 1.2398\n",
      "Epoch [836/3000]: Train loss: 1.1483, Valid loss: 0.9332\n",
      "Epoch [837/3000]: Train loss: 1.1359, Valid loss: 0.9493\n",
      "Epoch [838/3000]: Train loss: 1.1430, Valid loss: 0.9225\n",
      "Epoch [839/3000]: Train loss: 1.1601, Valid loss: 0.8475\n",
      "Epoch [840/3000]: Train loss: 1.1354, Valid loss: 0.9356\n",
      "Epoch [841/3000]: Train loss: 1.1128, Valid loss: 1.0057\n",
      "Epoch [842/3000]: Train loss: 1.1269, Valid loss: 1.2472\n",
      "Epoch [843/3000]: Train loss: 1.1675, Valid loss: 0.8780\n",
      "Epoch [844/3000]: Train loss: 1.1812, Valid loss: 1.0436\n",
      "Epoch [845/3000]: Train loss: 1.2337, Valid loss: 0.9415\n",
      "Epoch [846/3000]: Train loss: 1.1996, Valid loss: 0.9866\n",
      "Epoch [847/3000]: Train loss: 1.1491, Valid loss: 0.8268\n",
      "Epoch [848/3000]: Train loss: 1.1401, Valid loss: 1.0035\n",
      "Epoch [849/3000]: Train loss: 1.1093, Valid loss: 0.9806\n",
      "Epoch [850/3000]: Train loss: 1.1549, Valid loss: 0.9396\n",
      "Epoch [851/3000]: Train loss: 1.1408, Valid loss: 0.9454\n",
      "Epoch [852/3000]: Train loss: 1.1182, Valid loss: 0.9307\n",
      "Epoch [853/3000]: Train loss: 1.1511, Valid loss: 0.7774\n",
      "Epoch [854/3000]: Train loss: 1.1178, Valid loss: 0.9895\n",
      "Epoch [855/3000]: Train loss: 1.1675, Valid loss: 0.8864\n",
      "Epoch [856/3000]: Train loss: 1.1546, Valid loss: 0.8941\n",
      "Epoch [857/3000]: Train loss: 1.1288, Valid loss: 0.8564\n",
      "Epoch [858/3000]: Train loss: 1.1296, Valid loss: 0.9822\n",
      "Epoch [859/3000]: Train loss: 1.1628, Valid loss: 0.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [860/3000]: Train loss: 1.1846, Valid loss: 0.8775\n",
      "Epoch [861/3000]: Train loss: 1.1746, Valid loss: 1.0298\n",
      "Epoch [862/3000]: Train loss: 1.1945, Valid loss: 0.9688\n",
      "Epoch [863/3000]: Train loss: 1.1502, Valid loss: 1.0631\n",
      "Epoch [864/3000]: Train loss: 1.1686, Valid loss: 1.1063\n",
      "Epoch [865/3000]: Train loss: 1.1348, Valid loss: 0.8842\n",
      "Epoch [866/3000]: Train loss: 1.1548, Valid loss: 0.9645\n",
      "Epoch [867/3000]: Train loss: 1.1816, Valid loss: 1.0518\n",
      "Epoch [868/3000]: Train loss: 1.1682, Valid loss: 0.8770\n",
      "Epoch [869/3000]: Train loss: 1.1694, Valid loss: 0.8872\n",
      "Epoch [870/3000]: Train loss: 1.1268, Valid loss: 1.0197\n",
      "Epoch [871/3000]: Train loss: 1.1529, Valid loss: 0.9163\n",
      "Epoch [872/3000]: Train loss: 1.1634, Valid loss: 0.9485\n",
      "Epoch [873/3000]: Train loss: 1.1142, Valid loss: 0.8870\n",
      "Epoch [874/3000]: Train loss: 1.1252, Valid loss: 0.9077\n",
      "Epoch [875/3000]: Train loss: 1.1392, Valid loss: 1.0487\n",
      "Epoch [876/3000]: Train loss: 1.1298, Valid loss: 0.8517\n",
      "Epoch [877/3000]: Train loss: 1.1588, Valid loss: 1.0119\n",
      "Epoch [878/3000]: Train loss: 1.1844, Valid loss: 1.1155\n",
      "Epoch [879/3000]: Train loss: 1.2642, Valid loss: 0.8865\n",
      "Epoch [880/3000]: Train loss: 1.1602, Valid loss: 1.0076\n",
      "Epoch [881/3000]: Train loss: 1.2333, Valid loss: 1.1553\n",
      "Epoch [882/3000]: Train loss: 1.2449, Valid loss: 1.0675\n",
      "Epoch [883/3000]: Train loss: 1.1721, Valid loss: 1.0056\n",
      "Epoch [884/3000]: Train loss: 1.1366, Valid loss: 1.0614\n",
      "Epoch [885/3000]: Train loss: 1.2315, Valid loss: 1.2907\n",
      "Epoch [886/3000]: Train loss: 1.2902, Valid loss: 1.0173\n",
      "Epoch [887/3000]: Train loss: 1.1813, Valid loss: 0.9737\n",
      "Epoch [888/3000]: Train loss: 1.1760, Valid loss: 0.9587\n",
      "Epoch [889/3000]: Train loss: 1.1599, Valid loss: 0.9516\n",
      "Epoch [890/3000]: Train loss: 1.1494, Valid loss: 1.0739\n",
      "Epoch [891/3000]: Train loss: 1.1355, Valid loss: 1.0755\n",
      "Epoch [892/3000]: Train loss: 1.1495, Valid loss: 0.9039\n",
      "Epoch [893/3000]: Train loss: 1.1382, Valid loss: 1.0847\n",
      "Epoch [894/3000]: Train loss: 1.1617, Valid loss: 0.9537\n",
      "Epoch [895/3000]: Train loss: 1.1826, Valid loss: 0.9994\n",
      "Epoch [896/3000]: Train loss: 1.1336, Valid loss: 0.9574\n",
      "Epoch [897/3000]: Train loss: 1.1536, Valid loss: 0.9725\n",
      "Epoch [898/3000]: Train loss: 1.1298, Valid loss: 0.9162\n",
      "Epoch [899/3000]: Train loss: 1.1711, Valid loss: 0.9561\n",
      "Epoch [900/3000]: Train loss: 1.1431, Valid loss: 0.9259\n",
      "Epoch [901/3000]: Train loss: 1.1661, Valid loss: 0.8741\n",
      "Epoch [902/3000]: Train loss: 1.1722, Valid loss: 0.9163\n",
      "Epoch [903/3000]: Train loss: 1.1773, Valid loss: 0.9641\n",
      "Epoch [904/3000]: Train loss: 1.1430, Valid loss: 0.7750\n",
      "Epoch [905/3000]: Train loss: 1.1541, Valid loss: 0.9180\n",
      "Epoch [906/3000]: Train loss: 1.1600, Valid loss: 0.9542\n",
      "Epoch [907/3000]: Train loss: 1.1685, Valid loss: 1.0253\n",
      "Epoch [908/3000]: Train loss: 1.1444, Valid loss: 1.0514\n",
      "\n",
      "Model is not improving, so we halt the training session.\n",
      "0.7163983335097631\n"
     ]
    }
   ],
   "source": [
    "model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "# model.load_state_dict(torch.load('./models/model.ckpt'))\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik09KPqU-di-"
   },
   "source": [
    "# Plot learning curves with `tensorboard` (optional)\n",
    "\n",
    "`tensorboard` is a tool that allows you to visualize your training progress.\n",
    "\n",
    "If this block does not display your learning curve, please wait for few minutes, and re-run this block. It might take some time to load your logging information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "loA4nKmLGQ-n"
   },
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir=./runs/\n",
    "# torch.save(model.state_dict(), config['save_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhAHGqC9-woK"
   },
   "source": [
    "# Testing\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Q5eVdpbvAlAe"
   },
   "outputs": [],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device) \n",
    "save_pred(preds, 'model5.csv')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ_k5rY0GvSV"
   },
   "source": [
    "# Reference\n",
    "This notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML2022Spring - HW1(0.89704).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
