{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cFq_TgWlQ_"
      },
      "source": [
        "# Homework 11 - Transfer Learning (Domain Adversarial Training)\n",
        "\n",
        "> Author: Arvin Liu (r09922071@ntu.edu.tw)\n",
        "\n",
        "If there are any questions, please contact mlta-2022-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNiZCGrIYKdR"
      },
      "source": [
        "# Readme\n",
        "\n",
        "In homework 11, you will need to implement Domain Adversarial Training in Transfer Learning. As shown in the bottom left part of the figure.\n",
        "\n",
        "<img src=\"https://i.imgur.com/iMVIxCH.png\" width=\"500px\">\n",
        "\n",
        "> \n",
        "\n",
        "## Scenario and Why Domain Adversarial Training\n",
        "Now we have labeled source data and unlabeled target data, where source data might be relavent to the target data. We now want to train a model with source data only and test it on target data.\n",
        "\n",
        "What problem might occur if we do so? After we have learned Anomaly Detection, we now know that if we test the model with an abnormal data that have never appeared in source data, our trained model is likely to result in poor performance since it is not familiar with the abnormal data.\n",
        "\n",
        "For example, we have a model that contains Feature Extractor and Classifier:\n",
        "<img src=\"https://i.imgur.com/IL0PxCY.png\" width=\"500px\">\n",
        "\n",
        "When the model is trained with source data, the feature extractor \n",
        "will extract meaningful features since it is familiar with the distribution of it.It could be seen in the following figure that the blue dots, which is the distribution of source data, has already been clustered into different clusters. Therefore, the Classifier can predict the label based on these clusters.\n",
        "\n",
        "However, when test on the target data, the Feature Extractor will not be able to extract meaningful features that follow the distribution of the source feature distribution, which result in the classifier learned for the source domain will not be able to apply to the target domain.\n",
        "\n",
        "\n",
        "## Domain Adversarial Training of Nerural Networks (DaNN)\n",
        "\n",
        "Based on the above problems, DaNN approaches build mappings between the source (training-time) and the target (test-time) domains, so that the classifier learned for the source domain can also be applied to the target domain, when composed with the learned mapping between domains.\n",
        "\n",
        "<img src=\"https://i.imgur.com/vrOE5a6.png\" width=\"500px\">\n",
        "\n",
        "In DaNN, the authors added a Domain Classifier, which is a deep discriminatively-trained classifeir in the training framework to distinguish the data from different domain by the features extracted by the feature extractor. As the training progresses, the approach promotes a domain classifier that discriminates between the source and the target domains and a feature extractor that can extractor features that are discriminative for the main learning task on the source domain and indiscriminate with respect to the shift between the domains. \n",
        "\n",
        "\n",
        "The feature extractor are likely to outperform the domain classifier as its input are generated by the feature extractor and that the task of domain classification and label classification are not conflict.\n",
        "\n",
        "This method leads to the emergence of features that are domain-invariant and on the same feature distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-qnUkspmap3"
      },
      "source": [
        "# Data Introduce\n",
        "\n",
        "Our task contains source data: real photos, and target data: hand-drawn graffiti.\n",
        "\n",
        "We are going to train the model with the photos and the labels, and try to predict what the labels are for hand-drawn graffiti.\n",
        "\n",
        "The data could be downloaded [here](https://github.com/redxouls/ml2020spring-hw11-dataset/releases/download/v1.0.0/real_or_drawing.zip). The code below is for data downloading and visualization.\n",
        "\n",
        "Note that: **The source and target data are all balanced data, you can make use of this information.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF-i0sVlnUbq",
        "outputId": "556e93b5-a4c4-4e59-bb19-b37fdd0edaea"
      },
      "outputs": [],
      "source": [
        "# # Download dataset\n",
        "# !wget \"https://github.com/redxouls/ml2020spring-hw11-dataset/releases/download/v1.0.0/real_or_drawing.zip\" -O real_or_drawing.zip\n",
        "\n",
        "# # Download from mirrored dataset link\n",
        "# # !wget \"https://github.com/redxouls/ml2020spring-hw11-dataset/releases/download/v1.0.1/real_or_drawing.zip\" -O real_or_drawing.zip\n",
        "# # !wget \"https://github.com/redxouls/ml2020spring-hw11-dataset/releases/download/v1.0.2/real_or_drawing.zip\" -O real_or_drawing.zip\n",
        "\n",
        "# # Unzip the files\n",
        "# !unzip real_or_drawing.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "0_uO-ZSDoR6i",
        "outputId": "a56910e2-d5fb-437e-c5ad-032daa710804"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def no_axis_show(img, title='', cmap=None):\n",
        "#   # imshow, and set the interpolation mode to be \"nearest\"ã€‚\n",
        "#   fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n",
        "#   # do not show the axes in the images.\n",
        "#   fig.axes.get_xaxis().set_visible(False)\n",
        "#   fig.axes.get_yaxis().set_visible(False)\n",
        "#   plt.title(title)\n",
        "\n",
        "# titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
        "# plt.figure(figsize=(18, 18))\n",
        "# for i in range(10):\n",
        "#   plt.subplot(1, 10, i+1)\n",
        "#   fig = no_axis_show(plt.imread(f'real_or_drawing/train_data/{i}/{500*i}.bmp'), title=titles[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "3eMs7DbVt4Ee",
        "outputId": "d4342786-241a-419c-93e2-f79b9ffffb1e"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(18, 18))\n",
        "# for i in range(10):\n",
        "#   plt.subplot(1, 10, i+1)\n",
        "#   fig = no_axis_show(plt.imread(f'real_or_drawing/test_data/0/' + str(i).rjust(5, '0') + '.bmp'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moXQw9To5TqZ"
      },
      "source": [
        "# Special Domain Knowledge\n",
        "\n",
        "When we graffiti, we usually draw the outline only, therefore we can perform edge detection processing on the source data to make it more similar to the target data.\n",
        "\n",
        "\n",
        "## Canny Edge Detection\n",
        "The implementation of Canny Edge Detection is as follow.\n",
        "The algorithm will not be describe thoroughly here.  If you are interested, please refer to the wiki or [here](https://medium.com/@pomelyu5199/canny-edge-detector-%E5%AF%A6%E4%BD%9C-opencv-f7d1a0a57d19).\n",
        "\n",
        "We only need two parameters to implement Canny Edge Detection with CV2:  `low_threshold` and `high_threshold`.\n",
        "\n",
        "```cv2.Canny(image, low_threshold, high_threshold)```\n",
        "\n",
        "Simply put, when the edge value exceeds the high_threshold, we determine it as an edge. If the edge value is only above low_threshold, we will then determine whether it is an edge or not.\n",
        "\n",
        "Let's implement it on the source data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "mn2MkDLV7E2-",
        "outputId": "537f1e22-420e-4cf3-ac87-e975e0bb524f"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
        "# plt.figure(figsize=(18, 18))\n",
        "\n",
        "# original_img = plt.imread(f'real_or_drawing/train_data/0/0.bmp')\n",
        "# plt.subplot(1, 5, 1)\n",
        "# no_axis_show(original_img, title='original')\n",
        "\n",
        "# gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
        "# plt.subplot(1, 5, 2)\n",
        "# no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
        "\n",
        "# gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
        "# plt.subplot(1, 5, 2)\n",
        "# no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
        "\n",
        "# canny_50100 = cv2.Canny(gray_img, 50, 100)\n",
        "# plt.subplot(1, 5, 3)\n",
        "# no_axis_show(canny_50100, title='Canny(50, 100)', cmap='gray')\n",
        "\n",
        "# canny_150200 = cv2.Canny(gray_img, 150, 200)\n",
        "# plt.subplot(1, 5, 4)\n",
        "# no_axis_show(canny_150200, title='Canny(150, 200)', cmap='gray')\n",
        "\n",
        "# canny_250300 = cv2.Canny(gray_img, 250, 300)\n",
        "# plt.subplot(1, 5, 5)\n",
        "# no_axis_show(canny_250300, title='Canny(250, 300)', cmap='gray')\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8THSdt_hmwYh"
      },
      "source": [
        "# Data Process\n",
        " \n",
        " \n",
        "The data is suitible for `torchvision.ImageFolder`. You can create a dataset with `torchvision.ImageFolder`. Details for image augmentation please refer to the comments in the following codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WZHIBGknmi8Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        " \n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        " \n",
        "source_transform = transforms.Compose([\n",
        "    # Turn RGB to grayscale. (Bacause Canny do not support RGB images.)\n",
        "    transforms.Grayscale(),\n",
        "    # cv2 do not support skimage.Image, so we transform it to np.array, \n",
        "    # and then adopt cv2.Canny algorithm.\n",
        "    transforms.Lambda(lambda x: cv2.Canny(np.array(x), 170, 300)),\n",
        "    # Transform np.array back to the skimage.Image.\n",
        "    transforms.ToPILImage(),\n",
        "    # 50% Horizontal Flip. (For Augmentation)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
        "    # if there's empty pixel after rotation.\n",
        "    transforms.RandomRotation(15, fill=(0,)),\n",
        "    # Transform to tensor for model inputs.\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "target_transform = transforms.Compose([\n",
        "    # Turn RGB to grayscale.\n",
        "    transforms.Grayscale(),\n",
        "    # Resize: size of source data is 32x32, thus we need to \n",
        "    #  enlarge the size of target data from 28x28 to 32x32ã€‚\n",
        "    transforms.Resize((32, 32)),\n",
        "    # 50% Horizontal Flip. (For Augmentation)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
        "    # if there's empty pixel after rotation.\n",
        "    transforms.RandomRotation(15, fill=(0,)),\n",
        "    # Transform to tensor for model inputs.\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        " \n",
        "source_dataset = ImageFolder('real_or_drawing/train_data', transform=source_transform)\n",
        "target_dataset = ImageFolder('real_or_drawing/test_data', transform=target_transform)\n",
        " \n",
        "source_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
        "target_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdwDEMrOycs5"
      },
      "source": [
        "# Model\n",
        "\n",
        "Feature Extractor: Classic VGG-like architecture\n",
        "\n",
        "Label Predictor / Domain Classifier: Linear models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3uw2eP09z-pD"
      },
      "outputs": [],
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x).squeeze()\n",
        "        return x\n",
        "\n",
        "class LabelPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LabelPredictor, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, h):\n",
        "        c = self.layer(h)\n",
        "        return c\n",
        "\n",
        "class DomainClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DomainClassifier, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, h):\n",
        "        y = self.layer(h)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxdBIPhF0Icb"
      },
      "source": [
        "# Pre-processing\n",
        "\n",
        "Here we use Adam as our optimizor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hrxKelBy0PJ7"
      },
      "outputs": [],
      "source": [
        "feature_extractor = FeatureExtractor().cuda()\n",
        "label_predictor = LabelPredictor().cuda()\n",
        "\n",
        "feature_extractor.load_state_dict(torch.load('extractor_model.bin'))\n",
        "label_predictor.load_state_dict(torch.load('predictor_model.bin'))\n",
        "\n",
        "domain_classifier = DomainClassifier().cuda()\n",
        "\n",
        "class_criterion = nn.CrossEntropyLoss()\n",
        "domain_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer_F = optim.Adam(feature_extractor.parameters())\n",
        "optimizer_C = optim.Adam(label_predictor.parameters())\n",
        "optimizer_D = optim.Adam(domain_classifier.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuAE4cqJ0itR"
      },
      "source": [
        "# Start Training\n",
        "\n",
        "\n",
        "## DaNN Implementation\n",
        "\n",
        "In the original paper, Gradient Reversal Layer is used.\n",
        "Feature Extractor, Label Predictor, and Domain Classifier are all trained at the same time. In this code, we train Domain Classifier first, and then train our Feature Extractor (same concept as Generator and Discriminator training process in GAN).\n",
        "\n",
        "## Reminder\n",
        "* Lambda, which controls the domain adversarial loss, is adaptive in the original paper. You can refer to [the original work](https://arxiv.org/pdf/1505.07818.pdf) . Here lambda is set to 0.1.\n",
        "* We do not have the label to target data, you can only evaluate your model by uploading your result to kaggle.:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRAFFKvX0p9y",
        "outputId": "bd4172f4-2ddf-4168-898d-0f9f9aeb436f"
      },
      "outputs": [],
      "source": [
        "# def train_epoch(source_dataloader, target_dataloader, epoch, n_epoch):\n",
        "#     '''\n",
        "#       Args:\n",
        "#         source_dataloader: source dataçš„dataloader\n",
        "#         target_dataloader: target dataçš„dataloader\n",
        "#         lamb: control the balance of domain adaptatoin and classification.\n",
        "#     '''\n",
        "\n",
        "#     # D loss: Domain Classifierçš„loss\n",
        "#     # F loss: Feature Extrator & Label Predictorçš„loss\n",
        "#     running_D_loss, running_F_loss = 0.0, 0.0\n",
        "#     total_hit, total_num = 0.0, 0.0\n",
        "\n",
        "#     for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n",
        "\n",
        "#         source_data = source_data.cuda()\n",
        "#         source_label = source_label.cuda()\n",
        "#         target_data = target_data.cuda()\n",
        "        \n",
        "#         # Mixed the source data and target data, or it'll mislead the running params\n",
        "#         #   of batch_norm. (runnning mean/var of soucre and target data are different.)\n",
        "#         mixed_data = torch.cat([source_data, target_data], dim=0)\n",
        "#         domain_label = torch.zeros([source_data.shape[0] + target_data.shape[0], 1]).cuda()\n",
        "#         # set domain label of source data to be 1.\n",
        "#         domain_label[:source_data.shape[0]] = 1\n",
        "\n",
        "#         # Step 1 : train domain classifier\n",
        "#         feature = feature_extractor(mixed_data)\n",
        "#         # We don't need to train feature extractor in step 1.\n",
        "#         # Thus we detach the feature neuron to avoid backpropgation.\n",
        "#         domain_logits = domain_classifier(feature.detach())\n",
        "#         loss = domain_criterion(domain_logits, domain_label)\n",
        "#         running_D_loss+= loss.item()\n",
        "#         loss.backward()\n",
        "#         optimizer_D.step()\n",
        "\n",
        "#         # Step 2 : train feature extractor and label classifier\n",
        "#         class_logits = label_predictor(feature[:source_data.shape[0]])\n",
        "#         domain_logits = domain_classifier(feature)\n",
        "#         # loss = cross entropy of classification - lamb * domain binary cross entropy.\n",
        "#         #  The reason why using subtraction is similar to generator loss in disciminator of GAN\n",
        "#         lamb = 4. / (1. + np.exp(-10 * float(epoch * len(source_dataloader) + i) / n_epoch / len(source_dataloader)))-2\n",
        "#         loss = class_criterion(class_logits, source_label) - lamb * domain_criterion(domain_logits, domain_label)\n",
        "#         running_F_loss+= loss.item()\n",
        "#         loss.backward()\n",
        "#         optimizer_F.step()\n",
        "#         optimizer_C.step()\n",
        "\n",
        "#         optimizer_D.zero_grad()\n",
        "#         optimizer_F.zero_grad()\n",
        "#         optimizer_C.zero_grad()\n",
        "\n",
        "#         total_hit += torch.sum(torch.argmax(class_logits, dim=1) == source_label).item()\n",
        "#         total_num += source_data.shape[0]\n",
        "#         print(i, end='\\r')\n",
        "\n",
        "#     return running_D_loss / (i+1), running_F_loss / (i+1), total_hit / total_num\n",
        "\n",
        "# # train 200 epochs\n",
        "# n_epoch = 2000\n",
        "# for epoch in range(n_epoch):\n",
        "#     train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader,epoch, n_epoch)\n",
        "\n",
        "#     torch.save(feature_extractor.state_dict(), f'extractor_model.bin')\n",
        "#     torch.save(label_predictor.state_dict(), f'predictor_model.bin')\n",
        "\n",
        "#     print('epoch {:>3d}: train D loss: {:6.4f}, train F loss: {:6.4f}, acc {:6.4f}'.format(epoch, train_D_loss, train_F_loss, train_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get 94872 new data with psuedo label\n"
          ]
        }
      ],
      "source": [
        "#get psuedo label\n",
        "threshold = 0.9\n",
        "pseudo_data, pseudo_label = torch.LongTensor([]).cuda(), torch.LongTensor([]).cuda()\n",
        "\n",
        "label_predictor.eval()\n",
        "feature_extractor.eval()\n",
        "\n",
        "softmax = nn.Softmax(dim=-1)\n",
        "for i, (test_data, _) in enumerate(test_dataloader):\n",
        "    with torch.no_grad():\n",
        "        test_data = test_data.cuda()\n",
        "        class_logits = label_predictor(feature_extractor(test_data))\n",
        "        probs = softmax(class_logits)\n",
        "        prob = probs.max(dim=-1).values\n",
        "        x = torch.argmax(probs, dim=1)\n",
        "    \n",
        "    pseudo_data = torch.cat((pseudo_data, test_data[prob>threshold]), dim=0)\n",
        "    pseudo_label = torch.cat((pseudo_label, x[prob>threshold]), dim=0)\n",
        "\n",
        "print(f'get {len(pseudo_data)} new data with psuedo label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
        "class PseudoDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.data = x\n",
        "        self.label = y.tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.label[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "pseudo_dataset = PseudoDataset(pseudo_data.cpu(), pseudo_label.cpu())\n",
        "combine_dataset = ConcatDataset([pseudo_dataset, source_dataset])\n",
        "combine_dataloader = DataLoader(pseudo_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "new_classifier = models.resnet18(pretrained = False, num_classes=10).cuda()\n",
        "new_classifier.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False).cuda()\n",
        "# new_criterion = nn.CrossEntropyLoss()\n",
        "# new_optimizer = optim.Adam(new_classifier.parameters(), lr=0.001)\n",
        "# new_scheduler = optim.lr_scheduler.CosineAnnealingLR(new_optimizer,T_max=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def new_train_epoch(dataloader):\n",
        "#     total_loss = 0.0\n",
        "#     total_hit, total_num = 0.0, 0.0\n",
        "\n",
        "#     for i, data in enumerate(dataloader):\n",
        "#         imgs, labels = data\n",
        "#         imgs = imgs.cuda()\n",
        "#         labels = labels.cuda()\n",
        "#         logits = new_classifier(imgs)\n",
        "#         loss = new_criterion(logits, labels)\n",
        "#         total_loss += loss.item()\n",
        "#         loss.backward()\n",
        "\n",
        "#         new_optimizer.step()\n",
        "#         new_scheduler.step()\n",
        "#         new_optimizer.zero_grad()\n",
        "\n",
        "#         total_hit += torch.sum(torch.argmax(logits, dim=1) == labels).item()\n",
        "#         total_num += imgs.shape[0]\n",
        "#         print(i, end='\\r')\n",
        "\n",
        "#     return total_loss / (i+1), total_hit / total_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.42270 | Correct: 6/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.90620 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 0.56090 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 0.24834 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 400 | Loss: 0.45268 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 500 | Loss: 0.71753 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 600 | Loss: 0.21664 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 700 | Loss: 0.69001 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 800 | Loss: 0.24305 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 900 | Loss: 0.51766 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1000 | Loss: 0.18676 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1100 | Loss: 0.38374 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1200 | Loss: 0.59819 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1300 | Loss: 0.52438 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1400 | Loss: 0.09390 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1500 | Loss: 0.50411 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1600 | Loss: 0.35954 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1700 | Loss: 0.32113 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1800 | Loss: 0.16860 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 1900 | Loss: 0.41246 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2000 | Loss: 0.35786 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2100 | Loss: 0.22668 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2200 | Loss: 0.31121 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2300 | Loss: 0.15339 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2400 | Loss: 0.21985 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2500 | Loss: 0.10037 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2600 | Loss: 0.22266 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2700 | Loss: 0.18179 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2800 | Loss: 0.36903 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 2900 | Loss: 0.19539 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.42256 | Correct: 2/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.38055 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 0.41949 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 0.56100 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 400 | Loss: 0.41009 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 500 | Loss: 0.38703 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 600 | Loss: 0.35854 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 700 | Loss: 0.48158 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 800 | Loss: 0.19903 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 900 | Loss: 0.35082 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1000 | Loss: 0.24886 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1100 | Loss: 0.28276 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1200 | Loss: 0.28324 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1300 | Loss: 0.47771 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1400 | Loss: 0.49942 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1500 | Loss: 0.26521 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1600 | Loss: 0.43160 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1700 | Loss: 0.21270 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1800 | Loss: 0.14459 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 1900 | Loss: 0.31993 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2000 | Loss: 0.07032 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2100 | Loss: 0.43023 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2200 | Loss: 0.37845 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2300 | Loss: 0.48296 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2400 | Loss: 0.15177 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2500 | Loss: 0.41704 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2600 | Loss: 0.21308 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2700 | Loss: 0.50009 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2800 | Loss: 0.10359 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 2900 | Loss: 0.67611 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.36751 | Correct: 5/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.43045 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 0.59137 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 0.32099 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 400 | Loss: 0.47633 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 500 | Loss: 0.38412 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 600 | Loss: 0.54230 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 700 | Loss: 0.20067 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 800 | Loss: 0.34280 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 900 | Loss: 0.41663 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1000 | Loss: 0.34014 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1100 | Loss: 0.17752 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1200 | Loss: 0.33289 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1300 | Loss: 0.28723 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1400 | Loss: 0.27053 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1500 | Loss: 0.57474 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1600 | Loss: 0.29499 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1700 | Loss: 0.76781 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1800 | Loss: 0.26910 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 1900 | Loss: 0.12454 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2000 | Loss: 0.37641 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2100 | Loss: 0.48250 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2200 | Loss: 0.14035 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2300 | Loss: 0.12916 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2400 | Loss: 0.29393 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2500 | Loss: 0.31926 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2600 | Loss: 0.28249 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2700 | Loss: 0.24412 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2800 | Loss: 0.28976 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 2900 | Loss: 0.28631 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.43783 | Correct: 4/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.97947 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 0.64719 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 0.34901 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 400 | Loss: 0.34697 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 500 | Loss: 0.38119 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 600 | Loss: 0.33302 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 700 | Loss: 0.28046 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 800 | Loss: 0.20764 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 900 | Loss: 0.11414 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1000 | Loss: 0.45775 | Correct: 26/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1100 | Loss: 0.37047 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1200 | Loss: 0.55736 | Correct: 25/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1300 | Loss: 0.30377 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1400 | Loss: 0.23554 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1500 | Loss: 0.25879 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1600 | Loss: 0.27961 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1700 | Loss: 0.26606 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1800 | Loss: 0.67190 | Correct: 26/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 1900 | Loss: 0.51724 | Correct: 25/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2000 | Loss: 0.32573 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2100 | Loss: 0.36331 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2200 | Loss: 0.20788 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2300 | Loss: 0.27042 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2400 | Loss: 0.34726 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2500 | Loss: 0.21087 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2600 | Loss: 0.32092 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2700 | Loss: 0.49949 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2800 | Loss: 0.30126 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 2900 | Loss: 0.37077 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.22495 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.33972 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 200 | Loss: 0.14538 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 300 | Loss: 0.26839 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 400 | Loss: 0.13666 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 500 | Loss: 0.21916 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 600 | Loss: 0.27873 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 700 | Loss: 0.36183 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 800 | Loss: 0.50303 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 900 | Loss: 0.14487 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1000 | Loss: 0.19541 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1100 | Loss: 0.45167 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1200 | Loss: 0.23641 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1300 | Loss: 0.11526 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1400 | Loss: 0.11082 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1500 | Loss: 0.34410 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1600 | Loss: 0.35923 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1700 | Loss: 0.24542 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1800 | Loss: 0.28246 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 1900 | Loss: 0.09487 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2000 | Loss: 0.19885 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2100 | Loss: 0.11285 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2200 | Loss: 0.08478 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2300 | Loss: 0.25599 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2400 | Loss: 0.25804 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2500 | Loss: 0.08109 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2600 | Loss: 0.51551 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2700 | Loss: 0.12569 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2800 | Loss: 0.44059 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 2900 | Loss: 0.17366 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.09720 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.29073 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 200 | Loss: 0.25960 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 300 | Loss: 0.23222 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 400 | Loss: 0.23021 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 500 | Loss: 0.49527 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 600 | Loss: 0.27788 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 700 | Loss: 0.39967 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 800 | Loss: 0.21120 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 900 | Loss: 0.11987 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1000 | Loss: 0.42010 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1100 | Loss: 0.24388 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1200 | Loss: 0.26288 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1300 | Loss: 0.22237 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1400 | Loss: 0.55706 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1500 | Loss: 0.17964 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1600 | Loss: 0.45961 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1700 | Loss: 0.16657 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1800 | Loss: 0.20654 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 1900 | Loss: 0.13057 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2000 | Loss: 0.43066 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2100 | Loss: 0.62911 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2200 | Loss: 0.37928 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2300 | Loss: 0.28717 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2400 | Loss: 0.14652 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2500 | Loss: 0.18248 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2600 | Loss: 0.17114 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2700 | Loss: 0.11909 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2800 | Loss: 0.26821 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 2900 | Loss: 0.18958 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.21006 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.17254 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 200 | Loss: 0.31265 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 300 | Loss: 0.20457 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 400 | Loss: 0.49930 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 500 | Loss: 0.28730 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 600 | Loss: 0.21523 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 700 | Loss: 0.22574 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 800 | Loss: 0.11679 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 900 | Loss: 0.15635 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1000 | Loss: 0.21681 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1100 | Loss: 0.27834 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1200 | Loss: 0.17505 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1300 | Loss: 0.21685 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1400 | Loss: 0.17958 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1500 | Loss: 0.43174 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1600 | Loss: 0.21092 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1700 | Loss: 0.14358 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1800 | Loss: 0.34577 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 1900 | Loss: 0.14499 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2000 | Loss: 0.74490 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2100 | Loss: 0.12651 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2200 | Loss: 0.49224 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2300 | Loss: 0.23466 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2400 | Loss: 0.32862 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2500 | Loss: 0.10361 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2600 | Loss: 0.66638 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2700 | Loss: 0.54765 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2800 | Loss: 0.16491 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 2900 | Loss: 0.16746 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.26258 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.26853 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 200 | Loss: 0.43769 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 300 | Loss: 0.07439 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 400 | Loss: 0.31679 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 500 | Loss: 0.37755 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 600 | Loss: 0.28800 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 700 | Loss: 0.12140 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 800 | Loss: 0.25009 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 900 | Loss: 0.24709 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1000 | Loss: 0.15671 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1100 | Loss: 0.11088 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1200 | Loss: 0.17679 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1300 | Loss: 0.54579 | Correct: 26/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1400 | Loss: 0.11310 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1500 | Loss: 0.24601 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1600 | Loss: 0.34370 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1700 | Loss: 0.39501 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1800 | Loss: 0.28049 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 1900 | Loss: 0.11885 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2000 | Loss: 0.30354 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2100 | Loss: 0.24511 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2200 | Loss: 0.05345 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2300 | Loss: 0.38826 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2400 | Loss: 0.24308 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2500 | Loss: 0.09895 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2600 | Loss: 0.29363 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2700 | Loss: 0.38904 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2800 | Loss: 0.22658 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 2900 | Loss: 0.52275 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.20639 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.23686 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 200 | Loss: 0.24939 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 300 | Loss: 0.22641 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 400 | Loss: 0.09907 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 500 | Loss: 0.12412 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 600 | Loss: 0.06557 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 700 | Loss: 0.10511 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 800 | Loss: 0.11167 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 900 | Loss: 0.23398 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1000 | Loss: 0.26698 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1100 | Loss: 0.27783 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1200 | Loss: 0.13340 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1300 | Loss: 0.27845 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1400 | Loss: 0.32888 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1500 | Loss: 0.16264 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1600 | Loss: 0.08189 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1700 | Loss: 0.04556 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1800 | Loss: 0.05368 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 1900 | Loss: 0.25359 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2000 | Loss: 0.08808 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2100 | Loss: 0.30860 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2200 | Loss: 0.16467 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2300 | Loss: 0.25259 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2400 | Loss: 0.09525 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2500 | Loss: 0.31658 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2600 | Loss: 0.08746 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2700 | Loss: 0.16107 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2800 | Loss: 0.54222 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 2900 | Loss: 0.04194 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.10901 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.35444 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 200 | Loss: 0.07437 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 300 | Loss: 0.18454 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 400 | Loss: 0.31701 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 500 | Loss: 0.36771 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 600 | Loss: 0.16354 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 700 | Loss: 0.06875 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 800 | Loss: 0.63068 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 900 | Loss: 0.20329 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1000 | Loss: 0.13418 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1100 | Loss: 0.08125 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1200 | Loss: 0.05788 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1300 | Loss: 0.18034 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1400 | Loss: 0.26825 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1500 | Loss: 0.14017 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1600 | Loss: 0.12588 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1700 | Loss: 0.20417 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1800 | Loss: 0.33491 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 1900 | Loss: 0.13417 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2000 | Loss: 0.17425 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2100 | Loss: 0.16721 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2200 | Loss: 0.23426 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2300 | Loss: 0.18935 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2400 | Loss: 0.08597 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2500 | Loss: 0.18187 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2600 | Loss: 0.17156 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2700 | Loss: 0.51393 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2800 | Loss: 0.10037 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 2900 | Loss: 0.17563 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.20276 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.25704 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 200 | Loss: 0.19454 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 300 | Loss: 0.23739 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 400 | Loss: 0.17295 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 500 | Loss: 0.05964 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 600 | Loss: 0.20067 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 700 | Loss: 0.55670 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 800 | Loss: 0.36038 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 900 | Loss: 0.23820 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1000 | Loss: 0.25531 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1100 | Loss: 0.10670 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1200 | Loss: 0.30282 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1300 | Loss: 0.24850 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1400 | Loss: 0.17909 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1500 | Loss: 0.40973 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1600 | Loss: 0.25143 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1700 | Loss: 0.01503 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1800 | Loss: 0.04396 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 1900 | Loss: 0.15671 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2000 | Loss: 0.21271 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2100 | Loss: 0.16476 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2200 | Loss: 0.58252 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2300 | Loss: 0.06371 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2400 | Loss: 0.17656 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2500 | Loss: 0.03036 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2600 | Loss: 0.22924 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2700 | Loss: 0.18413 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2800 | Loss: 0.25209 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 2900 | Loss: 0.21084 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.12654 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.22361 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 200 | Loss: 0.24681 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 300 | Loss: 0.13630 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 400 | Loss: 0.36401 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 500 | Loss: 0.14268 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 600 | Loss: 0.20735 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 700 | Loss: 0.53950 | Correct: 25/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 800 | Loss: 0.08263 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 900 | Loss: 0.09105 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1000 | Loss: 0.17550 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1100 | Loss: 0.05294 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1200 | Loss: 0.25768 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1300 | Loss: 0.05967 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1400 | Loss: 0.26085 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1500 | Loss: 0.09309 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1600 | Loss: 0.26101 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1700 | Loss: 0.25386 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1800 | Loss: 0.16730 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 1900 | Loss: 0.08211 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2000 | Loss: 0.15585 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2100 | Loss: 0.20440 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2200 | Loss: 0.36906 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2300 | Loss: 0.59776 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2400 | Loss: 0.49732 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2500 | Loss: 0.08012 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2600 | Loss: 0.25029 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2700 | Loss: 0.08268 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2800 | Loss: 0.06405 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 2900 | Loss: 0.29012 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.04093 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.05485 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 200 | Loss: 0.16597 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 300 | Loss: 0.26462 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 400 | Loss: 0.40252 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 500 | Loss: 0.35348 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 600 | Loss: 0.02660 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 700 | Loss: 0.23289 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 800 | Loss: 0.28163 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 900 | Loss: 0.11976 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1000 | Loss: 0.08824 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1100 | Loss: 0.06555 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1200 | Loss: 0.07411 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1300 | Loss: 0.13650 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1400 | Loss: 0.21385 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1500 | Loss: 0.21192 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1600 | Loss: 0.22559 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1700 | Loss: 0.08212 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1800 | Loss: 0.20848 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 1900 | Loss: 0.17963 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2000 | Loss: 0.05799 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2100 | Loss: 0.13154 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2200 | Loss: 0.22036 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2300 | Loss: 0.12342 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2400 | Loss: 0.17026 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2500 | Loss: 0.29941 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2600 | Loss: 0.35291 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2700 | Loss: 0.07125 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2800 | Loss: 0.20075 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 2900 | Loss: 0.21754 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.21635 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.19808 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 200 | Loss: 0.10810 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 300 | Loss: 0.09517 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 400 | Loss: 0.13527 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 500 | Loss: 0.10567 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 600 | Loss: 0.31586 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 700 | Loss: 0.25270 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 800 | Loss: 0.08424 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 900 | Loss: 0.13802 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1000 | Loss: 0.18394 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1100 | Loss: 0.11272 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1200 | Loss: 0.05525 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1300 | Loss: 0.05849 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1400 | Loss: 0.16588 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1500 | Loss: 0.05173 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1600 | Loss: 0.06509 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1700 | Loss: 0.06486 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1800 | Loss: 0.07479 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 1900 | Loss: 0.12728 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2000 | Loss: 0.36202 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2100 | Loss: 0.11848 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2200 | Loss: 0.28173 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2300 | Loss: 0.02353 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2400 | Loss: 0.02897 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2500 | Loss: 0.33099 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2600 | Loss: 0.06117 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2700 | Loss: 0.10710 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2800 | Loss: 0.06239 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 2900 | Loss: 0.38722 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.17989 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.13723 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 200 | Loss: 0.13844 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 300 | Loss: 0.08958 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 400 | Loss: 0.05906 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 500 | Loss: 0.10968 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 600 | Loss: 0.06215 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 700 | Loss: 0.17805 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 800 | Loss: 0.05305 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 900 | Loss: 0.15415 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1000 | Loss: 0.23263 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1100 | Loss: 0.07395 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1200 | Loss: 0.10236 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1300 | Loss: 0.10060 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1400 | Loss: 0.36792 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1500 | Loss: 0.40373 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1600 | Loss: 0.22010 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1700 | Loss: 0.04820 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1800 | Loss: 0.04024 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 1900 | Loss: 0.04584 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2000 | Loss: 0.13410 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2100 | Loss: 0.16695 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2200 | Loss: 0.18556 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2300 | Loss: 0.12131 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2400 | Loss: 0.13355 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2500 | Loss: 0.13514 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2600 | Loss: 0.03644 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2700 | Loss: 0.11064 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2800 | Loss: 0.16463 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 2900 | Loss: 0.05587 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.15373 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.11855 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 200 | Loss: 0.20149 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 300 | Loss: 0.23421 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 400 | Loss: 0.04382 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 500 | Loss: 0.08989 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 600 | Loss: 0.16619 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 700 | Loss: 0.24401 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 800 | Loss: 0.14644 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 900 | Loss: 0.46128 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1000 | Loss: 0.14471 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1100 | Loss: 0.11389 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1200 | Loss: 0.18766 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1300 | Loss: 0.18067 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1400 | Loss: 0.06856 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1500 | Loss: 0.17507 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1600 | Loss: 0.23912 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1700 | Loss: 0.02173 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1800 | Loss: 0.03372 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 1900 | Loss: 0.09083 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2000 | Loss: 0.14972 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2100 | Loss: 0.09442 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2200 | Loss: 0.11218 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2300 | Loss: 0.45825 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2400 | Loss: 0.10110 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2500 | Loss: 0.22440 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2600 | Loss: 0.07173 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2700 | Loss: 0.03985 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2800 | Loss: 0.21327 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 2900 | Loss: 0.30330 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.11151 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.09906 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 200 | Loss: 0.11982 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 300 | Loss: 0.01882 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 400 | Loss: 0.10863 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 500 | Loss: 0.06851 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 600 | Loss: 0.48970 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 700 | Loss: 0.23899 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 800 | Loss: 0.23644 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 900 | Loss: 0.08607 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1000 | Loss: 0.00608 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1100 | Loss: 0.13589 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1200 | Loss: 0.00607 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1300 | Loss: 0.03308 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1400 | Loss: 0.62379 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1500 | Loss: 0.30313 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1600 | Loss: 0.14692 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1700 | Loss: 0.08325 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1800 | Loss: 0.25501 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 1900 | Loss: 0.12335 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2000 | Loss: 0.00451 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2100 | Loss: 0.13181 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2200 | Loss: 0.20585 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2300 | Loss: 0.22446 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2400 | Loss: 0.07433 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2500 | Loss: 0.05678 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2600 | Loss: 0.18787 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2700 | Loss: 0.03949 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2800 | Loss: 0.16093 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 2900 | Loss: 0.02575 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.07110 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.02674 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 200 | Loss: 0.12041 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 300 | Loss: 0.35106 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 400 | Loss: 0.18093 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 500 | Loss: 0.31493 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 600 | Loss: 0.14646 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 700 | Loss: 0.37857 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 800 | Loss: 0.14412 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 900 | Loss: 0.14877 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1000 | Loss: 0.24947 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1100 | Loss: 0.10073 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1200 | Loss: 0.03838 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1300 | Loss: 0.08644 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1400 | Loss: 0.38590 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1500 | Loss: 0.18296 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1600 | Loss: 0.14075 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1700 | Loss: 0.28260 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1800 | Loss: 0.13717 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 1900 | Loss: 0.07313 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2000 | Loss: 0.04267 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2100 | Loss: 0.08592 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2200 | Loss: 0.38137 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2300 | Loss: 0.27886 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2400 | Loss: 0.21486 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2500 | Loss: 0.02060 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2600 | Loss: 0.40356 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2700 | Loss: 0.15680 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2800 | Loss: 0.24554 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 2900 | Loss: 0.30070 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.26160 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.19267 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 200 | Loss: 0.12816 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 300 | Loss: 0.32915 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 400 | Loss: 0.04006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 500 | Loss: 0.06661 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 600 | Loss: 0.04201 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 700 | Loss: 0.17361 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 800 | Loss: 0.04470 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 900 | Loss: 0.20929 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1000 | Loss: 0.14211 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1100 | Loss: 0.37413 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1200 | Loss: 0.06107 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1300 | Loss: 0.08768 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1400 | Loss: 0.03850 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1500 | Loss: 0.34309 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1600 | Loss: 0.19432 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1700 | Loss: 0.17734 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1800 | Loss: 0.14024 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 1900 | Loss: 0.11087 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2000 | Loss: 0.32631 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2100 | Loss: 0.04670 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2200 | Loss: 0.09949 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2300 | Loss: 0.18244 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2400 | Loss: 0.01367 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2500 | Loss: 0.24783 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2600 | Loss: 0.11328 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2700 | Loss: 0.10166 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2800 | Loss: 0.10333 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 2900 | Loss: 0.17695 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.03371 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.44866 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 200 | Loss: 0.16020 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 300 | Loss: 0.02326 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 400 | Loss: 0.17981 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 500 | Loss: 0.06654 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 600 | Loss: 0.09650 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 700 | Loss: 0.17527 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 800 | Loss: 0.03744 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 900 | Loss: 0.13348 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1000 | Loss: 0.50418 | Correct: 25/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1100 | Loss: 0.04193 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1200 | Loss: 0.11264 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1300 | Loss: 0.02361 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1400 | Loss: 0.09107 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1500 | Loss: 0.02965 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1600 | Loss: 0.04879 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1700 | Loss: 0.04542 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1800 | Loss: 0.18431 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 1900 | Loss: 0.21470 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2000 | Loss: 0.20495 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2100 | Loss: 0.14239 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2200 | Loss: 0.03505 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2300 | Loss: 0.04692 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2400 | Loss: 0.10599 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2500 | Loss: 0.25095 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2600 | Loss: 0.50314 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2700 | Loss: 0.13518 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2800 | Loss: 0.27555 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 2900 | Loss: 0.07424 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 0.17877 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 100 | Loss: 0.12294 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 200 | Loss: 0.09118 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 300 | Loss: 0.12899 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 400 | Loss: 0.20099 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 500 | Loss: 0.09661 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 600 | Loss: 0.17681 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 700 | Loss: 0.10072 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 800 | Loss: 0.17902 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 900 | Loss: 0.05413 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1000 | Loss: 0.23193 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1100 | Loss: 0.15976 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1200 | Loss: 0.09376 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1300 | Loss: 0.21725 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1400 | Loss: 0.02490 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1500 | Loss: 0.01637 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1600 | Loss: 0.22645 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1700 | Loss: 0.03919 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1800 | Loss: 0.13520 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 1900 | Loss: 0.14095 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2000 | Loss: 0.06718 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2100 | Loss: 0.24064 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2200 | Loss: 0.29384 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2300 | Loss: 0.16686 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2400 | Loss: 0.09372 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2500 | Loss: 0.13216 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2600 | Loss: 0.20028 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2700 | Loss: 0.26344 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2800 | Loss: 0.16869 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 005 | Batch: 2900 | Loss: 0.01817 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 0.14248 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 100 | Loss: 0.08980 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 200 | Loss: 0.10180 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 300 | Loss: 0.06117 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 400 | Loss: 0.05050 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 500 | Loss: 0.15381 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 600 | Loss: 0.06790 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 700 | Loss: 0.11656 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 800 | Loss: 0.07050 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 900 | Loss: 0.09528 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1000 | Loss: 0.06008 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1100 | Loss: 0.19135 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1200 | Loss: 0.02875 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1300 | Loss: 0.07400 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1400 | Loss: 0.11329 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1500 | Loss: 0.16244 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1600 | Loss: 0.07310 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1700 | Loss: 0.21687 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1800 | Loss: 0.22530 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 1900 | Loss: 0.25870 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2000 | Loss: 0.12751 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2100 | Loss: 0.28607 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2200 | Loss: 0.31286 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2300 | Loss: 0.21198 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2400 | Loss: 0.21318 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2500 | Loss: 0.01704 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2600 | Loss: 0.10430 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2700 | Loss: 0.04463 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2800 | Loss: 0.07503 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 005 | Batch: 2900 | Loss: 0.16747 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 0.11998 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 100 | Loss: 0.07580 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 200 | Loss: 0.01147 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 300 | Loss: 0.22508 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 400 | Loss: 0.00688 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 500 | Loss: 0.05942 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 600 | Loss: 0.18280 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 700 | Loss: 0.10717 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 800 | Loss: 0.09886 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 900 | Loss: 0.09773 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1000 | Loss: 0.02473 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1100 | Loss: 0.11959 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1200 | Loss: 0.02587 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1300 | Loss: 0.06866 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1400 | Loss: 0.12133 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1500 | Loss: 0.09969 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1600 | Loss: 0.04319 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1700 | Loss: 0.05027 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1800 | Loss: 0.17385 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 1900 | Loss: 0.22269 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2000 | Loss: 0.04320 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2100 | Loss: 0.01508 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2200 | Loss: 0.18908 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2300 | Loss: 0.08368 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2400 | Loss: 0.16546 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2500 | Loss: 0.08347 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2600 | Loss: 0.06998 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2700 | Loss: 0.20187 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2800 | Loss: 0.26376 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 005 | Batch: 2900 | Loss: 0.05635 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 0.23298 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 100 | Loss: 0.09712 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 200 | Loss: 0.22713 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 300 | Loss: 0.04949 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 400 | Loss: 0.03441 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 500 | Loss: 0.09016 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 600 | Loss: 0.18941 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 700 | Loss: 0.14412 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 800 | Loss: 0.05915 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 900 | Loss: 0.11876 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1000 | Loss: 0.07101 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1100 | Loss: 0.04729 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1200 | Loss: 0.12674 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1300 | Loss: 0.06230 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1400 | Loss: 0.37765 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1500 | Loss: 0.17003 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1600 | Loss: 0.25738 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1700 | Loss: 0.22420 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1800 | Loss: 0.18714 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 1900 | Loss: 0.09304 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2000 | Loss: 0.24145 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2100 | Loss: 0.06340 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2200 | Loss: 0.22067 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2300 | Loss: 0.18739 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2400 | Loss: 0.06498 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2500 | Loss: 0.14630 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2600 | Loss: 0.19480 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2700 | Loss: 0.02977 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2800 | Loss: 0.06022 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 005 | Batch: 2900 | Loss: 0.11098 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 0.08679 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 100 | Loss: 0.04637 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 200 | Loss: 0.14551 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 300 | Loss: 0.17952 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 400 | Loss: 0.21059 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 500 | Loss: 0.50335 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 600 | Loss: 0.35494 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 700 | Loss: 0.02789 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 800 | Loss: 0.04518 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 900 | Loss: 0.21540 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1000 | Loss: 0.09390 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1100 | Loss: 0.11972 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1200 | Loss: 0.21667 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1300 | Loss: 0.02920 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1400 | Loss: 0.10585 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1500 | Loss: 0.15050 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1600 | Loss: 0.29313 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1700 | Loss: 0.34517 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1800 | Loss: 0.05065 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 1900 | Loss: 0.00656 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2000 | Loss: 0.05385 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2100 | Loss: 0.07113 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2200 | Loss: 0.04701 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2300 | Loss: 0.03000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2400 | Loss: 0.30734 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2500 | Loss: 0.15656 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2600 | Loss: 0.31324 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2700 | Loss: 0.05736 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2800 | Loss: 0.04271 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 006 | Batch: 2900 | Loss: 0.26226 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 0.09881 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 100 | Loss: 0.17793 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 200 | Loss: 0.15829 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 300 | Loss: 0.08333 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 400 | Loss: 0.13037 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 500 | Loss: 0.10446 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 600 | Loss: 0.03056 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 700 | Loss: 0.15354 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 800 | Loss: 0.08928 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 900 | Loss: 0.04487 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1000 | Loss: 0.10205 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1100 | Loss: 0.12585 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1200 | Loss: 0.08632 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1300 | Loss: 0.03982 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1400 | Loss: 0.10395 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1500 | Loss: 0.06113 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1600 | Loss: 0.03314 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1700 | Loss: 0.03934 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1800 | Loss: 0.22723 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 1900 | Loss: 0.03073 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2000 | Loss: 0.07758 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2100 | Loss: 0.02899 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2200 | Loss: 0.21132 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2300 | Loss: 0.21813 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2400 | Loss: 0.24903 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2500 | Loss: 0.15997 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2600 | Loss: 0.15201 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2700 | Loss: 0.02201 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2800 | Loss: 0.14299 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 006 | Batch: 2900 | Loss: 0.23056 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 0.09245 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 100 | Loss: 0.03837 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 200 | Loss: 0.01614 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 300 | Loss: 0.08004 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 400 | Loss: 0.09831 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 500 | Loss: 0.07297 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 600 | Loss: 0.02101 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 700 | Loss: 0.02359 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 800 | Loss: 0.06983 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 900 | Loss: 0.03978 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1000 | Loss: 0.12226 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1100 | Loss: 0.03750 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1200 | Loss: 0.17942 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1300 | Loss: 0.20947 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1400 | Loss: 0.02241 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1500 | Loss: 0.05800 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1600 | Loss: 0.34569 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1700 | Loss: 0.10399 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1800 | Loss: 0.01347 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 1900 | Loss: 0.08366 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2000 | Loss: 0.24556 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2100 | Loss: 0.05691 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2200 | Loss: 0.03953 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2300 | Loss: 0.22032 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2400 | Loss: 0.27654 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2500 | Loss: 0.04737 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2600 | Loss: 0.10500 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2700 | Loss: 0.43897 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2800 | Loss: 0.13202 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 006 | Batch: 2900 | Loss: 0.10793 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 0.15610 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 100 | Loss: 0.13959 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 200 | Loss: 0.02601 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 300 | Loss: 0.14127 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 400 | Loss: 0.31281 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 500 | Loss: 0.17177 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 600 | Loss: 0.12861 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 700 | Loss: 0.06888 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 800 | Loss: 0.05625 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 900 | Loss: 0.21397 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1000 | Loss: 0.24508 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1100 | Loss: 0.02862 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1200 | Loss: 0.13429 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1300 | Loss: 0.08298 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1400 | Loss: 0.25820 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1500 | Loss: 0.06645 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1600 | Loss: 0.01200 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1700 | Loss: 0.05726 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1800 | Loss: 0.14622 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 1900 | Loss: 0.07907 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2000 | Loss: 0.12946 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2100 | Loss: 0.17128 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2200 | Loss: 0.06574 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2300 | Loss: 0.14600 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2400 | Loss: 0.26265 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2500 | Loss: 0.08959 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2600 | Loss: 0.26570 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2700 | Loss: 0.24067 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2800 | Loss: 0.12751 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 006 | Batch: 2900 | Loss: 0.01696 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 0.02151 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 100 | Loss: 0.14723 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 200 | Loss: 0.15683 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 300 | Loss: 0.23004 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 400 | Loss: 0.03324 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 500 | Loss: 0.11416 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 600 | Loss: 0.03678 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 700 | Loss: 0.00979 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 800 | Loss: 0.09208 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 900 | Loss: 0.22532 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1000 | Loss: 0.01603 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1100 | Loss: 0.03623 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1200 | Loss: 0.06056 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1300 | Loss: 0.00960 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1400 | Loss: 0.04713 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1500 | Loss: 0.02893 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1600 | Loss: 0.05170 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1700 | Loss: 0.17211 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1800 | Loss: 0.06688 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 1900 | Loss: 0.04985 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2000 | Loss: 0.01648 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2100 | Loss: 0.23554 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2200 | Loss: 0.02414 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2300 | Loss: 0.01398 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2400 | Loss: 0.10125 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2500 | Loss: 0.03648 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2600 | Loss: 0.05984 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2700 | Loss: 0.08965 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2800 | Loss: 0.00375 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 007 | Batch: 2900 | Loss: 0.01738 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 0.12210 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 100 | Loss: 0.16208 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 200 | Loss: 0.06469 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 300 | Loss: 0.03916 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 400 | Loss: 0.03979 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 500 | Loss: 0.01169 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 600 | Loss: 0.04168 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 700 | Loss: 0.07771 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 800 | Loss: 0.19182 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 900 | Loss: 0.14574 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1000 | Loss: 0.06332 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1100 | Loss: 0.28758 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1200 | Loss: 0.10346 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1300 | Loss: 0.09353 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1400 | Loss: 0.12643 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1500 | Loss: 0.10166 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1600 | Loss: 0.10893 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1700 | Loss: 0.12137 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1800 | Loss: 0.02656 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 1900 | Loss: 0.05134 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2000 | Loss: 0.06602 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2100 | Loss: 0.13513 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2200 | Loss: 0.25793 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2300 | Loss: 0.03762 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2400 | Loss: 0.08045 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2500 | Loss: 0.00894 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2600 | Loss: 0.14656 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2700 | Loss: 0.13580 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2800 | Loss: 0.21608 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 007 | Batch: 2900 | Loss: 0.12985 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 0.04388 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 100 | Loss: 0.01207 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 200 | Loss: 0.09642 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 300 | Loss: 0.09282 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 400 | Loss: 0.08936 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 500 | Loss: 0.00906 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 600 | Loss: 0.02157 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 700 | Loss: 0.09640 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 800 | Loss: 0.30995 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 900 | Loss: 0.02430 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1000 | Loss: 0.11849 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1100 | Loss: 0.22329 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1200 | Loss: 0.01201 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1300 | Loss: 0.00656 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1400 | Loss: 0.04065 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1500 | Loss: 0.06018 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1600 | Loss: 0.22230 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1700 | Loss: 0.06946 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1800 | Loss: 0.02063 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 1900 | Loss: 0.04478 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2000 | Loss: 0.07788 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2100 | Loss: 0.11638 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2200 | Loss: 0.04277 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2300 | Loss: 0.23685 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2400 | Loss: 0.01931 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2500 | Loss: 0.32993 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2600 | Loss: 0.33458 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2700 | Loss: 0.03402 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2800 | Loss: 0.03790 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 007 | Batch: 2900 | Loss: 0.17735 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 0.06603 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 100 | Loss: 0.06296 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 200 | Loss: 0.03449 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 300 | Loss: 0.01599 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 400 | Loss: 0.01933 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 500 | Loss: 0.10501 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 600 | Loss: 0.08188 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 700 | Loss: 0.02179 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 800 | Loss: 0.04539 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 900 | Loss: 0.05276 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1000 | Loss: 0.03926 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1100 | Loss: 0.00660 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1200 | Loss: 0.00986 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1300 | Loss: 0.22584 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1400 | Loss: 0.10252 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1500 | Loss: 0.09733 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1600 | Loss: 0.02726 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1700 | Loss: 0.08354 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1800 | Loss: 0.04513 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 1900 | Loss: 0.15772 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2000 | Loss: 0.08959 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2100 | Loss: 0.24453 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2200 | Loss: 0.07469 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2300 | Loss: 0.10364 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2400 | Loss: 0.09748 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2500 | Loss: 0.13909 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2600 | Loss: 0.06031 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2700 | Loss: 0.12467 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2800 | Loss: 0.03407 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 007 | Batch: 2900 | Loss: 0.14998 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 0.01166 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 100 | Loss: 0.02948 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 200 | Loss: 0.00979 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 300 | Loss: 0.03937 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 400 | Loss: 0.07838 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 500 | Loss: 0.05677 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 600 | Loss: 0.01459 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 700 | Loss: 0.12192 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 800 | Loss: 0.07395 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 900 | Loss: 0.08743 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1000 | Loss: 0.01163 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1100 | Loss: 0.01968 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1200 | Loss: 0.07665 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1300 | Loss: 0.01731 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1400 | Loss: 0.00708 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1500 | Loss: 0.07943 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1600 | Loss: 0.02722 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1700 | Loss: 0.00649 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1800 | Loss: 0.12980 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 1900 | Loss: 0.00661 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2000 | Loss: 0.18061 | Correct: 29/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2100 | Loss: 0.02480 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2200 | Loss: 0.03374 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2300 | Loss: 0.03511 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2400 | Loss: 0.03159 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2500 | Loss: 0.08107 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2600 | Loss: 0.03481 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2700 | Loss: 0.07627 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2800 | Loss: 0.04731 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 008 | Batch: 2900 | Loss: 0.09284 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 0.06802 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 100 | Loss: 0.00347 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 200 | Loss: 0.12121 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 300 | Loss: 0.05135 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 400 | Loss: 0.03395 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 500 | Loss: 0.05643 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 600 | Loss: 0.19665 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 700 | Loss: 0.02390 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 800 | Loss: 0.01386 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 900 | Loss: 0.01523 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1000 | Loss: 0.13545 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1100 | Loss: 0.03700 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1200 | Loss: 0.00120 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1300 | Loss: 0.04645 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1400 | Loss: 0.20375 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1500 | Loss: 0.04684 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1600 | Loss: 0.06935 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1700 | Loss: 0.02064 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1800 | Loss: 0.11097 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 1900 | Loss: 0.21085 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2000 | Loss: 0.08426 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2100 | Loss: 0.05537 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2200 | Loss: 0.08673 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2300 | Loss: 0.03821 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2400 | Loss: 0.05634 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2500 | Loss: 0.03193 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2600 | Loss: 0.12552 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2700 | Loss: 0.05271 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2800 | Loss: 0.06589 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 008 | Batch: 2900 | Loss: 0.14391 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 0.04902 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 100 | Loss: 0.08108 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 200 | Loss: 0.00537 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 300 | Loss: 0.03017 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 400 | Loss: 0.00975 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 500 | Loss: 0.01063 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 600 | Loss: 0.01229 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 700 | Loss: 0.01085 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 800 | Loss: 0.07344 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 900 | Loss: 0.00367 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1000 | Loss: 0.13061 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1100 | Loss: 0.04162 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1200 | Loss: 0.15976 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1300 | Loss: 0.06603 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1400 | Loss: 0.02285 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1500 | Loss: 0.11681 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1600 | Loss: 0.22167 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1700 | Loss: 0.02617 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1800 | Loss: 0.06801 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 1900 | Loss: 0.06242 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2000 | Loss: 0.01487 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2100 | Loss: 0.03149 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2200 | Loss: 0.16965 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2300 | Loss: 0.03538 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2400 | Loss: 0.02758 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2500 | Loss: 0.01383 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2600 | Loss: 0.06783 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2700 | Loss: 0.06620 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2800 | Loss: 0.16900 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 008 | Batch: 2900 | Loss: 0.15277 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 0.00198 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 100 | Loss: 0.06475 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 200 | Loss: 0.00617 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 300 | Loss: 0.02304 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 400 | Loss: 0.12386 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 500 | Loss: 0.05109 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 600 | Loss: 0.01693 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 700 | Loss: 0.04948 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 800 | Loss: 0.01967 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 900 | Loss: 0.01758 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1000 | Loss: 0.03154 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1100 | Loss: 0.11776 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1200 | Loss: 0.03756 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1300 | Loss: 0.10921 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1400 | Loss: 0.01108 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1500 | Loss: 0.09605 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1600 | Loss: 0.16492 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1700 | Loss: 0.03246 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1800 | Loss: 0.01806 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 1900 | Loss: 0.10491 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2000 | Loss: 0.00452 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2100 | Loss: 0.01375 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2200 | Loss: 0.04056 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2300 | Loss: 0.06361 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2400 | Loss: 0.02562 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2500 | Loss: 0.08485 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2600 | Loss: 0.06130 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2700 | Loss: 0.03598 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2800 | Loss: 0.01508 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 008 | Batch: 2900 | Loss: 0.11357 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 0.05778 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 100 | Loss: 0.12129 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 200 | Loss: 0.03839 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 300 | Loss: 0.17019 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 400 | Loss: 0.07518 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 500 | Loss: 0.07359 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 600 | Loss: 0.11503 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 700 | Loss: 0.13487 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 800 | Loss: 0.06563 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 900 | Loss: 0.00517 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1000 | Loss: 0.00299 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1100 | Loss: 0.01701 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1200 | Loss: 0.02917 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1300 | Loss: 0.00073 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1400 | Loss: 0.12001 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1500 | Loss: 0.01528 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1600 | Loss: 0.10581 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1700 | Loss: 0.04878 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1800 | Loss: 0.04528 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 1900 | Loss: 0.04543 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2000 | Loss: 0.00731 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2100 | Loss: 0.01543 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2200 | Loss: 0.01160 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2300 | Loss: 0.03757 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2400 | Loss: 0.01003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2500 | Loss: 0.05736 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2600 | Loss: 0.05506 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2700 | Loss: 0.02758 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2800 | Loss: 0.11914 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 009 | Batch: 2900 | Loss: 0.05717 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 0.06577 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 100 | Loss: 0.00510 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 200 | Loss: 0.06785 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 300 | Loss: 0.16689 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 400 | Loss: 0.02712 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 500 | Loss: 0.00854 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 600 | Loss: 0.13839 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 700 | Loss: 0.06688 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 800 | Loss: 0.06018 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 900 | Loss: 0.08492 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1000 | Loss: 0.01480 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1100 | Loss: 0.01939 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1200 | Loss: 0.01367 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1300 | Loss: 0.01807 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1400 | Loss: 0.03157 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1500 | Loss: 0.07570 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1600 | Loss: 0.08899 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1700 | Loss: 0.01055 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1800 | Loss: 0.01639 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 1900 | Loss: 0.09635 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2000 | Loss: 0.02682 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2100 | Loss: 0.04485 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2200 | Loss: 0.09390 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2300 | Loss: 0.00148 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2400 | Loss: 0.07663 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2500 | Loss: 0.11485 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2600 | Loss: 0.02643 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2700 | Loss: 0.01143 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2800 | Loss: 0.01426 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 009 | Batch: 2900 | Loss: 0.02057 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 0.09495 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 100 | Loss: 0.01270 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 200 | Loss: 0.04999 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 300 | Loss: 0.03064 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 400 | Loss: 0.01593 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 500 | Loss: 0.09979 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 600 | Loss: 0.12107 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 700 | Loss: 0.03681 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 800 | Loss: 0.03256 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 900 | Loss: 0.02113 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1000 | Loss: 0.14703 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1100 | Loss: 0.00715 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1200 | Loss: 0.00468 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1300 | Loss: 0.01177 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1400 | Loss: 0.04269 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1500 | Loss: 0.03264 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1600 | Loss: 0.02564 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1700 | Loss: 0.04306 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1800 | Loss: 0.01475 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 1900 | Loss: 0.04169 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2000 | Loss: 0.01803 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2100 | Loss: 0.09319 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2200 | Loss: 0.04555 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2300 | Loss: 0.08323 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2400 | Loss: 0.02332 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2500 | Loss: 0.00376 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2600 | Loss: 0.02865 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2700 | Loss: 0.02253 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2800 | Loss: 0.21947 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 009 | Batch: 2900 | Loss: 0.00823 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 0.01532 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 100 | Loss: 0.01041 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 200 | Loss: 0.00078 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 300 | Loss: 0.01538 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 400 | Loss: 0.00892 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 500 | Loss: 0.09103 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 600 | Loss: 0.02833 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 700 | Loss: 0.00256 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 800 | Loss: 0.05183 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 900 | Loss: 0.00042 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1000 | Loss: 0.04360 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1100 | Loss: 0.02062 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1200 | Loss: 0.04305 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1300 | Loss: 0.04544 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1400 | Loss: 0.22229 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1500 | Loss: 0.03855 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1600 | Loss: 0.01644 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1700 | Loss: 0.12250 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1800 | Loss: 0.01656 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 1900 | Loss: 0.19258 | Correct: 29/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2000 | Loss: 0.08996 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2100 | Loss: 0.02758 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2200 | Loss: 0.01765 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2300 | Loss: 0.03433 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2400 | Loss: 0.21491 | Correct: 28/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2500 | Loss: 0.01928 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2600 | Loss: 0.04964 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2700 | Loss: 0.01757 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2800 | Loss: 0.13075 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 009 | Batch: 2900 | Loss: 0.02891 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 000 | Loss: 0.02116 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 100 | Loss: 0.01222 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 200 | Loss: 0.01337 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 300 | Loss: 0.01134 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 400 | Loss: 0.00702 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 500 | Loss: 0.00223 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 600 | Loss: 0.00625 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 700 | Loss: 0.07379 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 800 | Loss: 0.11626 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 900 | Loss: 0.04846 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1000 | Loss: 0.00775 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1100 | Loss: 0.02115 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1200 | Loss: 0.02086 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1300 | Loss: 0.00249 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1400 | Loss: 0.00167 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1500 | Loss: 0.00489 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1600 | Loss: 0.01961 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1700 | Loss: 0.01369 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1800 | Loss: 0.00165 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 1900 | Loss: 0.15142 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2000 | Loss: 0.00127 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2100 | Loss: 0.01346 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2200 | Loss: 0.00829 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2300 | Loss: 0.00527 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2400 | Loss: 0.30689 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2500 | Loss: 0.00055 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2600 | Loss: 0.00921 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2700 | Loss: 0.00528 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2800 | Loss: 0.01113 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 010 | Batch: 2900 | Loss: 0.02680 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 000 | Loss: 0.00403 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 100 | Loss: 0.00768 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 200 | Loss: 0.00928 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 300 | Loss: 0.03366 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 400 | Loss: 0.02474 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 500 | Loss: 0.00969 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 600 | Loss: 0.00031 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 700 | Loss: 0.00344 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 800 | Loss: 0.03773 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 900 | Loss: 0.03728 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1000 | Loss: 0.00308 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1100 | Loss: 0.00833 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1200 | Loss: 0.10489 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1300 | Loss: 0.02949 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1400 | Loss: 0.04312 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1500 | Loss: 0.00642 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1600 | Loss: 0.08065 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1700 | Loss: 0.02351 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1800 | Loss: 0.00071 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 1900 | Loss: 0.12394 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2000 | Loss: 0.18970 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2100 | Loss: 0.13855 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2200 | Loss: 0.01071 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2300 | Loss: 0.02558 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2400 | Loss: 0.00513 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2500 | Loss: 0.01523 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2600 | Loss: 0.00845 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2700 | Loss: 0.07711 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2800 | Loss: 0.04413 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 010 | Batch: 2900 | Loss: 0.00572 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 000 | Loss: 0.00137 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 100 | Loss: 0.01102 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 200 | Loss: 0.00544 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 300 | Loss: 0.07431 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 400 | Loss: 0.00221 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 500 | Loss: 0.01603 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 600 | Loss: 0.00419 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 700 | Loss: 0.01141 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 800 | Loss: 0.05614 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 900 | Loss: 0.00415 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1000 | Loss: 0.12367 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1100 | Loss: 0.00438 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1200 | Loss: 0.11597 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1300 | Loss: 0.07610 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1400 | Loss: 0.00611 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1500 | Loss: 0.01586 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1600 | Loss: 0.06334 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1700 | Loss: 0.02229 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1800 | Loss: 0.00443 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 1900 | Loss: 0.01572 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2000 | Loss: 0.15979 | Correct: 29/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2100 | Loss: 0.02618 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2200 | Loss: 0.10266 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2300 | Loss: 0.02318 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2400 | Loss: 0.01655 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2500 | Loss: 0.01820 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2600 | Loss: 0.08095 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2700 | Loss: 0.01673 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2800 | Loss: 0.07166 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 010 | Batch: 2900 | Loss: 0.01193 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 000 | Loss: 0.00306 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 100 | Loss: 0.02212 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 200 | Loss: 0.00569 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 300 | Loss: 0.00309 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 400 | Loss: 0.00525 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 500 | Loss: 0.01099 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 600 | Loss: 0.00485 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 700 | Loss: 0.14492 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 800 | Loss: 0.00131 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 900 | Loss: 0.09395 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1000 | Loss: 0.01183 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1100 | Loss: 0.10048 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1200 | Loss: 0.05217 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1300 | Loss: 0.00115 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1400 | Loss: 0.00867 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1500 | Loss: 0.01476 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1600 | Loss: 0.00134 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1700 | Loss: 0.03585 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1800 | Loss: 0.06920 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 1900 | Loss: 0.00358 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2000 | Loss: 0.00150 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2100 | Loss: 0.04731 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2200 | Loss: 0.03098 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2300 | Loss: 0.13087 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2400 | Loss: 0.01816 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2500 | Loss: 0.01829 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2600 | Loss: 0.00550 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2700 | Loss: 0.03918 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2800 | Loss: 0.01424 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 010 | Batch: 2900 | Loss: 0.03632 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 000 | Loss: 0.00336 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 100 | Loss: 0.00234 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 200 | Loss: 0.00709 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 300 | Loss: 0.01386 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 400 | Loss: 0.00184 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 500 | Loss: 0.00896 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 600 | Loss: 0.03778 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 700 | Loss: 0.10634 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 800 | Loss: 0.05827 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 900 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1000 | Loss: 0.00200 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1100 | Loss: 0.02470 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1200 | Loss: 0.00435 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1300 | Loss: 0.00491 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1400 | Loss: 0.00378 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1500 | Loss: 0.08692 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1600 | Loss: 0.00607 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1700 | Loss: 0.03186 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1800 | Loss: 0.00269 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 1900 | Loss: 0.00323 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2000 | Loss: 0.01305 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2100 | Loss: 0.25682 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2200 | Loss: 0.04362 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2300 | Loss: 0.01614 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2400 | Loss: 0.00411 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2500 | Loss: 0.00618 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2600 | Loss: 0.00255 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2700 | Loss: 0.00282 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2800 | Loss: 0.07303 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 011 | Batch: 2900 | Loss: 0.04995 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 000 | Loss: 0.10395 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 100 | Loss: 0.04432 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 200 | Loss: 0.07664 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 300 | Loss: 0.00074 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 400 | Loss: 0.00170 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 500 | Loss: 0.00255 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 600 | Loss: 0.04836 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 700 | Loss: 0.00149 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 800 | Loss: 0.05915 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 900 | Loss: 0.03037 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1000 | Loss: 0.05164 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1100 | Loss: 0.03718 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1200 | Loss: 0.00852 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1300 | Loss: 0.00568 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1400 | Loss: 0.00386 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1500 | Loss: 0.00658 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1600 | Loss: 0.00381 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1700 | Loss: 0.04419 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1800 | Loss: 0.00537 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 1900 | Loss: 0.04010 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2000 | Loss: 0.00844 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2100 | Loss: 0.00701 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2200 | Loss: 0.00752 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2300 | Loss: 0.15746 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2400 | Loss: 0.00618 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2500 | Loss: 0.05319 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2600 | Loss: 0.00514 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2700 | Loss: 0.00393 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2800 | Loss: 0.00738 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 011 | Batch: 2900 | Loss: 0.00294 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 000 | Loss: 0.00520 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 100 | Loss: 0.00112 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 200 | Loss: 0.02298 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 300 | Loss: 0.02421 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 400 | Loss: 0.01424 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 500 | Loss: 0.04255 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 600 | Loss: 0.00272 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 700 | Loss: 0.00185 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 800 | Loss: 0.00114 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 900 | Loss: 0.04563 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1000 | Loss: 0.01411 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1100 | Loss: 0.11888 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1200 | Loss: 0.05225 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1300 | Loss: 0.00951 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1400 | Loss: 0.02592 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1500 | Loss: 0.00038 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1600 | Loss: 0.01451 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1700 | Loss: 0.00782 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1800 | Loss: 0.16924 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 1900 | Loss: 0.01105 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2000 | Loss: 0.09418 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2100 | Loss: 0.04635 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2200 | Loss: 0.08284 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2300 | Loss: 0.01102 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2400 | Loss: 0.00420 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2500 | Loss: 0.02183 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2600 | Loss: 0.06351 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2700 | Loss: 0.00312 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2800 | Loss: 0.02131 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 011 | Batch: 2900 | Loss: 0.00098 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 000 | Loss: 0.06738 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 100 | Loss: 0.04464 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 200 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 300 | Loss: 0.02052 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 400 | Loss: 0.00282 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 500 | Loss: 0.01890 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 600 | Loss: 0.00127 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 700 | Loss: 0.00887 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 800 | Loss: 0.09232 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 900 | Loss: 0.00456 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1000 | Loss: 0.13211 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1100 | Loss: 0.09621 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1200 | Loss: 0.00182 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1300 | Loss: 0.01297 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1400 | Loss: 0.00719 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1500 | Loss: 0.07404 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1600 | Loss: 0.00600 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1700 | Loss: 0.00341 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1800 | Loss: 0.00268 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 1900 | Loss: 0.00368 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2000 | Loss: 0.01733 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2100 | Loss: 0.01306 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2200 | Loss: 0.02205 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2300 | Loss: 0.01555 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2400 | Loss: 0.15222 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2500 | Loss: 0.00163 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2600 | Loss: 0.02197 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2700 | Loss: 0.03324 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2800 | Loss: 0.13176 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 011 | Batch: 2900 | Loss: 0.00417 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 000 | Loss: 0.03471 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 100 | Loss: 0.00129 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 200 | Loss: 0.01373 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 300 | Loss: 0.00360 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 400 | Loss: 0.00638 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 500 | Loss: 0.05941 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 600 | Loss: 0.00170 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 700 | Loss: 0.00140 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 800 | Loss: 0.00787 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 900 | Loss: 0.03783 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1000 | Loss: 0.00677 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1100 | Loss: 0.06571 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1200 | Loss: 0.01082 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1300 | Loss: 0.00488 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1400 | Loss: 0.02841 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1500 | Loss: 0.00291 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1600 | Loss: 0.11802 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1700 | Loss: 0.00507 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1800 | Loss: 0.06395 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 1900 | Loss: 0.00089 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2000 | Loss: 0.16937 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2100 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2200 | Loss: 0.00490 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2300 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2400 | Loss: 0.00349 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2500 | Loss: 0.02563 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2600 | Loss: 0.00042 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2700 | Loss: 0.05005 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2800 | Loss: 0.00046 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 012 | Batch: 2900 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 000 | Loss: 0.01617 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 100 | Loss: 0.02531 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 200 | Loss: 0.00089 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 300 | Loss: 0.03707 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 400 | Loss: 0.02596 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 500 | Loss: 0.00988 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 600 | Loss: 0.07470 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 700 | Loss: 0.17802 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 800 | Loss: 0.06886 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 900 | Loss: 0.03106 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1000 | Loss: 0.00933 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1100 | Loss: 0.00487 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1200 | Loss: 0.00316 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1300 | Loss: 0.00071 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1400 | Loss: 0.25019 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1500 | Loss: 0.00163 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1600 | Loss: 0.03555 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1700 | Loss: 0.05529 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1800 | Loss: 0.00786 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 1900 | Loss: 0.15814 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2000 | Loss: 0.01362 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2100 | Loss: 0.00855 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2200 | Loss: 0.01383 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2300 | Loss: 0.00035 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2400 | Loss: 0.00159 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2500 | Loss: 0.00562 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2600 | Loss: 0.00334 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2700 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2800 | Loss: 0.10204 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 012 | Batch: 2900 | Loss: 0.06771 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 000 | Loss: 0.00623 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 100 | Loss: 0.00091 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 200 | Loss: 0.01942 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 300 | Loss: 0.00604 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 400 | Loss: 0.00065 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 500 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 600 | Loss: 0.07112 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 700 | Loss: 0.01511 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 800 | Loss: 0.15836 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 900 | Loss: 0.00078 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1000 | Loss: 0.02618 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1100 | Loss: 0.13872 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1200 | Loss: 0.15481 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1300 | Loss: 0.00777 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1400 | Loss: 0.01243 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1500 | Loss: 0.00801 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1600 | Loss: 0.02898 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1700 | Loss: 0.00327 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1800 | Loss: 0.07604 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 1900 | Loss: 0.03263 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2000 | Loss: 0.00115 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2100 | Loss: 0.03254 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2200 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2300 | Loss: 0.04351 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2400 | Loss: 0.14766 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2500 | Loss: 0.01660 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2600 | Loss: 0.01564 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2700 | Loss: 0.02007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2800 | Loss: 0.00061 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 012 | Batch: 2900 | Loss: 0.01406 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 000 | Loss: 0.00154 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 100 | Loss: 0.00457 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 200 | Loss: 0.00102 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 300 | Loss: 0.00373 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 400 | Loss: 0.05277 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 500 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 600 | Loss: 0.00212 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 700 | Loss: 0.03906 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 800 | Loss: 0.00416 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 900 | Loss: 0.01857 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1000 | Loss: 0.00121 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1100 | Loss: 0.08040 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1200 | Loss: 0.00447 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1300 | Loss: 0.00121 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1400 | Loss: 0.07255 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1500 | Loss: 0.09222 | Correct: 30/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1700 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1800 | Loss: 0.00343 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 1900 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2000 | Loss: 0.04359 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2100 | Loss: 0.00339 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2200 | Loss: 0.00119 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2300 | Loss: 0.00928 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2400 | Loss: 0.00442 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2500 | Loss: 0.00147 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2600 | Loss: 0.00218 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2700 | Loss: 0.00221 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2800 | Loss: 0.02618 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 012 | Batch: 2900 | Loss: 0.06017 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 000 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 100 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 200 | Loss: 0.02053 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 300 | Loss: 0.00756 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 400 | Loss: 0.00030 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 500 | Loss: 0.00650 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 600 | Loss: 0.00085 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 700 | Loss: 0.02888 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 800 | Loss: 0.00136 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 900 | Loss: 0.03545 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1000 | Loss: 0.05169 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1100 | Loss: 0.01778 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1200 | Loss: 0.01091 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1300 | Loss: 0.00434 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1400 | Loss: 0.01432 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1500 | Loss: 0.00983 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1600 | Loss: 0.12602 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1700 | Loss: 0.18396 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1800 | Loss: 0.00420 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 1900 | Loss: 0.12124 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2000 | Loss: 0.04587 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2100 | Loss: 0.02015 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2200 | Loss: 0.00861 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2300 | Loss: 0.00255 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2400 | Loss: 0.11529 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2500 | Loss: 0.01220 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2600 | Loss: 0.13788 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2700 | Loss: 0.04136 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2800 | Loss: 0.09039 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 013 | Batch: 2900 | Loss: 0.00074 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 000 | Loss: 0.02078 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 100 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 200 | Loss: 0.01599 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 300 | Loss: 0.06513 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 400 | Loss: 0.00136 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 500 | Loss: 0.00625 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 600 | Loss: 0.11225 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 700 | Loss: 0.14375 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 800 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 900 | Loss: 0.00402 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1000 | Loss: 0.00784 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1100 | Loss: 0.00190 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1200 | Loss: 0.00328 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1300 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1400 | Loss: 0.01548 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1500 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1600 | Loss: 0.00271 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1700 | Loss: 0.02257 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1800 | Loss: 0.00043 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 1900 | Loss: 0.07345 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2000 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2100 | Loss: 0.01311 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2200 | Loss: 0.00081 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2300 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2400 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2500 | Loss: 0.00353 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2600 | Loss: 0.00126 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2700 | Loss: 0.00205 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2800 | Loss: 0.00479 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 013 | Batch: 2900 | Loss: 0.03286 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 000 | Loss: 0.00617 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 100 | Loss: 0.00255 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 200 | Loss: 0.09322 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 300 | Loss: 0.02417 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 400 | Loss: 0.00854 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 500 | Loss: 0.02241 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 600 | Loss: 0.00038 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 700 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 800 | Loss: 0.02515 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 900 | Loss: 0.03001 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1000 | Loss: 0.00092 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1100 | Loss: 0.09487 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1200 | Loss: 0.03951 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1300 | Loss: 0.14390 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1400 | Loss: 0.02601 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1500 | Loss: 0.00939 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1600 | Loss: 0.00038 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1700 | Loss: 0.00056 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1800 | Loss: 0.06521 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 1900 | Loss: 0.04105 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2000 | Loss: 0.06141 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2100 | Loss: 0.04328 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2200 | Loss: 0.12588 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2300 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2400 | Loss: 0.01738 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2500 | Loss: 0.06647 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2600 | Loss: 0.00532 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2700 | Loss: 0.03771 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2800 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 013 | Batch: 2900 | Loss: 0.00799 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 000 | Loss: 0.11348 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 100 | Loss: 0.00960 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 200 | Loss: 0.00143 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 300 | Loss: 0.00658 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 400 | Loss: 0.00507 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 500 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 600 | Loss: 0.01918 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 700 | Loss: 0.00529 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 800 | Loss: 0.00373 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 900 | Loss: 0.00612 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1000 | Loss: 0.00323 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1100 | Loss: 0.00109 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1200 | Loss: 0.03517 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1300 | Loss: 0.00290 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1400 | Loss: 0.02841 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1500 | Loss: 0.03325 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1600 | Loss: 0.03265 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1700 | Loss: 0.01809 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1800 | Loss: 0.00812 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 1900 | Loss: 0.00245 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2000 | Loss: 0.01759 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2100 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2200 | Loss: 0.00684 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2300 | Loss: 0.03524 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2400 | Loss: 0.00144 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2500 | Loss: 0.00865 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2600 | Loss: 0.00339 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2700 | Loss: 0.00379 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2800 | Loss: 0.00138 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 013 | Batch: 2900 | Loss: 0.00521 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 000 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 100 | Loss: 0.00164 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 200 | Loss: 0.00049 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 300 | Loss: 0.04916 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 400 | Loss: 0.00353 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 500 | Loss: 0.00091 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 600 | Loss: 0.00067 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 700 | Loss: 0.00114 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 800 | Loss: 0.00242 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 900 | Loss: 0.08547 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1000 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1200 | Loss: 0.01045 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1300 | Loss: 0.00110 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1400 | Loss: 0.00164 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1500 | Loss: 0.05881 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1600 | Loss: 0.02660 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1700 | Loss: 0.00339 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1800 | Loss: 0.21720 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 1900 | Loss: 0.00247 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2000 | Loss: 0.00044 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2100 | Loss: 0.00105 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2300 | Loss: 0.00134 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2400 | Loss: 0.00085 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2500 | Loss: 0.01251 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2600 | Loss: 0.00282 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2700 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2800 | Loss: 0.02830 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 014 | Batch: 2900 | Loss: 0.00771 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 000 | Loss: 0.00270 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 100 | Loss: 0.01341 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 300 | Loss: 0.01059 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 400 | Loss: 0.00651 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 500 | Loss: 0.00900 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 600 | Loss: 0.00072 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 700 | Loss: 0.00348 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 800 | Loss: 0.01966 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 900 | Loss: 0.11944 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1000 | Loss: 0.00317 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1100 | Loss: 0.09682 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1200 | Loss: 0.00669 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1400 | Loss: 0.00439 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1500 | Loss: 0.00038 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1600 | Loss: 0.08571 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1700 | Loss: 0.00150 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1800 | Loss: 0.02999 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 1900 | Loss: 0.00156 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2000 | Loss: 0.00747 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2100 | Loss: 0.05916 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2300 | Loss: 0.00114 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2400 | Loss: 0.15016 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2500 | Loss: 0.00615 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2600 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2700 | Loss: 0.01585 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2800 | Loss: 0.00284 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 014 | Batch: 2900 | Loss: 0.04757 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 000 | Loss: 0.00040 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 100 | Loss: 0.00024 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 200 | Loss: 0.00027 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 300 | Loss: 0.00687 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 400 | Loss: 0.00109 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 500 | Loss: 0.01203 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 600 | Loss: 0.00032 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 700 | Loss: 0.00087 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 800 | Loss: 0.00499 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 900 | Loss: 0.06280 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1000 | Loss: 0.00204 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1100 | Loss: 0.00103 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1200 | Loss: 0.00580 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1300 | Loss: 0.01168 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1400 | Loss: 0.05993 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1500 | Loss: 0.00674 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1600 | Loss: 0.00454 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1700 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1800 | Loss: 0.01584 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 1900 | Loss: 0.00944 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2000 | Loss: 0.00236 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2100 | Loss: 0.00930 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2200 | Loss: 0.11192 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2300 | Loss: 0.00604 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2400 | Loss: 0.00314 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2500 | Loss: 0.00648 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2600 | Loss: 0.00197 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2700 | Loss: 0.01229 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2800 | Loss: 0.00215 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 014 | Batch: 2900 | Loss: 0.00265 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 000 | Loss: 0.01207 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 100 | Loss: 0.00236 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 200 | Loss: 0.02259 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 300 | Loss: 0.00419 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 400 | Loss: 0.00238 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 500 | Loss: 0.00118 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 600 | Loss: 0.00189 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 700 | Loss: 0.09361 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 800 | Loss: 0.01021 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 900 | Loss: 0.00989 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1000 | Loss: 0.01725 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1100 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1200 | Loss: 0.00569 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1300 | Loss: 0.02484 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1400 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1500 | Loss: 0.00121 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1600 | Loss: 0.00600 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1700 | Loss: 0.04959 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1800 | Loss: 0.01638 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 1900 | Loss: 0.00680 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2000 | Loss: 0.00053 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2100 | Loss: 0.02982 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2200 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2300 | Loss: 0.02956 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2400 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2500 | Loss: 0.00482 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2600 | Loss: 0.00032 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2700 | Loss: 0.00261 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2800 | Loss: 0.00549 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 014 | Batch: 2900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 000 | Loss: 0.00359 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 100 | Loss: 0.08329 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 200 | Loss: 0.00047 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 300 | Loss: 0.00946 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 400 | Loss: 0.01930 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 500 | Loss: 0.00043 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 600 | Loss: 0.00061 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 700 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 800 | Loss: 0.00123 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 900 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1000 | Loss: 0.01349 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1100 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1200 | Loss: 0.00053 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1400 | Loss: 0.00770 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1500 | Loss: 0.01089 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1600 | Loss: 0.00283 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1700 | Loss: 0.06235 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1800 | Loss: 0.00148 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 1900 | Loss: 0.00270 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2000 | Loss: 0.00037 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2100 | Loss: 0.00577 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2200 | Loss: 0.02186 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2300 | Loss: 0.00027 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2400 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2500 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2600 | Loss: 0.01146 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2700 | Loss: 0.08020 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2800 | Loss: 0.08188 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 015 | Batch: 2900 | Loss: 0.01931 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 000 | Loss: 0.00042 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 100 | Loss: 0.04892 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 200 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 300 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 400 | Loss: 0.00359 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 500 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 600 | Loss: 0.01297 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 700 | Loss: 0.00258 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 800 | Loss: 0.00040 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 900 | Loss: 0.09480 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1000 | Loss: 0.00060 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1100 | Loss: 0.00273 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1200 | Loss: 0.06157 | Correct: 30/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1300 | Loss: 0.00044 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1400 | Loss: 0.00064 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1600 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1700 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1800 | Loss: 0.00032 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 1900 | Loss: 0.01226 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2000 | Loss: 0.00127 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2100 | Loss: 0.00579 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2200 | Loss: 0.02893 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2300 | Loss: 0.00262 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2400 | Loss: 0.00340 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2500 | Loss: 0.00036 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2600 | Loss: 0.00807 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2700 | Loss: 0.00172 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2800 | Loss: 0.00080 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 015 | Batch: 2900 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 000 | Loss: 0.00193 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 100 | Loss: 0.00206 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 200 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 300 | Loss: 0.00100 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 400 | Loss: 0.06468 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 500 | Loss: 0.00847 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 600 | Loss: 0.00120 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 700 | Loss: 0.08803 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 800 | Loss: 0.00388 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 900 | Loss: 0.00072 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1000 | Loss: 0.03961 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1100 | Loss: 0.00047 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1200 | Loss: 0.00343 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1300 | Loss: 0.00033 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1400 | Loss: 0.00440 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1500 | Loss: 0.00061 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1600 | Loss: 0.00094 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1700 | Loss: 0.05440 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1800 | Loss: 0.00607 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 1900 | Loss: 0.00048 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2000 | Loss: 0.01679 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2100 | Loss: 0.01345 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2200 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2300 | Loss: 0.01123 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2400 | Loss: 0.10826 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2500 | Loss: 0.00030 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2600 | Loss: 0.00089 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2700 | Loss: 0.00777 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2800 | Loss: 0.00071 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 015 | Batch: 2900 | Loss: 0.02316 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 000 | Loss: 0.00761 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 100 | Loss: 0.00391 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 200 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 300 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 400 | Loss: 0.01154 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 500 | Loss: 0.00330 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 600 | Loss: 0.00079 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 700 | Loss: 0.00037 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 800 | Loss: 0.01139 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 900 | Loss: 0.05383 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1000 | Loss: 0.00269 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1100 | Loss: 0.00142 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1200 | Loss: 0.07739 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1300 | Loss: 0.06057 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1400 | Loss: 0.00716 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1500 | Loss: 0.01717 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1600 | Loss: 0.00828 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1700 | Loss: 0.01041 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1800 | Loss: 0.00172 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2000 | Loss: 0.00116 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2100 | Loss: 0.03809 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2200 | Loss: 0.00328 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2300 | Loss: 0.00347 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2400 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2500 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2600 | Loss: 0.00123 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2700 | Loss: 0.00061 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2800 | Loss: 0.00046 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 015 | Batch: 2900 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 000 | Loss: 0.00058 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 200 | Loss: 0.00091 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 300 | Loss: 0.00777 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 400 | Loss: 0.01291 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 500 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 600 | Loss: 0.00053 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 700 | Loss: 0.00084 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 800 | Loss: 0.00804 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 900 | Loss: 0.00073 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1000 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1100 | Loss: 0.00461 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1300 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1500 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1700 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1800 | Loss: 0.00408 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 1900 | Loss: 0.00255 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2000 | Loss: 0.02171 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2100 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2200 | Loss: 0.00345 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2300 | Loss: 0.00091 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2400 | Loss: 0.00438 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2500 | Loss: 0.01131 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2600 | Loss: 0.00241 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2700 | Loss: 0.04804 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 016 | Batch: 2900 | Loss: 0.00143 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 000 | Loss: 0.00299 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 100 | Loss: 0.00147 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 200 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 300 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 400 | Loss: 0.01889 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 500 | Loss: 0.00027 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 600 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 700 | Loss: 0.00104 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 800 | Loss: 0.00354 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 900 | Loss: 0.00048 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1000 | Loss: 0.00595 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1100 | Loss: 0.00308 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1200 | Loss: 0.05136 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1300 | Loss: 0.01578 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1400 | Loss: 0.00059 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1500 | Loss: 0.00290 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1600 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1700 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1800 | Loss: 0.00063 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 1900 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2000 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2100 | Loss: 0.00245 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2200 | Loss: 0.00274 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2300 | Loss: 0.00074 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2400 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2500 | Loss: 0.00177 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2700 | Loss: 0.02246 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2800 | Loss: 0.00705 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 016 | Batch: 2900 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 100 | Loss: 0.00137 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 200 | Loss: 0.05855 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 300 | Loss: 0.00044 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 400 | Loss: 0.00388 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 500 | Loss: 0.01601 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 600 | Loss: 0.00170 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 700 | Loss: 0.00639 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 800 | Loss: 0.00077 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 900 | Loss: 0.03924 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1000 | Loss: 0.00148 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1100 | Loss: 0.00640 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1200 | Loss: 0.00207 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1300 | Loss: 0.00059 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1400 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1600 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1700 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1800 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 1900 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2000 | Loss: 0.02201 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2100 | Loss: 0.01160 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2200 | Loss: 0.00051 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2400 | Loss: 0.00427 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2500 | Loss: 0.01119 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2600 | Loss: 0.05205 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2700 | Loss: 0.00039 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2800 | Loss: 0.00093 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 016 | Batch: 2900 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 000 | Loss: 0.00086 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 100 | Loss: 0.00290 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 200 | Loss: 0.00346 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 300 | Loss: 0.00066 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 400 | Loss: 0.02304 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 500 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 600 | Loss: 0.00277 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 800 | Loss: 0.00116 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 900 | Loss: 0.01285 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1000 | Loss: 0.03029 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1100 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1200 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1300 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1400 | Loss: 0.00057 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1500 | Loss: 0.00202 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1600 | Loss: 0.00721 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1700 | Loss: 0.00447 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1800 | Loss: 0.00189 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 1900 | Loss: 0.00057 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2000 | Loss: 0.02037 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2100 | Loss: 0.02956 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2200 | Loss: 0.01055 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2300 | Loss: 0.08279 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2500 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2700 | Loss: 0.00361 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 016 | Batch: 2900 | Loss: 0.00133 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 000 | Loss: 0.00054 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 200 | Loss: 0.00511 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 300 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 400 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 500 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 600 | Loss: 0.00454 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 700 | Loss: 0.00278 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 800 | Loss: 0.11262 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 900 | Loss: 0.00024 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1000 | Loss: 0.00092 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1100 | Loss: 0.08890 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1200 | Loss: 0.00144 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1300 | Loss: 0.05487 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1400 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1500 | Loss: 0.00195 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1600 | Loss: 0.01127 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1700 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 1900 | Loss: 0.00300 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2000 | Loss: 0.00049 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2100 | Loss: 0.01349 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2200 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2300 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2400 | Loss: 0.05419 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2500 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2600 | Loss: 0.00211 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2700 | Loss: 0.00110 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2800 | Loss: 0.00363 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 017 | Batch: 2900 | Loss: 0.00072 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 000 | Loss: 0.09110 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 100 | Loss: 0.01715 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 200 | Loss: 0.00031 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 300 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 400 | Loss: 0.00073 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 500 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 700 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 800 | Loss: 0.00244 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 900 | Loss: 0.00206 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1000 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1100 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1200 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1300 | Loss: 0.00467 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1400 | Loss: 0.00037 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1500 | Loss: 0.00060 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1600 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1700 | Loss: 0.02923 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1800 | Loss: 0.00044 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 1900 | Loss: 0.03323 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2000 | Loss: 0.00071 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2100 | Loss: 0.00360 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2200 | Loss: 0.01222 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2300 | Loss: 0.00259 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2400 | Loss: 0.02650 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2500 | Loss: 0.00032 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2600 | Loss: 0.00155 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2700 | Loss: 0.00042 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2800 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 017 | Batch: 2900 | Loss: 0.00513 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 000 | Loss: 0.00126 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 100 | Loss: 0.00505 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 200 | Loss: 0.00083 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 300 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 400 | Loss: 0.00351 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 500 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 600 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 700 | Loss: 0.00047 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 800 | Loss: 0.00463 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 900 | Loss: 0.00279 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1000 | Loss: 0.00091 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1100 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1200 | Loss: 0.00028 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1300 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1500 | Loss: 0.00067 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1600 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1700 | Loss: 0.00090 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1800 | Loss: 0.00740 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 1900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2000 | Loss: 0.00075 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2100 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2200 | Loss: 0.00067 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2300 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2400 | Loss: 0.00223 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2500 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2600 | Loss: 0.00207 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2700 | Loss: 0.00086 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 017 | Batch: 2900 | Loss: 0.00432 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 000 | Loss: 0.00285 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 100 | Loss: 0.00030 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 300 | Loss: 0.00057 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 400 | Loss: 0.00178 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 500 | Loss: 0.00028 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 600 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 700 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 800 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 900 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1000 | Loss: 0.00164 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1200 | Loss: 0.00120 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1400 | Loss: 0.00405 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1500 | Loss: 0.00129 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1600 | Loss: 0.03203 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1700 | Loss: 0.00072 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1800 | Loss: 0.05020 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2200 | Loss: 0.00502 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2300 | Loss: 0.00209 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2400 | Loss: 0.00049 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2500 | Loss: 0.00612 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2600 | Loss: 0.00459 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2700 | Loss: 0.02346 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2800 | Loss: 0.00670 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 017 | Batch: 2900 | Loss: 0.00056 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 100 | Loss: 0.00042 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 200 | Loss: 0.00235 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 300 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 400 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 500 | Loss: 0.00109 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 600 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 800 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 900 | Loss: 0.01588 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1000 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1100 | Loss: 0.01042 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1200 | Loss: 0.01873 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1300 | Loss: 0.00436 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1500 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1600 | Loss: 0.00207 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1700 | Loss: 0.00486 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1800 | Loss: 0.05061 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2100 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2200 | Loss: 0.00099 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2300 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2400 | Loss: 0.02910 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2500 | Loss: 0.01773 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2600 | Loss: 0.12734 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2700 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2800 | Loss: 0.00116 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 018 | Batch: 2900 | Loss: 0.00060 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 000 | Loss: 0.05117 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 100 | Loss: 0.00298 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 200 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 400 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 500 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 600 | Loss: 0.00172 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 700 | Loss: 0.00345 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 800 | Loss: 0.01038 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 900 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1000 | Loss: 0.00075 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1100 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1200 | Loss: 0.00525 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1300 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1400 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1500 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1600 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1700 | Loss: 0.00059 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1800 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2000 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2100 | Loss: 0.00048 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2200 | Loss: 0.00451 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2500 | Loss: 0.00231 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2600 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 018 | Batch: 2900 | Loss: 0.00095 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 000 | Loss: 0.00243 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 100 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 200 | Loss: 0.05501 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 300 | Loss: 0.02090 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 400 | Loss: 0.00250 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 500 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 700 | Loss: 0.00074 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 800 | Loss: 0.00916 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 900 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1000 | Loss: 0.00123 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1400 | Loss: 0.00631 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 1900 | Loss: 0.00090 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2000 | Loss: 0.00167 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2200 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2300 | Loss: 0.00150 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2500 | Loss: 0.00146 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2600 | Loss: 0.00091 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2700 | Loss: 0.00275 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2800 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 018 | Batch: 2900 | Loss: 0.00967 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 200 | Loss: 0.00786 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 300 | Loss: 0.00063 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 400 | Loss: 0.00100 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 500 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 600 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 700 | Loss: 0.00319 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 800 | Loss: 0.00192 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 900 | Loss: 0.05894 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1200 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1300 | Loss: 0.00055 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1400 | Loss: 0.00128 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1500 | Loss: 0.00070 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1600 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1700 | Loss: 0.00200 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1800 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 1900 | Loss: 0.00152 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2000 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2100 | Loss: 0.00160 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2300 | Loss: 0.00165 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2400 | Loss: 0.00214 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2600 | Loss: 0.00424 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2700 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2800 | Loss: 0.00266 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 018 | Batch: 2900 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 000 | Loss: 0.00053 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 200 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 300 | Loss: 0.14469 | Correct: 30/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 500 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 700 | Loss: 0.00100 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 800 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 900 | Loss: 0.00033 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1000 | Loss: 0.00499 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1100 | Loss: 0.03696 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1300 | Loss: 0.00247 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1400 | Loss: 0.00475 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1500 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1600 | Loss: 0.00108 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1700 | Loss: 0.00333 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1800 | Loss: 0.05849 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 1900 | Loss: 0.00315 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2000 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2100 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2200 | Loss: 0.00213 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2300 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2400 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2600 | Loss: 0.02555 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2800 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 019 | Batch: 2900 | Loss: 0.00213 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 000 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 100 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 200 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 300 | Loss: 0.00677 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 400 | Loss: 0.01575 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 500 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 600 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 700 | Loss: 0.04747 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 800 | Loss: 0.00099 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 900 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1000 | Loss: 0.00031 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1100 | Loss: 0.00035 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1200 | Loss: 0.00027 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1300 | Loss: 0.00082 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1500 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1600 | Loss: 0.00885 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1700 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1800 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 1900 | Loss: 0.00094 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2000 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2200 | Loss: 0.00487 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2300 | Loss: 0.00386 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2400 | Loss: 0.00890 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2500 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2700 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2800 | Loss: 0.10011 | Correct: 31/32\n",
            "Estimator: 001 | Epoch: 019 | Batch: 2900 | Loss: 0.00256 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 000 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 100 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 200 | Loss: 0.00262 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 400 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 600 | Loss: 0.00581 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 900 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1000 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1200 | Loss: 0.00078 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1400 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1500 | Loss: 0.01384 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1700 | Loss: 0.00362 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1800 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 1900 | Loss: 0.00185 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2200 | Loss: 0.00372 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2300 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2500 | Loss: 0.00786 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2600 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2700 | Loss: 0.00110 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2800 | Loss: 0.01779 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 019 | Batch: 2900 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 000 | Loss: 0.00432 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 300 | Loss: 0.00359 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 400 | Loss: 0.00143 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 500 | Loss: 0.00152 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 600 | Loss: 0.02414 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 700 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 800 | Loss: 0.00043 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 900 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1000 | Loss: 0.00117 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1100 | Loss: 0.00077 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1200 | Loss: 0.00079 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1300 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1400 | Loss: 0.00069 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1500 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1600 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1700 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1800 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 1900 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2100 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2300 | Loss: 0.00051 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2400 | Loss: 0.00101 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2500 | Loss: 0.02354 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2600 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2700 | Loss: 0.00102 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 019 | Batch: 2900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 000 | Loss: 0.00040 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 100 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 200 | Loss: 0.15392 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 300 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 500 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 700 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1000 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1100 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1300 | Loss: 0.00302 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1500 | Loss: 0.00185 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1600 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1800 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 1900 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2000 | Loss: 0.00036 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2100 | Loss: 0.00286 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2200 | Loss: 0.00168 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2400 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2500 | Loss: 0.00035 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2700 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 020 | Batch: 2900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 000 | Loss: 0.01617 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 100 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 200 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 300 | Loss: 0.00042 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 400 | Loss: 0.00241 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 700 | Loss: 0.00100 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 900 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1100 | Loss: 0.00195 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1200 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1400 | Loss: 0.00078 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1500 | Loss: 0.00387 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1600 | Loss: 0.00518 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1700 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1800 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2100 | Loss: 0.00064 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2200 | Loss: 0.00051 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2300 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2400 | Loss: 0.00024 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2500 | Loss: 0.00283 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2600 | Loss: 0.00104 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2700 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2800 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 020 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 000 | Loss: 0.00031 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 200 | Loss: 0.00206 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 300 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 500 | Loss: 0.00027 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 600 | Loss: 0.03641 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 700 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 800 | Loss: 0.00031 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1000 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1200 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1400 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1500 | Loss: 0.04234 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1700 | Loss: 0.10932 | Correct: 30/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1800 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2000 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2300 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2400 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 020 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 100 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 200 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 300 | Loss: 0.00178 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 500 | Loss: 0.00053 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 600 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 700 | Loss: 0.00209 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 900 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1100 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1300 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1500 | Loss: 0.00037 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1600 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1700 | Loss: 0.00090 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1800 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 1900 | Loss: 0.01186 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2000 | Loss: 0.00081 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2100 | Loss: 0.00261 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2200 | Loss: 0.00145 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2400 | Loss: 0.00146 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2500 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2600 | Loss: 0.00255 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2700 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 020 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 000 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 100 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 400 | Loss: 0.00039 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 500 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 600 | Loss: 0.00054 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 800 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 900 | Loss: 0.00024 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1000 | Loss: 0.00067 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1100 | Loss: 0.00533 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1200 | Loss: 0.02237 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1300 | Loss: 0.00895 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1500 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1600 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1700 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1800 | Loss: 0.00300 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 1900 | Loss: 0.00034 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2100 | Loss: 0.00087 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2200 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2300 | Loss: 0.00068 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2700 | Loss: 0.00081 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 021 | Batch: 2900 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 300 | Loss: 0.00063 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 600 | Loss: 0.00033 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 700 | Loss: 0.00038 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1000 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1100 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1200 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1300 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1600 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1700 | Loss: 0.01843 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1800 | Loss: 0.01546 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 1900 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2000 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2400 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2500 | Loss: 0.00086 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2600 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2700 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 021 | Batch: 2900 | Loss: 0.00111 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 000 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 100 | Loss: 0.00349 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 200 | Loss: 0.00051 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 300 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 400 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 500 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 700 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1000 | Loss: 0.00431 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1300 | Loss: 0.00066 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1500 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1600 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 1900 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2100 | Loss: 0.00209 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2400 | Loss: 0.00030 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2500 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2700 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 021 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 000 | Loss: 0.00027 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 100 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 400 | Loss: 0.00176 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 900 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1100 | Loss: 0.00086 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1400 | Loss: 0.05605 | Correct: 31/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1600 | Loss: 0.00028 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 1900 | Loss: 0.00192 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2000 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2100 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2200 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2500 | Loss: 0.00063 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2600 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2700 | Loss: 0.00572 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 021 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 300 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 400 | Loss: 0.00302 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 600 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 800 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1000 | Loss: 0.00089 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1100 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1300 | Loss: 0.00054 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1400 | Loss: 0.00057 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1500 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1600 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2100 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2200 | Loss: 0.00024 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2500 | Loss: 0.00033 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2600 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2700 | Loss: 0.00062 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2800 | Loss: 0.00725 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 022 | Batch: 2900 | Loss: 0.00212 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 000 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 200 | Loss: 0.00111 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 500 | Loss: 0.00244 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 700 | Loss: 0.00047 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 800 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1000 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1100 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1200 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1300 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1500 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1800 | Loss: 0.01362 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 1900 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2000 | Loss: 0.00275 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2200 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2700 | Loss: 0.00035 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 022 | Batch: 2900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 000 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 100 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 200 | Loss: 0.00168 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 300 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 700 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 800 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1000 | Loss: 0.00092 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1200 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1300 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1600 | Loss: 0.00033 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1700 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1800 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 1900 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2100 | Loss: 0.01756 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2600 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2800 | Loss: 0.05552 | Correct: 31/32\n",
            "Estimator: 002 | Epoch: 022 | Batch: 2900 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 400 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 700 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 900 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1000 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1300 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1400 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1700 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2000 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2100 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2300 | Loss: 0.00367 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2400 | Loss: 0.00108 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2500 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2800 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 022 | Batch: 2900 | Loss: 0.01029 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 100 | Loss: 0.00030 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 200 | Loss: 0.00390 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 600 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1000 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1100 | Loss: 0.00023 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1300 | Loss: 0.00075 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1400 | Loss: 0.00040 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1500 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 1900 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2100 | Loss: 0.00157 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2300 | Loss: 0.00168 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2500 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2600 | Loss: 0.00025 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2700 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 023 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 200 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 400 | Loss: 0.00476 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 600 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1200 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1300 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1500 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2200 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2300 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2400 | Loss: 0.00036 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 023 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 300 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 700 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 900 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1000 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1200 | Loss: 0.00058 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1400 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1600 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1700 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1800 | Loss: 0.00563 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2300 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2400 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2500 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 023 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 200 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 800 | Loss: 0.00166 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1000 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1200 | Loss: 0.00035 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1700 | Loss: 0.00069 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1800 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2000 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2200 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2500 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2800 | Loss: 0.00019 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 023 | Batch: 2900 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 600 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 900 | Loss: 0.00024 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1500 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1700 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2000 | Loss: 0.00104 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2100 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2200 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2300 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2500 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 024 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 100 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 200 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 500 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 700 | Loss: 0.00077 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 900 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1000 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1500 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1800 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 1900 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2200 | Loss: 0.00028 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2300 | Loss: 0.00067 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 024 | Batch: 2900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 300 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 400 | Loss: 0.00214 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 700 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1000 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1100 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1500 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1800 | Loss: 0.00017 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2000 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2300 | Loss: 0.00089 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2600 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2700 | Loss: 0.00115 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2800 | Loss: 0.00108 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 024 | Batch: 2900 | Loss: 0.00013 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 100 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 400 | Loss: 0.00114 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 600 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 800 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 900 | Loss: 0.00196 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2100 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2300 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2500 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2800 | Loss: 0.00039 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 024 | Batch: 2900 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 100 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 300 | Loss: 0.00370 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1100 | Loss: 0.00365 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1400 | Loss: 0.00099 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1600 | Loss: 0.00029 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2000 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2400 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 025 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 000 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 100 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 500 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 700 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1100 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1500 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2400 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 025 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 100 | Loss: 0.00109 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 500 | Loss: 0.02204 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 1900 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2700 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2800 | Loss: 0.00116 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 025 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 000 | Loss: 0.00177 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 100 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 200 | Loss: 0.00035 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 400 | Loss: 0.00061 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 700 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1100 | Loss: 0.00075 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1300 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1700 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2200 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2600 | Loss: 0.00056 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2800 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 025 | Batch: 2900 | Loss: 0.04822 | Correct: 31/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 000 | Loss: 0.00020 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 500 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 600 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1400 | Loss: 0.00040 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1600 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2300 | Loss: 0.00040 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2800 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 026 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 000 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 200 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 800 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1500 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1700 | Loss: 0.00036 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2100 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 026 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 200 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1600 | Loss: 0.00186 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1800 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2400 | Loss: 0.00199 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 026 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 300 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 700 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1100 | Loss: 0.00853 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1400 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 026 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 000 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 300 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 500 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 600 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 800 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 900 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1000 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1100 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1400 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1600 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 1900 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2200 | Loss: 0.00015 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 027 | Batch: 2900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 600 | Loss: 0.00009 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1000 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1600 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1700 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2000 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2400 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2500 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2700 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 027 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 000 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 800 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2000 | Loss: 0.00174 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2100 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2400 | Loss: 0.00026 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 027 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 900 | Loss: 0.00697 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1500 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1800 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 1900 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2500 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 027 | Batch: 2900 | Loss: 0.00052 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 800 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1200 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1800 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2700 | Loss: 0.00041 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 028 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 000 | Loss: 0.00012 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 500 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 800 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1100 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1400 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2300 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2500 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2800 | Loss: 0.00011 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 028 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 100 | Loss: 0.00022 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 200 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 300 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 400 | Loss: 0.00070 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 600 | Loss: 0.00028 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1500 | Loss: 0.00010 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1800 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2800 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 028 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 100 | Loss: 0.00004 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2800 | Loss: 0.00005 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 028 | Batch: 2900 | Loss: 0.00021 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 500 | Loss: 0.00059 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1500 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2000 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2500 | Loss: 0.00014 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2800 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 000 | Epoch: 029 | Batch: 2900 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 000 | Loss: 0.00399 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 300 | Loss: 0.00007 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 600 | Loss: 0.00109 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 800 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1200 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2100 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 001 | Epoch: 029 | Batch: 2900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 000 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 500 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 600 | Loss: 0.00016 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 700 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1100 | Loss: 0.00008 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1200 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1400 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1600 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 1900 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2000 | Loss: 0.00018 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2200 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2700 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2800 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 002 | Epoch: 029 | Batch: 2900 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 300 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 400 | Loss: 0.00003 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 500 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1200 | Loss: 0.00006 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1600 | Loss: 0.00002 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 1900 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2000 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2100 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2200 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2300 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2400 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2500 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2600 | Loss: 0.00000 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2700 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2800 | Loss: 0.00001 | Correct: 32/32\n",
            "Estimator: 003 | Epoch: 029 | Batch: 2900 | Loss: 0.00002 | Correct: 32/32\n"
          ]
        }
      ],
      "source": [
        "from torchensemble import VotingClassifier\n",
        "num_epoch = 30\n",
        "model = VotingClassifier(\n",
        "    estimator=new_classifier,\n",
        "    n_estimators=4,\n",
        "    cuda=True,\n",
        ")\n",
        "model.set_optimizer(\"Adam\", lr=0.001)\n",
        "model.set_scheduler(\n",
        "    \"CosineAnnealingLR\",\n",
        "    T_max=30,\n",
        ")\n",
        "\n",
        "model.fit(combine_dataloader, epochs=num_epoch)\n",
        "\n",
        "# for epoch in range(num_epoch):\n",
        "#     loss, acc = new_train_epoch(combine_dataloader)\n",
        "#     print('epoch {:>3d}: train F loss: {:6.4f}, acc {:6.4f}'.format(epoch, loss, acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8_-0iSSje4w"
      },
      "source": [
        "# Inference\n",
        "\n",
        "We use pandas to generate our csv file.\n",
        "\n",
        "BTW, the performance of the model trained for 200 epoches might be unstable. You can train for more epoches for a more stable performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wly5AgH2jePv"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "# label_predictor.eval()\n",
        "# feature_extractor.eval()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (test_data, _) in enumerate(test_dataloader):\n",
        "        \n",
        "        test_data = test_data.cuda()\n",
        "        # class_logits = label_predictor(feature_extractor(test_data))\n",
        "\n",
        "        # x = torch.argmax(class_logits, dim=1).cpu().detach().numpy()\n",
        "        outputs = model.predict(test_data)\n",
        "        x = torch.argmax(outputs, 1).cpu().detach().numpy()\n",
        "        result.append(x)\n",
        "\n",
        "import pandas as pd\n",
        "result = np.concatenate(result)\n",
        "\n",
        "# Generate your submission\n",
        "df = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\n",
        "df.to_csv('DaNN_submission_ensem_2.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X8v0wojx1jD"
      },
      "source": [
        "# Visualization\n",
        "We use t-SNE plot to observe the distribution of extracted features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkRtbyEOyYSN"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn import manifold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8NNrBEUjjz3"
      },
      "source": [
        "## Step1: Load checkpoint and evaluate to get extracted features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgO5O7uZjcCw"
      },
      "outputs": [],
      "source": [
        "# Hints:\n",
        "# Set features_extractor to eval mode\n",
        "# Start evaluation and collect features and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb9TmH3Wkh5P"
      },
      "source": [
        "## Step2: Apply t-SNE and normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edkTrdlri1MS"
      },
      "outputs": [],
      "source": [
        "# process extracted features with t-SNE\n",
        "# X_tsne = manifold.TSNE(n_components=2, init='random', random_state=5, verbose=1).fit_transform(X)\n",
        "\n",
        "# Normalization the processed features \n",
        "# x_min, x_max = X_tsne.min(0), X_tsne.max(0)\n",
        "# X_norm = (X_tsne - x_min) / (x_max - x_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoujX3uxk79a"
      },
      "source": [
        "## Step3: Visualization with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1dgPoDkjrLc"
      },
      "outputs": [],
      "source": [
        "# Data Visualization\n",
        "# Use matplotlib to plot the distribution\n",
        "# The shape of X_norm is (N,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpheoH_rvFbO"
      },
      "source": [
        "# Training Statistics\n",
        "\n",
        "- Number of parameters:\n",
        "  - Feature Extractor: 2, 142, 336\n",
        "  - Label Predictor: 530, 442\n",
        "  - Domain Classifier: 1, 055, 233\n",
        "\n",
        "- Simple\n",
        " - Training time on colab: ~ 1 hr\n",
        "- Medium\n",
        " - Training time on colab: 2 ~ 4 hr\n",
        "- Strong\n",
        " - Training time on colab: 5 ~ 6 hrs\n",
        "- Boss\n",
        " - **Unmeasurable**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYO8InxavGsy"
      },
      "source": [
        "# Learning Curve (Strong Baseline)\n",
        "* This method is slightly different from colab.\n",
        "\n",
        "![Loss Curve](https://i.imgur.com/vIujQyo.png)\n",
        "\n",
        "# Accuracy Curve (Strong Baseline)\n",
        "* Note that you cannot access testing accuracy. But this plot tells you that even though the model overfits the training data, the testing accuracy is still improving, and that's why you need to train more epochs.\n",
        "\n",
        "![Acc Curve](https://i.imgur.com/4W1otXG.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6UfXzef-wNl"
      },
      "source": [
        "# Q&A\n",
        "\n",
        "If there is any problem related to Domain Adaptation, please email to b08901058@ntu.edu.tw / mlta-2022-spring@googlegroups.comã€‚\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4TMXG_YCqVb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "hw11_domain_adaptation (en).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ecbd9286bd544f7fe4ef1add3c640987467b2b9ee7c82bb6d3e9831005f6ced4"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 ('torch11')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
